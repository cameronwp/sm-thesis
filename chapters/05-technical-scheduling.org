#+title: Technical Scheduling

* COMMENT
** TODO consistency with "noop"
is it =noop= or =no-op= or $\mathit{noop}$?
** TODO consistency with capitalization and italics of Scheduler, Delay Scheduler, Dispatcher, Driver
** TODO we need an =updateSchedule= algo defined in the execution strategy section
include the fact that it returns if an event is buffered
** TODO clean up fast-ex algos
- [ ] double check accuracy!
- [ ] weird italics
- [ ] check for loop usage
** TODO fix:observations is weird. fix notation, caption
** extra content 1
Bhargava et al. [cite:@Bhargava2018] addressed this ambiguity in contingent event assignment by
first transforming the VDC STNU into a controllability-equivalent fixed-delay STNU. With fixed
observation delay, we /do/ have the guarantee that we learn the exact assignment of contingent
events (so long as the observation delay is not infinite). Thus, scheduling a fixed-delay STNU only
differs from scheduling a vanilla STNU in that we must subtract a fixed observation delay when we
make contingent event assignments. Otherwise, the dispatchable form is the same as in the case of a
vanilla STNU, and we can choose any STNU scheduling algorithm to generate execution decisions.

# TODO explain "execution space" earlier?
# TODO wc "tractable"
The flow from variable-delay STNU to fixed-delay STNU to dispatchable form may appear sufficient to
enable scheduling of variable-delay STNUs, but we must contend with a novel issue: the execution
spaces of the original variable-delay STNU and its transformed fixed-delay equivalent are
mismatched. Nature is obliged to respect the uncertainties of the original variable-delay STNU. As
will be shown later, the fixed-delay equivalent reduces the execution space to make the
controllability check tractable. As such, we may receive observations outside the range of the
contingent links in the fixed-delay STNU, which we must reconcile with the dispatchable form. See
Figure [[fig:flow-chart]] for an overview of the information flow in scheduling a variable-delay STNU.
** old explanation of buffering and imagining
Next, in comparing the bounds of $x_{c}$ and $x'_{c}$ when $u - l \geq \gammabar^+(x_c) -
\gammabar^-(x_c)$, $x'_{c} \in [l^+(x_{c}), u^-(x_{c})]$ (Lemma [[lemma:main-tightening]]) there are
three regimes of observations of $\obs(x_{c})$ we must consider:

# TODO might be wordy
Nature decides in which regime we receive $\obs(x_{c})$. We are faced with the unique challenge of
deciding how to act when Nature selects an $\obs(x_{c})$ that fails to follow the constraints of
$S'$, eg. $\obs(x_{c}) < l^+(x_{c}) \lor \obs(x_{c}) > u^-(x_{c})$, which would lead to an
assignment, $\assign(x'_{c})$, in the first or third regimes above. In plainer words, the contingent
links of $S$ and $S'$ do not have the same constraints. We make assignments in $S'$, but we receive
observations from $S$. We need to decide how to act when we observe a contingent event earlier or
later than we expect according to $S'$, because if we blindly assigned $\assign(x'_{c})$ outside its
constraints from $S'$, we lose the guarantee of controllability. Our only choice is to find a
strategy to assign $x'_{c}$ that respects the constraints of $S'$, despite observing $x_{c}$ earlier
or later than expected. We do so by reasoning over the possible /range/ of assignments,
$\assign(x_{c})$, that could have led to a particular observation, $\obs(x_{c})$. What we find is
that, due to the uncertainty in observation delay, we are allowed to /modify/ our assignment of
$\assign(x'_{c})$ to ensure it respects $S'$. We present two modification strategies for addressing
the first and third cases, which we call /buffering/ and /imagining/ respectively.

We first address the case where $\obs(x_{c}) < l^+(x_{c})$. As shown in Lemma
[[lemma:buffering-imagining]], buffering is a valid execution strategy for early observations.

#+label: lemma:buffering
#+latex: \begin{lemma}
#+latex: \label{lemma:buffering}
If a contingent event, $x_{c} \in X_{c}$, is observed earlier than the bounds of $x'_{c}$ in $S'$
for a fixed-delay controllable $S'$, $\obs(x_{c}) < l^+(x_{c})$, we perform a /buffering/ operation
by letting $\assign(x'_{c}) = l^+(x_{c})$ in $S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
# Our strategy is to artificially assign \assign(x'_{c}) \in [l^+(x_{c}), l^+(x_{c})]$, or, in other
# words, /buffer/ it.

# TODO ditch g(x_c) in graph
# TODO subscripts and superscripts look like garbage in g docs
To demonstrate why buffering is sound, we compare the bounds of $x_{c}$ in $S$ and $x'_{c}$ in $S'$
to show that our execution strategy for $\assign(x'_{c})$ is applicable to any $\assign(x_{c}) \in
[l, l^+(x_{c})]$.

We know that $S'$ is fixed-delay controllable when $\assign(x'_{c}) \in [l^+(x_{c}), u^-(x_{c})]$.
Consider an observation at the lower bound of $\assign(x'_{c}), $\obs(x_{c}) = l^+(x_{c})$. We can
discern the range of possible assignments of $x_{c}$ in $S$ (Using Lemma
[[lemma:information-fixes-bounds]] to rewrite $o(x_{c}) = l^+(x_{c})$ as $o(x_{c}) = [l^+(x_{c}),
l^+(x_{c})]$).

#+begin_export tex
\begin{align*}
\obs(x_{c}) &= \assign(x_{c}) + \gammabar(x_{c}) \\
\assign(x_{c}) &= \obs(x_{c}) - \gammabar(x_{c}) \\
\assign(x_{c}) &= [l^+(x_{c}), l^+(x_{c})] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_{c}) &= [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c}))]
\end{align*}
#+end_export

Let $\alpha = [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c}))]$ for this Lemma.

Given $S'$ is fixed-delay controllable, there must exist an execution strategy when $\assign(x'_{c})
= l^+(x_{c})$, which entails the same execution strategy applies for any assignment of
$\assign(x_{c}) \in \alpha$. Thus, during execution, if we can show that $\assign(x_{c}) \subseteq
\alpha$, we can safely act as if $\assign(x'_{c}) = l^+(x_{c})$.

Now, let $\obs(x_{c}) = l^+(x_{c}) - \epsilon$ for some small, positive $\epsilon$. Accordingly, it
is the case that $\assign(x_{c})$ must fall in the range,

#+begin_export tex
\begin{align*}
\assign(x_{c}) &= [(l^+(x_{c}) - \epsilon) - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_c) &= [l^+(x_{c}) - \epsilon, l^+(x_{c}) - \epsilon] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_c) &= [l - \epsilon, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]
\end{align*}
#+end_export

Of course, $\assign(x_{c})$ must respect the original bounds of $x_{c}$, $x_{c} \in [l, u]$.

#+begin_export tex
\begin{align*}
\assign(x_c) &= [l - \epsilon, l + \gammabar^+(x_{c}) - \gammabar^-(x_{c}) - \epsilon] \cap [l, u]
\assign(x_c) &= [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]
\end{align*}
#+end_export

Let $\beta = [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]$ for this Lemma. See
Figure [[fig:observations]] for a visual representation of how an observation $\obs(x_{c})$ is
interpreted as an assignment \assign(x'_{c})$ during scheduling.

We see that $\beta \subset \alpha$. Thus, if we receive an observation $\obs(x_{c})$ earlier than
$l^+(x_{c})$, we may safely buffer by applying the execution strategy from an assignment of
$\obs(x_{c}) = \assign(x'_{c}) = l^+(x_{c})$.
#+begin_export tex
\end{proof}
#+end_export

Next,we address the case where $\obs(x_{c}) > u^-(x_{c})$.

#+label: lemma:imagining
#+begin_export tex
\begin{lemma}
\label{lemma:imagining}
If a contingent event, $x_{c} \in X_{c}$, will be observed after the bounds of $x'_{c}$, $\obs(x_{c}) > u^-(x_{c})$, we \textit{imagine} we have received it by assigning $\assign(x'_{c}) = u^-(x_{c})$ in $S'$.
\end{lemma}
#+end_export

#+begin_export tex
\begin{proof}
#+end_export
We apply the same argument to /imagining/ late events. We now consider an observation at the upper
bounds of $x'_{c}$, $\obs(x_{c}) = \assign(x'_{c}) = u^-(x_{c})$. We then have a new $\alpha$
representing the range of the earliest and latest assignments to $\assign(x_{c})$,

#+begin_export tex
\begin{align*}
\alpha &= u^-(x_{c}) - g(x_{c}) \\
       &= [u^-(x_{c}), u^-(x_{c})] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\alpha &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})), u]
\end{align*}
#+end_export

Once again, if $S'$ is fixed-delay controllable, there must exist an execution strategy for
$\assign(x'_{c}) = u^-(x_{c})$. It follows that we can apply this execution strategy when
$\assign(x_{c}) \in \alpha$.

If we receive a late observation, $\obs(x_{c}) = u^-(x_{c}) + \epsilon$, we find that
$\assign(x_{c})$ must fall in the range of a new $\beta$, where

#+begin_export tex
\begin{align*}
\beta &= \left[ (u^-(x_{c}) + \epsilon) - g(x_{c}) \right] \cap [l, u] \\
      &= \left[ [u^-(x_{c}) + \epsilon, u^-(x_{c}) + \epsilon] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \right] \cap [l, u] \\
      &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) + \epsilon, u + \epsilon] \cap [l, u] \\
\beta &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) + \epsilon, u]
\end{align*}
#+end_export

We find that $\beta \subset \alpha$ again and can safely imagine that we received $\obs(x_{c}) =
u^-(x_{c})$. Of course, we need not wait to receive a late observation of $x_{c}$ only to assign it
to a time in the past. During execution, if we have not received $\obs(x_{c})$ by $u^-(x_{c})$, we
imagine an observation arrived at $\obs(x_{c}) = u^-(x_{c})$ and thus assign $\assign(x'_{c}) =
u^-(x_{c})$. We then ignore the real observation of $x_{c}$ that we receive later.
#+begin_export tex
\end{proof}
#+end_export

** extra content 2 - analogy
To solidify the process of scheduling a variable-delay STNU, consider the following analogy.

#+begin_quote
Alex wants to go hiking in the woods. The area is unfamiliar to them, so they ask their friend, Sam,
who hiked these trails a long time ago, to give them directions to traverse from the trailhead to a
particularly spectacular overlook. Sam has a working idea of the trail map, but their memory is
imperfect. Regardless, they guarantee Alex that their directions will lead Alex to the overlook even
if the woods have changed over the years. Sam writes down directions like "turn left after 500
meters at the giant oak tree" and "turn right after 100 meters when you see the brook." Alex knows
that Nature will not necessarily obey Sam's directions. They may observe a giant oak tree earlier
than expected, so they must then wait to take the next trail going left. Or the brook may have dried
up, so they imagine they saw one near where Sam thought it would be and take the next right. While
hiking, Alex is charged with reconciling Sam's directions with their own observations. Even though
they may identify the landmarks in Sam's directions earlier or later than expected, their actions
will need to follow Sam's instructions to maintain the guarantee of reaching the overlook.
#+end_quote

In our analogy, $S$ models the current state of the hiking trails and the full range of projections,
while $S'$ is Sam's working memory of them. Sam's directions are the execution strategy described by
the AllMax graph we get by checking the fixed-delay controllability of $S'$. Observations of Nature
obey $S$. Alex is charged with reconciling their observations from $S$ with Sam's hiking directions
from $S'$. The analogy ends here, though, as the math and logic of temporal reasoning do not neatly
translate into hiking. Luckily, we have more information than Alex. Unlike human memory, which is
untrustworthy and irrational, the fixed-delay STNU, $S'$, is created by a set of Lemmas with
deterministic outcomes. As such, we have the means to interpret how observations in $S$ /would
appear/ in $S'$, which will be critical in adapting our fixed-delay execution strategy in response
to variable observation delay.

Our key challenge for scheduling an STNU with variable observation delay is reconciling observations
from $S$ with the dispatchable form from $S'$.

During execution, we observe the outcome of contingent events $\obs(x_{c})$ in $S$, but we make
assignments in the dispatchable form of $\assign(x'_{c})$ in $S'$. Despite being equivalent with
respect to controllability, the bounds of contingent links $x_{c}$ in $S$ and $x'_{c}$ in $S'$ are
not equivalent.

** I think VDC->FDC algo? not sure why this was here
Let $x$ be a temporal event, $x \forall x \in X_{c} \cup X_{e}$.

#+begin_export tex
\begin{algorithm}[H]
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{VDC-FAST-EX-Update}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{AllMax Graph $G$; fixed-delay function $\gamma(x'_{c})$; Observation $\obs(x_{c})$}
\Output{Updated AllMax Graph $G$}
\Initialize{}
\Indp
\Indm
\Algorithm{}
\Indp
\For{$l \in S'.contingentLinks()$} {
    $x_c \leftarrow l.endpoint()$\;
    $a, b \leftarrow l.bounds()$\;
    \If{$\gammabar^+(x_c) == \infty$ or $\gammabar^+(x_c) == \gammabar^-(x_c)$} {
        $\gamma'(x_c) \leftarrow \gammabar^+(x_c)$\;
    } \ElseIf {$b - a < \gammabar^+(x_c) - \gammabar^-(x_c)$} {
        $\gamma'(x_c) \leftarrow \infty$\;
    }
    \Else {
        $l.setBounds(a + \gammabar^+(x_c), b + \gammabar^-(x_c))$\;
        $\gamma'(x_c) \leftarrow 0$\;
        \For{$l' \in x_c.outgoingReqLinks()$} {
            $u, v \leftarrow l'.bounds()$\;
            $l'.setBounds(u - \gammabar^-(x_c), v - \gammabar^+(x_c))$\;
        }
        \For{$l' \in x_c.incomingReqLinks()$} {
            $u, v \leftarrow l'.bounds()$\;
            $l'.setBounds(u + \gammabar^+(x_c), v + \gammabar^-(x_c))$\;
        }
    }
}
\Return $S', \gamma'$
\caption{Algorithm for updating the AllMax graph when an observation arrives}
\label{alg:conversion}
\end{algorithm}
#+end_export
** something about practicalities of string event-ids
While we made a careful distinction between $x_{c}$ and $x'_{c}$ in our discussion of scheduling, in
our implementation it was important to be able to easily replace one with another when looking up
values in hash-tables and lists. For instance, to implement Equation [[eqn:fixed-recording]], we receive
$x_{c}$ but key the fixed-delay function on $x'_{c}$. Rather than adding an additional translation
layer, we give each temporal event in $S$ a unique name, all of which get copied to their equivalent
events in $S'$. Hash-tables are keyed on event names, vastly simplifying lookups in the AllMax
graph, delay function, and elsewhere.

* Single-Agent Execution with Delayed Event Monitoring
<<ch:delay-scheduling>>

Now that we have shown there exists a valid execution strategy for variable-delay controllable
STNUs, we contribute a novel scheduling and dispatching architecture for online, dynamic execution.
In this Chapter, our aim is to describe the single-agent form of a new instantiation of Kirk, /Delay
Kirk/, that can reason over uncertain observation delay to decide when to execute requirement events
on real hardware. There are two main components to Delay Kirk: (1) a /delay scheduler/, and (2) a
/delay dispatcher/. As will be shown in Section [[sec:delay-scheduling]], scheduling variable-delay
controllable STNUs is an extension to existing dynamic scheduling algorithms with modifications for
the execution strategy shown to be sound and complete in Chapter [[ch:modeling-tn]].

Additionally, to the best of our knowledge, scheduling fixed-delay STNUs has not been presented in
the literature. Fixed-delay scheduling is required for addressing (1). As such, we contribute a
fixed-delay scheduler in Section [[sec:delay-scheduling]]. The execution strategy from Chapter
[[ch:modeling-tn]] will be shown to be a small extension to the fixed-delay scheduler. As to (2), to the
best of our knowledge, there are no other formalized dispatching algorithms in the literature. In
the development of Delay Kirk, we found it to be extremely useful to formalize dispatching as part
of creating a clear interface boundary between scheduling and dispatching. The dispatching
algorithms we put forth in Section [[sec:dynamic-dispatching]] represent novel contributions to temporal
reasoning.

This Chapter makes additional contributions to scheduling and dispatching. Safely executing events
on real hardware requires modifications to generating decisions in dynamic scheduling. We include
said modifications, with confluent interfaces in dynamic dispatching, to suit our intended use cases
for Delay Kirk.

# TODO maybe?
In Section [[sec:optimistic-rescheduling]], we extend our approach to scheduling variable-delay STNUs by
introducing an optional procedure that addresses a shortcoming in the semantics of scheduling a
variable-delay STNU. The shortcoming takes the form of potentially unnecessary wait times that are
added after receiving contingent event assignments, extending the makespan of procedures. We present
a generate-and-test algorithm to partially mitigate said shortcomings.

Finally, Section [[sec:scheduling-experimental]] provides a series of benchmarks of the scheduling and
dispatching algorithms described in this Chapter.

** Dynamic Scheduling through Real-Time Execution Decisions
<<sec:dynamic-scheduling>>

We first provide a necessary overview of dynamic scheduling of vanilla STNUs, which we will extend
for STNUs with observation delay in Section [[sec:delay-scheduling]].

An STNU, $S$, that exhibits dynamic controllability can be /scheduled/ dynamically (or /online/). At
a high-level, dynamic scheduling is the process of mapping the history of event assignments to the
execution time of future free events. We will build off of the scheduling work by Hunsberger
[cite:@Hunsberger2013;@Hunsberger2016], which describes an $O(N^{3})$ online procedure, FAST-EX, for
dynamic scheduling of STNUs. We chose FAST-EX because, to the best of our knowledge, this is the
fastest dynamic scheduling algorithm in the literature today. At its core is the notion of
/Real-Time Execution Decisions/ (RTEDs), which map a timepoint to a set of requirement events to be
executed and are generated based on /partial schedules/ of STNUs being executed. =WAIT= decisions
may also be produced, reflecting the need to wait for the assignment of a contingent event before
continuing. RTED-based scheduling applies a dynamic programming paradigm in three steps:

# TODO why did I use Hunsberger2009 here? not 2016?
1. creating a dispatchable form of temporal constraints offline in the form of a distance graph,
2. updating the dispatchable form as the partial schedule is updated online through event
   assignments, and
3. querying the dispatchable form online to quickly find the next RTED [cite:@Hunsberger2009].

The dispatchable form employed by FAST-EX is the /AllMax/ distance graph, which is produced by the
Morris $O(N^{4})$ DC-checking procedure [cite:@Morris2006].

#+latex: \begin{defn}
*AllMax Distance Graph* [cite:@Morris2005]

The /AllMax/ distance graph is a distance graph exclusively consisting of unlabeled and upper-case
edges.
#+latex: \end{defn}

The key idea of FAST-EX is maintaining accurate distances from an artificial zero point, $Z$, of the
distance graph to all events. At the outset of execution, all events from $S$ are present as nodes
in /AllMax/. As events are assigned, /AllMax/ performs update steps using Dijkstra Single
Source/Sink Shortest Path (SSSP) to maintain distances to unexecuted events, while also collapsing
executed events to $Z$. We include pseudo-code of the real-time update step in Figure
[[alg:fast-ex-update]].

#+label: alg:fast-ex-update
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{FAST-EX Update}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{Time $t$; Set of newly executed events $\texttt{Exec} \subseteq X_{e} \cup X_{r}$; AllMax Graph $G$; Distance matrix $D$, where $D(A, B)$ is the distance from $A$ to $B$}
\Output{Updated $D$}
\Indp
\Algorithm{}
\Indp
\For{each contingent event $C \in \texttt{Exec}$} {
    Remove each upper-case edge, $\edge{Y}{A}{C:-w}$, labled by $C$\;
    Replace each edge from $Y$ to $Z$ with the strongest replacement edge\;
}
\For{each event $E \in \texttt{Exec}$} {
    Add lower-bound edge $\edge{E}{Z}{-t}$\;
}
For each event $X$, update $D(X, Z)$ using Dijkstra Single-Sink Shortest Paths\;
\For{each event $E \in \texttt{Exec}$} {
    Add upper-bound edge $\edge{Z}{E}{t}$\;
}
For each event $X$, update $D(Z, X)$ using Dijkstra Single-Source Shortest Paths\;
\caption{Algorithm for updating distances for all events in relation to $Z$ upon the execution of an event. Adapated from \citeprocitem{3}{[3]}, Fig. 19.}
\label{alg:fast-ex-update}
\end{algorithm}
#+end_export

With an up-to-date distance graph in hand, we can perform an online query for the current RTED.

#+latex: \begin{defn}
*Real-Time Execution Decisions* [cite:@Hunsberger2009]

A /Real-Time Execution Decision/ is a two-tuple $\langle t, \chi \rangle$, where:
- $t$ is a time with domain $\mathbb{R}$,
- $\chi$ is a set of $x_{r} \in X_{r}$ to be executed at time $t$
#+latex: \end{defn}

Let $U_{x}$ be the set of unexecuted free timepoints. If $U_{x}$ is empty, then the RTED is to
=WAIT=. Otherwise, we find the lower bound of the earliest executable time point and the set of
executable events associated with it.

#+label: eqn:rted1
\begin{align}
t &= \min\{-D(X, Z)~|~X \in U_{x}\} \\
\label{eqn:rted-chi}
\chi &= \{X \in U_{x}~|~-D(X, Z) = t\}
\end{align}

We cannot execute events in the past. Let =now= be the current time, i.e. the last timepoint
captured in the event assignments. It is possible that $t \leq \texttt{now}$, in which case we must
reassign $t$ to guarantee that $t > \texttt{now}$. To do so, we update $t$ as follows, where $t^+$
is earliest upper bound of the executable timepoints,

#+label: eqn:rted2
\begin{align}
t^+ &= \min\{D(Z, X)~|~X \in U_{x}\} \\
\label{eqn:rted-t}
t &= \cfrac{\texttt{now} + t^+}{2}
\end{align}

So long as $t^+ > \texttt{now}$, we know that the reassignment of $t$ ensures $t > \texttt{now}$.

** Delay Scheduling as an Extension to Dynamic Scheduling
<<sec:delay-scheduling>>

#+ATTR_ORG: :width 400
#+ATTR_LATEX: :width 0.8\textwidth
#+caption: A high-level flow chart showing how we use variable-delay STNUs to generate scheduling decisions. The boxes represent the data structures involved in scheduling, while the arrows are the processes that are followed to eventually produce RTEDs.
#+label: fig:flow-chart
[[file:../images/flow-chart.png]]

Figure [[fig:flow-chart]] presents a high-level overview of the information flow in the scheduling
process.

In order to schedule a variable-delay STNU, the core problem we must address is that, to date, there
is no means to directly create a corresponding dispatchable form that accounts for uncertain
assignments resulting from variable observation delay. We encountered this same problem when
describing the process of checking VDC in Section [[sec:vdc]]. We overcame this limitation by first
transforming the variable-delay STNU to a fixed-delay STNU before checking FDC. A similar strategy
will be followed for scheduling in that we will transform the variable-delay to a fixed-delay STNU,
then dispatch events using the dispatchable form of the fixed-delay STNU instead. However, doing so
creates a second problem. While we will be performing FAST-EX against the fixed-delay STNU, the
contingent event observations we receive will adhere to the constraints and variable-delay function
of the variable-delay STNU. Hence, we must modify our real-time update and RTED generation
algorithms to account for early and late contingent event observations.

# TODO rewrite
We start by providing an explanation of fixed-delay scheduling, before expanding it to address the
execution strategies of variable-delay scheduling.

*** Fixed-Delay Scheduling

# TODO wc algebra
We first establish the algebra of receiving observations.

#+label: lemma:information-fixes-bounds
#+latex: \begin{lemma}
#+latex: \label{lemma:information-fixes-bounds}
For any contingent event, $x_{c} \in S$ or $x'_{c} \in S'$, observing $x_{c}$ at time $t \in
[l^-(x_{c}), u^+(x_{c})]$ fixes the observation to $\obs(x_{c}) = [t, t]$.
#+latex: \end{lemma}
#+latex: \begin{proof}

# TODO use def:schedule-as-interval?

Prior to execution, an observation of $x_{c}$ may fall anywhere within the set-bounded interval from
the earliest possible observation at $l^-(x_{c})$ to the last possible observation at $u^+(x_{c})$.
Receiving an observation $\obs(x_{c}) = t$ during execution eliminates all possible observations
outside the interval $[t, t]$.
#+latex: \end{proof}

#+label: lemma:equal-is-fixed-bounds
#+latex: \begin{lemma}
#+latex: \label{equal-is-fixed-bounds}
For any temporal constraint, $x$, with bounds $x \in [l, u]$ for some $l$ and $u$, and timepoint $t
\in [l, u]$, if information reduces the bounds of $x$ to $x \in [t, t]$, we may assert $x = t$.
#+latex: \end{lemma}

#+latex: \begin{proof}
# TODO is this sound?
When the bounds of an interval, $x \in [l, u]$ are fixed such that $t = l = u$, we can assert that
$x$ must have resolved to $t$.
#+latex: \end{proof}

#+label: lemma:subtract-gamma
#+latex: \begin{lemma}
#+latex: \label{lemma:subtract-gamma}
For any contingent event $x'_{c} \in X_{c}$ in fixed-delay controllable $S'$, if $\gamma(x'_{c}) \in
\mathbb{R}$, we assign $\assign(x'_{c}) = \obs(x_{c}) - \gamma(x'_{c})$ in the dispatchable form of
$S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
The central challenge of checking fixed-delay controllability is determining that an execution
strategy exists that allows an agent to wait an additional $\gamma(x'_{c})$ time units after a
contingent event has been assigned to learn its outcome. Importantly, the $\gamma$ function is not
used to modify the edges of the labeled distance graph, which are derived from the constraints $r
\in R_{e} \cup R_{c}$ in $S'$.

As $\gamma(x'_{c})$ resolves to a known and finite value, we can derive the true value of
$\assign(x'_{c})$ to be assigned in the labeled distance graph. Contingent event assignments are
recorded in the labeled distance graph as follows, where $\obs(x_{c})$ is the resolved observation,

#+label: eqn:fixed-recording
#+begin_export tex
\begin{align}\assign(x'_c) = \obs(x_c) - \gamma(x'_c) \label{eqn:fixed-recording}
\end{align}
#+end_export
#+latex: \end{proof}

The FAST-EX real-time update algorithm, Algorithm [[alg:fast-ex-update]], then becomes Algorithm
[[alg:fast-ex-fixed-obs]].

#+label: alg:fast-ex-fixed-obs
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{FAST-EX Update with Fixed Observation Delay}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{Time $t$; Set of newly observed events $\texttt{Exec} \subseteq X_{e} \cup X_{r}$; AllMax Graph $G$; Distance matrix $D$, where $D(A, B)$ is the distance from $A$ to $B$; Fixed-delay function $\gamma$;}
\Output{Updated $D$}
\Indp
\Algorithm{}
\Indp
\For{each contingent event $C \in \texttt{Exec}$} {
    $\assign(C) \leftarrow \obs(C) - \gamma(C)$\;
    Remove each upper-case edge, $\edge{Y}{A}{C:-w}$, labled by $C$\;
    Replace each edge from $Y$ to $Z$ with the strongest replacement edge\;
}
\For{each event $E \in \texttt{Exec}$} {
    Add lower-bound edge $\edge{E}{Z}{-t}$\;
}
For each event $X$, update $D(X, Z)$ using Dijkstra Single-Sink Shortest Paths\;
\For{each event $E \in \texttt{Exec}$} {
    Add upper-bound edge $\edge{Z}{E}{t}$\;
}
For each event $X$, update $D(Z, X)$ using Dijkstra Single-Source Shortest Paths\;
\caption{Algorithm for updating distances for all events in relation to $Z$ upon the execution or observation of an event.}
\label{alg:fast-ex-fixed-obs}
\end{algorithm}
#+end_export

No other modifications to FAST-EX are required to schedule a fixed-delay STNU.

*** Variable-Delay Scheduling

Our execution strategy must address each of the following special categories of contingent event
observations:

1. contingent events with infinite observation delay,
2. contingent events that are observed outside $[l^+(x_{c}), u^-(x_{c})]$ in $S'$.

The first category is a requirement for dispatching the fixed-delay equivalent of a variable-delay
STNU. If the constraints of a problem domain are modeled directly in a fixed-delay STNU and the
modeler gives a contingent event, $x_{c}$, infinite delay, e.g. $\gamma(x_{c}) = \infty$, the event
will never be observed and thus a fixed-delay scheduler has no need for an execution strategy in the
event that $x_{c}$ is observed. However, by Lemmas [[lemma:partially-unobservable]] and
[[lemma:not-enough-information]] there are some contingent events with potentially finite observation
delay in $S$ that are transformed to infinite observation delay in $S'$, making it possible that the
scheduler receives observations of them.

#+label: lemma:ignore-inf-delay
#+latex: \begin{lemma}
#+latex: \label{lemma:ignore-inf-delay}
For any contingent event $x'_{c} \in X_{c}$ in fixed-delay controllable $S'$, if $\gamma(x'_{c}) =
\infty$, we mark the event executed but do not assign $\assign(x'_{c})$ in the dispatchable form of
$S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
If we are scheduling a fixed-delay STNU, $S'$, that is already known to be fixed-delay controllable,
an execution strategy must exist that is independent of the assignment of $\assign(x'_{c})$ when
$\gamma(x'_{c}) = 0$. We are not required to record $\assign(x'_{c})$ when $\gamma(x'_{c}) = \infty$
to guarantee controllability and may safely ignore it.

We mark the event executed to prevent it from appearing in future RTEDs.
#+latex: \end{proof}

#+label: fig:observations
#+attr_latex: :width 3in
#+caption: Here, we show how the combination of $\assign(x_{c})$ and $\gammabar(x_{c})$ lead to an assignment of $\assign(x'_{c})$ in $S'$. We see the range $\alpha \in [l, l + \gammabar^+(x_{c}) - \gammabar^-(x_{c})$ representing the earliest and latest assignments of $\assign(x_{c})$ that could result in $\obs(x_{c}) \in \assign(x'_{c}) \in [l^+(x_{c})$, l^+(x_c)]$. The grey region represents the range of possible observation delays, $\gammabar(x_{c})$, supporting $\assign(x'_{c}) \in [l^+(x_{c}), l^+(x_{c})]$.
[[file:../images/viz-l-plus.png]]

The second category refers to the need for buffering and imagining events as a result of Lemma
[[lemma:main-tightening]] using the execution strategy proven to be valid in Lemma
[[lemma:buffering-imagining]]. There are three regimes of contingent event observations to address.

1. $\obs(x_{c})  \in [l^-(x_{c}), l^+(x_{c}))$, ie. strictly earlier than the range
   of $\assign(x'_{c})$,
2. $\obs(x_{c}) \in [l^+(x_{c}), u^-(x_{c})]$, ie. the range equivalent to $x'_{c}$, and
3. $\obs(x_{c}) \in(u^-(x_{c}), u^+(x_{c})]$, ie. strictly later than the range of
   $\assign(x'_{c})$.

Note that we omit the $-\gamma(x'_{c})$ term from Equation [[eqn:fixed-recording]] in this analysis due
to the fact that $\gamma(x'_{c}) = 0$ after applying Lemma [[lemma:main-tightening]].

Our execution strategy is to then make the following assignments during the FAST-EX real-time
update.

#+begin_export tex
\begin{equation}
\assign(x'_c) = \begin{cases}
$l^+(x_{c})$  & \text{if } $\obs(x_{c}) \in [l^-(x_{c}), l^+(x_{c}))$ \textit{(buffering)} \\
$\obs(x_{c})$ & \text{if } $\obs(x_{c}) \in [l^+(x_{c}), u^-(x_{c})]$ \\
$u^-(x_{c})$  & \text{if } $\obs(x_{c}) \in (u^-(x_{c}), u^+(x_{c})]$ \textit{(imagining)}
\end{cases}
\end{equation}
#+end_export

In the last case, late observations are assigned to an earlier time. During execution, time is
always increasing. There is no need to wait to make an observation after $u^-(x_{c})$. Instead, we
modify RTED generation, namely Equation [[eqn:rted1]], such that we dispatch $x'_{c}$ at $u^-(x_{c})$ if
it is not been observed before $u^-(x_{c})$. Let $U_{c}$ be the set of unobserved contingent
timepoints.

#+label: rted-with-ctg
\begin{align}
t_{x} &= \min\{-D(X, Z)~|~X \in U_{x}\} \\
t_{c} &= \min\{D(Z, X)~|~X \in U_{c}\} \\
t &= \min\{t_{x}, t_{c}\} \\
\chi_{x} &= \{X \in U_{x}~|~-D(X, Z) = t\} \\
\chi_{c} &= \{X \in U_{c}~|~D(Z, X) = t\} \\
\chi &= \chi_{x} \cup \chi_{c}
\end{align}

We see that RTEDs may now include unobserved (or unexecuted) contingent timepoints at their upper
bounds. Note that there is no need to distinguish between contingent events that are the result of
tightening during the fixed-delay transformation by applying Lemma [[lemma:main-tightening]] and others.
We assume that the contingent constraints of the variable-delay STNU accurately reflect Nature. The
latest any other contingent event should be observed is their upper bound in $S'$ and thus should
never be in the set of events, $\chi$, of an executed RTED.

We have defined variable-delay execution strategies for when contingent events have infinite delay
and tightened constraints. The remaining category of contingent events is when a contingent event
has a finite, non-zero $\gamma(x'_{c})$ in $S'$. If that is the case, $x'_{c}$ must have had fixed
observation delay in $S$, Lemma [[lemma:emulating-fixed]], and can be scheduled normally after backing
out the observation delay with Equation [[eqn:fixed-recording]].

We have addressed the key issue of reconciling observations from $S$ with the dispatchable form from
$S'$. We now present a dispatcher and wrapper algorithms on top of FAST-EX that combine to add
robustness for variable observation delay.

** Dynamic Dispatching of STNUs with Observation Delay
<<sec:delay-scheduler>>

The terms "scheduling" and "dispatching" are often used interchangeably in temporal reasoning
literature. However, we distinguish the goals of a scheduler, as described above, and a dispatcher.

- *Scheduling*: Generating RTEDs based on a partial schedule.
- *Dispatching*: Reasoning over a clock and RTEDs to guarantee requirement events are safely (w.r.t.
  controllability) executed.

We assume that events in an STNU map 1:1 to actions in the real world. To put the design of the
dispatcher in context, it is worth considering what events may look like. In the case of a robotic
agent, requirement events may represent the instantaneous timepoint when a motion plan begins, while
contingent events could be anything from the completion of said motion plan to receiving a "GO"
message from a third party. For a human, a requirement event could be presented in a mission
timeline as the start of action like, say, collecting a scientific sample. The end of sampling would
then be a contingent event. Or contingent events could be the actions performed by other agents,
like say another astronaut on an EVA, with whom temporal constraints are shared. In both the case of
the robot and the human, a robust dispatcher should take into consideration that passing a message
to the agent telling it to execute a requirement event does not cause the event to occur
instantaneously. Put in other words, dispatching is not the same as assignment. A robot may need
offline processing before it executes the motion plan. Or a human may need to acknowledge that they
have started the activity their mission timeline has told them to perform. Neither is a problem,
though, for our chosen formalism for representing temporal constraints and scheduling so long as a
requirement event is assigned at some point within its constraint in the STNU. In our view, the
dispatcher is responsible for ensuring said requirement constraints are met by both monitoring the
real-world and interfacing with hardware to cause actions to be performed.

In this Section, we contribute a set of algorithms for building a robust executive that can reason
over observation delay and safely enact the actions symbolized in requirement events in the real
world.


Dynamic dispatching is designed around the two interfaces of scheduling - the input of partial
schedules and output of RTEDs. As such, we contribute algorithms for observing events and managing
RTEDs.

In our view, RTEDs are not commands to the agent. Rather, they inform the executive of the
time where actions ensure consistency.

*** Real vs No-op Events
<<sec:real-vs-noop-events>>

The introduction of buffering and imagining events creates a new distinction between temporal
events: there are events that need to be executed by the agent and there are those events that do
not. We call these /real/ and /no-op/ ("no operation") events. Both contingent /and/ requirement
events may fall into either category. Below, we present our rationale for the distinction between
real and no-op events, and how we modify real-time execution decisions accordingly.

To start, both buffered and imagined contingent events are no-ops. Both cases represent timepoints
that we use to update our dispatchable form to maintain consistency with $S'$.

Consider the process of normalization of an STNU [cite:@Morris2006]. While building the labeled
distance graph during a dynamic controllabillity check, we rewrite contingent links such that their
lower bounds are always $0$. For instance, for a contingent event $C$ and free event $E$, $C - E \in
[l, u]$, during normalization we create a new requirement event, $C'$, fixed at the lower bound of
the contingent link, and then shift the bounds of the contingent link to start at 0 while
maintaining the original range, $u - l$. This results in two constraints: $E - C' \in [l, l]$ and
$C - C' \in [0, u - l]$ that still reflect the original contingent link's semantics.

# TODO how many times am I going to use the word "semantics"?

To a scheduler, there is no distinction between the semantics of a real event, as modeled by a human
planner writing an STNU for an agent to execute, and $C'$, an artifact of checking controllability.
Both are modeled in the AllMax distance graph forming the basis of RTED generation. However, an
agent does not need to execute any task in the outside world to satisfy $E - C'$. We take a view
that the only information our agent has about the timepoints it should execute comes from the input
STNU. Thus, we need RTEDs to reflect the distinction between requirement events that are /real/,
meaning the agent is responsible for taking some action to execute them, and those that are
/no-ops/, or algorithmic by-products that require no operation. This distinction naturally leads to
the following addendum to the definition of RTEDs.

#+begin_export latex
\newcommand*{\eventnoop}{\mathit{event}\textsf{-}\mathit{noop}}
\newcommand*{\eventnoops}{\mathit{event}\textsf{-}\mathit{noops}}
#+end_export

# TODO these variables aren't great
#+label: def:rted
#+latex: \begin{defn}
*Event-No-op Pair*

An /Event-No-op Pair/, $\eventnoop$, is a two-tuple, $\langle x, \mathit{noop} \rangle$,
where:
- $x$ is an event in $X_{e} \cup X_{c}$,
- $\mathit{noop}$ is a boolean, where if true, the event does not correspond to an action an agent
  should take, else real.
#+latex: \end{defn}

#+label: def:rted-op
#+latex: \begin{defn}
#+latex: \label{def:rted-op}
*RTED with Operational Distinction*

A /Real-Time Execution Decision with Operational Distinction/ is a two-tuple $\langle t,
\eventnoops \rangle$, where:
- $t$ is a time with domain $\mathbb{R}$,
- $\eventnoops$ is a set of $\eventnoop$ pairs to be executed at time $t$.
#+latex: \end{defn}

For convenience and simplicity, and given the similarities between RTED and RTED with Operational
Distinction, future references to RTEDs will always mean RTEDs with Operational Distinctions.

** Dynamic Dispatching
<<sec:dynamic-dispatching>>

# TODO is the salient point here RTEDs? or is there something else that's more important about the
# relationship between the dispatcher and the scheduler?
This thesis contributes a dynamic dispatching algorithm for which the process of generating RTEDs is
a subroutine. As such, a dedicated dispatcher layer is required to
translate RTEDs to real actions at the right time. The dispatcher will request RTEDs and then wait
until the time window of the execution to trigger their execution.

# This thesis contributes a novel dispatching algorithm that works with any dynamic scheduler.

# TODO these paragraphs need to be cleaned up and streamlined

# scheduler doesn't do any "extraneous" jobs (extraneous is a good word. use it?)
A /dynamic dispatcher/ (or just "dispatcher") is an interface layer situated between the scheduler
and a /driver/ that communicates with hardware. The dispatcher has a two-fold responsibility: it
triggers the execution of RTEDs in the outside world by communicating with the driver (Section
[[sec:event-dispatching]]), and it relays observations from the outside world about the execution of
events to the scheduler (Section [[sec:event-observations]]). An explicit dispatching layer allows us to
centralize the logic for interacting with the outside world therein, keeping the scheduler simple.
In the implementation of Kirk used in this thesis, the scheduler wholly consists of the algorithms
described above, nothing more. We go so far as to enforce that the scheduler itself has no notion of
a clock. Instead, the dispatcher has a clock. When the dispatcher wants the scheduler to update
itself, it is required to send both an event and a elapsed time to the scheduler.

Consequently, the dispatching algorithm is separate from the scheduler. As such, there is no hard
requirement on the FAST-EX-based scheduler described above. Any scheduling algorithm that produces
RTEDs adhering to Definition [[def:rted-op]] would be compatible with the dispatcher described below.

*** Dynamic Event Dispatching
<<sec:event-dispatching>>

The dynamic dispatcher runs the main loop of the executive's temporal reasoning routine. The inner
loop, Algorithm [[alg:dispatcher-inner]], is responsible for retrieving the latest RTEDs and firing
driver commands when the clock indicates that the agent is inside RTED time windows. The outer loop,
Algorithm, [[alg:dispatcher-outer]], runs continuously until the scheduler reports that there are no
free events remaining to schedule. The dispatcher requests RTEDs with blocking synchronous calls,
while the dispatcher and driver communicate asynchronously. The dispatcher spawns a thread to make
non-blocking calls to the driver's interface to execute events. The dispatcher and driver also share
a FIFO queue that the driver can append messages to indicating the successful execution of events.

We now provide a walkthrough of the dynamic dispatching algorithm. For simplicity's sake, the term
/schedule/ here is shorthand for whatever data structures the scheduler uses to generate RTED.
/Updating the schedule/ may be used to refer to making an event assignment in the scheduler,
triggering any necessary changes to the schedule.

The interaction between the inner and outer loop is limited. The inner loop returns a Boolean
indicating whether there are executable events remaining. The outer loop is a simple =while= that
repeats until it receives =false= from the inner loop. Otherwise, the only communication between the
inner and outer loops is a variable containing the last RTED that was generated but not executed.
The outer loop creates the variable and passes it by reference to the inner loop. The inner loop is
free to use or modify the variable as it sees fit.

We break the inner loop of algorithm into three distinct phases.

# TODO it's not a time window! it's a single time. probs need to define execution window
1. Receive execution confirmation from the driver.
2. Collect an RTED and confirm the clock time is within the execution window.
3. If there is an RTED:
   a. send executable events to the driver, else
   b. immediately assign all =noop= events to the current time.

Our goal in the inner loop is to dispatch events to the driver only after updating the schedule,
collecting an up-to-date RTED, and confirming we are within the time window of the RTED. The loop
will exit before reaching the dispatch step if any conditions are not met.

For the first step, we ask the scheduler if there are any remaining executable events. If there are
none, we return =false= to signal the loop's termination, otherwise we continue.

Next, we check the FIFO queue for any event execution messages returned from the driver. The
presence of a message would indicate that the driver has successfully executed a free event. We
iteratively pop messages off the queue and update the schedule with the events and execution time
contained in each message. Note that the scheduler update is a blocking operation because we need an
up-to-date schedule to guarantee future RTEDs are consistent. We then invalidate the last RTED
generated.

# TODO do we need to be more specific about checking the RTED? what if some events overlap but not all?
The second step starts once we have popped all messages from the driver off the queue. If we do not
have a valid RTED from the last iteration of the inner loop, we ask the scheduler for one and save
it to the referenced variable from the outer loop. Given that we interact with the driver
asynchronously, it is possible that the current RTED is one that has already been sent to the driver
but we have yet to receive a message confirming its execution. If so, there is nothing to do so we
return =true=.

# TODO does it make sense to call it a "suggested" time?
# TODO isn't this the second \epsilon in the chapter? what about the epsilon proof? maybe the proof gets a new variable because this one is baked into Kirk?
Lastly, we compare the suggested time in the RTED against the clock's elapsed time. Given the
relationship between the scheduler, inner loop, and driver, we do not assume that dispatched events
are executed instantaneously by the driver. We know that execution contends against delays such as
the computational time in simply calling a function, to network latency, to robotic hardware that
takes a moment to interpolate a motion plan from waypoints. In some contexts, it may make sense to
preempt execution by dispatching events some small amount of time /before/ the clock time reaches
the RTED execution window. We call this preemption time $\epsilon$, where $\epsilon \in
\mathbb{R}^{\geq 0}$. Thus, we dispatch events, =dispatch-p=, when $\texttt{dispatch-p} =
(t_{\text{RTED}} - t_{\text{clock}} \leq \epsilon)$. If $\epsilon = 0$, the dispatcher is not
allowed to preemptively dispatch events before the RTED time. We allow the human operator to choose
an $\epsilon$ that is consistent with the operational context for the driver.

If =dispatch-p= is =false=, we are too early to execute the RTED and so the loop returns =true=.
Otherwise we continue.

Once we reach the third stage, we are guaranteed to be able to safely dispatch events because (1) we
have confirmed that the RTED we have in hand has unexecuted events that have never been dispatched,
and (2) that we are in a time window that the scheduler has told us is consistent with the STNU's
constraints. Going forward, we take advantage of the operational distinction we added to
Hunsberger's RTEDs in Definition [[def:rted-op]]. Using the $\mathit{noop}$ property of each
$\eventnoop$ pair in the RTED, we filter the $\eventnoop$ pairs into a set of =noop= events and a
set of real events. The real events are asynchronously sent to the driver. We then loop through the
=noop= events and schedule them in turn.

Finally, because events were dispatched, the inner loop returns =true=.

# TODO is it really an inner /loop/ or the inner part of the loop?

# TODO annotate the algo better. maybe comments? sections?

#+label: alg:dispatcher-outer
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Outer Loop}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\SetKw{Continue}{continue}

\Indm

\Initialize{$\mathit{RTED_{\mathit{last}}} \gets \varnothing$}

\Indp
\Algorithm{}
\Indp

\While{Calling inner loop with $\mathit{RTED_{\mathit{last}}}$ returns $\textbf{true}$} {
    \Continue
}
\caption{The outer loop of the dynamic dispatching algorithm.}
\label{alg:dispatcher-outer}
\end{algorithm}
#+end_export

# TODO check logic with last RTED

#+label: alg:dispatcher-inner
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Inner Loop}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{$\mathit{Scheduler}$; $\mathit{Driver}$; FIFO queue, $\mathit{Queue}$; $\mathit{RTED_{\mathit{last}}}$; $\epsilon$;}
\Output{Boolean whether the outer loop should continue}

\Initialize{$\mathit{events}_{\mathit{real}} \gets$ \{\}; $\mathit{events}_{\mathbf{noop}} \gets$ \{\};}

\Indp
\Algorithm{}
\Indp

\If{$\mathit{Scheduler}$ has no more unexecuted events} {
    \Return $\mathtt{false}$\;
}

\For{$\mathit{message}$ in $\mathit{Queue}$} {
    Pop $\mathit{message}$\;
    \For{$\mathit{event}, t_{\mathit{execution}}$ in $\mathit{message}$} {
        Set $\assign(\mathit{event}) = t_{\mathit{execution}}$ in $\mathit{Scheduler}$\;
    }
    $\mathit{RTED_{\mathit{last}}} \gets \varnothing$\;
}

$\mathit{RTED} \gets$ a new RTED from $\mathit{Scheduler}$; \Comment{Equations \ref{eqn:rted-chi} and \ref{eqn:rted-t}}

\If{$\mathit{RTED} = \mathit{RTED}_{\mathit{last}}$} {
    \Return $\mathtt{true}$\;
}

$\mathit{RTED}_{\mathit{last}} \gets \mathit{RTED} = $\;

\If{$t_{\mathit{RTED}} - t_{\mathit{current}} > \epsilon$} {
    \Return $\mathtt{true}$\;
}

\For{$\eventnoop$ pair in $\mathit{RTED}_{\eventnoops}$} {
    \eIf{$\eventnoop[noop]$ is \textbf{true}} {
        Add $\eventnoop[x]$ to $\mathit{events}_{\mathbf{noop}}$\;
    } {
        Add $\eventnoop[x]$ to $\mathit{events}_{\mathit{real}}$\;
    }
}

Asynchronously send all $\mathit{events}_{\mathit{real}}$ to the $\mathit{Driver}$\;

\For{$\mathit{event}$ in $\mathit{events}_{\mathbf{noop}}$} {
    Set $\assign(\mathit{event}) = t_{\mathit{RTED}}$ in $\mathit{Scheduler}$\;
}

\Return $\mathtt{true}$\;

\caption{The inner loop of the dynamic dispatching algorithm.}
\label{alg:dispatcher-inner}
\end{algorithm}
#+end_export

The biggest contributor to the performance of the inner loop, Algorithm [[alg:dispatcher-inner]], is
updating the schedule. Assuming the $\mathit{Scheduler}$ is the Delay Scheduler described in Section
[[sec:delay-scheduler]], then performing an assignment of an event will trigger the FAST-EX update that
runs in $O(N^{3})$ [cite:@Hunsberger2016 p144] with the number of events in the STNU. In the worst
case, all events in the STNU arrive at the same time, whether as messages from the driver in the
FIFO queue, or RTED =noop= events. Thus, the dynamic dispatcher's inner loop runs in $O(N^{4})$.

*** Observing Contingent Events
<<sec:event-observations>>

The dispatcher relays contingent event observations to the scheduler. In the base case, when a
contingent event is observed, the dispatcher updates the schedule with the event and current clock
time. If this were the only responsibility of the dispatcher when receiving a contingent event, we
would end the section here. However, this interface is also where we implement an /Optimistic
Rescheduling/ technique to address a problem inherent to the buffering performed by the Delay
Scheduler.

# Now that we have a complete picture of the relationship between the scheduler, dispatcher, and
# driver,

We describe Optimistic Rescheduling below and present the full contingent event
observation algorithm.

**** Optimistic Rescheduling
<<sec:optimistic-rescheduling>>

We return to problem of potentially unnecessary wait time created by the buffering execution
strategy described in Lemma [[lemma:buffering-imagining]]. First, we use an example to demonstrate how
buffering early contingent events results in a reduction of the execution space. Then we contribute
a technique for managing event observations that circumvents the loss of execution space.

Consider the following variable-delay controllable STNU, which we will refer to as
$\mathit{Bufferable}$.

$$
\vdelayedge{A}{B}{[1, 7]}{[1, 3]}
\edge{}{C}{[5, 9]}
$$

Following the semantics of the delay scheduler, we would first transform $\mathit{Bufferable}$ to
its fixed-delay equivalent, $\mathit{Bufferable}'$ by applying Lemma [[lemma:main-tightening]].

$$
\fdelayedge{A'}{B'}{[4, 8]}{0}
\edge{}{C'}{[4, 6]}
$$

# TODO what's wrong with the latex at the end of this paragraph?
# TODO clean up writing and explanation. point out difference in times
If we assume $A$ is executed at $t = 0$, the only question is when to schedule $C$ (or its
fixed-delay equivalent, $C'$). According to the semantics of $\mathit{Buffering}$, if $B$ is
observed at $t = 2$, we know that $B$ was assigned at $t = 1$. Thus, we only need to wait until $t =
6$ to schedule $C$. However, the delay scheduler would schedule according the constraints found in
$\mathit{Buffering}'$, wherein $\assign(B') = 2$ falls earlier than the lower bound of
$\conedge{A'}{B'}{[4, 8]}$, triggering Lemma [[lemma:buffering-imagining]]. As a result, we act as if
$\assign(B') = 4$ and then wait for the lower bound of $\edge{B'}{C'}{[4, 6]}$. The end result is
that $C'$ is assigned to a later time of $t = 8$.

From a human mission manager perspective, this wait appears to be a waste. Time is money. And in the
case of planetary exploration, time is safety. If a NASA flight controller were to ask why your
software is telling astronauts on Moon to just stand there doing nothing, responding that your
algorithm /does not know/ if it is safe to act, would be unacceptable. Therefore, we contribute a
generate-and-test approach that looks for opportunities to avoid buffering when contingent events
arrive before their expected windows in the fixed-delay STNU. The goal of this method is to dispatch
future events earlier if possible.

# We can see that the full execution space for $C$ is $[1, 7] + [5, 9] = [6, 16]$.

# TODO include a diagram used in group meeting that highlights the gaps at either end of the VDC->FDC translation

At its core, Optimistic Rescheduling consists of copying the original variable-delay STNU then
rewriting it to reflect the resolution of uncertainty so far. Key to rewriting the variable-delay
STNU is narrowing the constraint and observation delay to match what was observed. We then
re-perform controllability checks. If controllable, we have a new schedule that removes the need to
buffer this contingent event. If not controllable, we do nothing, buffer the contingent event as
planned, and continue dispatching against the original schedule.

We now step through the Event Observations with Optimistic Rescheduling algorithm (Algorithm
[[alg:optimistic-rescheduling]]) in detail.

# TODO should be looping over observations in order!

#+label: alg:optimistic-rescheduling
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Event Observations with Optimistic Rescheduling}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{Original VDC STNU $S$; Equivalent fixed-delay function $\gamma$\; Partial history $\xi$; Executed events map $\mathit{Ex}(S, x)$; Observed contingent event $x$; Normalized lower bound $\hat x$; Current time $t$;}
\Output{Boolean whether $x$ was successfully scheduled, VDC STNU}

\Indp
\Algorithm{}
\Indp

$\mathit{successp}, \mathit{bufferedp} \gets \mathtt{updateSchedule(S, x, t)}$\;

\If{$\neg \mathit{bufferedp}$} {
    \Return $\mathit{successp}, S$\;
}

$S^{\ast} \gets \mathtt{rewriteSTNU(S, x, t)}$\;

\If{$S^{\ast}$ is not variable-delay controllable} {
    \Return $\mathit{successp}, S$\;
}

\For{$\mathit{a}$ in $\xi$ \Comment{$\mathit{a}$ is an assignment}} {
    \If{$\gamma(\mathit{a[event]}) \neq \infty$} {
        $\mathtt{updateSchedule(\mathit{S^{\ast}}, \mathit{a[event]}, \mathit{a[time]} + \gamma(\mathit{a[event]}))}$;
    }
}

\For{$\mathit{event}$ in $\mathit{Ex(S)}$} {
     $\mathit{Ex}(S^{\ast}, x) \gets \mathit{Ex}(S, x)$
}

$\mathtt{updateSchedule(\mathit{S^{\ast}}, \hat x, t)}$\;
$\mathtt{updateSchedule(\mathit{S^{\ast}, x, t)}$\;

\Return $\mathtt{true}, S^{\ast}$\;

\caption{An Algorithm for observing contingent events with Optimistic Rescheduling.}
\label{alg:optimistic-rescheduling}
\end{algorithm}
#+end_export

We cannot know if an event is buffered if we do not attempt to schedule it. Our first step is to
schedule an event like normal. If scheduling is possible without buffering, we simply return whether
scheduling was successful.

If the event was buffered, then we begin to optimistically reschedule. We do so by tightening the
bounds of the original VDC STNU, $S_{\mathit{original}}$, based on the observation we received,
which is the responsibility of Algorithm [[alg:rewrite-stnu]], implementing Lemma [[lemma:narrow-bounds]].

If the rewritten STNU, $S^{\ast}$, is found to be VDC, we prepare to schedule it. First we iterate
through all the assignments in the partial schedule and make the same assignments against the new
STNU. When assignments are made, we subtract out the fixed observation delay. In this loop, we add
the observation delay back, lest it be subtracted from the original observation twice.

If any contingent events with infinite delay were observed, they would have been marked executed but
not assigned. We iterate through the executed events of $S$ and mark the same events executed in
$S^{\ast}$.

The distance graph, partial schedule, and executed events of $S^{\ast}$ now match that of $S$ before
$x_{c}$ was received. We are almost safe to record a new observation. Lastly, we must address the
executable event representing the normalized lower bound of $x_{c}$, $\hat x_{c}$. During
scheduling, we would have received an RTED consisting of $\langle l + \gammabar^+(x_{c}), \hat x_{c}
\rangle$. Given that $x_{c}$ arrived before $l + \gammabar^+(x_{c})$, we never would have assigned
$\hat x_{c}$, so we assign $\assign(\hat x_{c}) = t$ now. We finally update the schedule with the
contingent event that arrived.

#+label: lemma:narrow-bounds
#+latex: \begin{lemma}
#+latex: \label{lemma:narrow-bounds}
If a contingent event, $x_{c} \in X_{c}$, where $u - l > \gammabar^+(x_{c}) - \gammabar^{-}(x_{c})$,
is observed at time $t$ and when $t < l + \gammabar^+(x_{c})$, we may replace $x_{c}$ and
$\gammabar(x_{c})$ with a constraint, $x_{c}^{\ast}$, and variable-delay function,
$\gammabar(x_{c}^{\ast})$, with narrower bounds as follows.

\begin{align*}
x_{c}^{\ast} &= [l^{\ast}, u^{\ast}] \\
x_{c}^{\ast} &= [\max(l, t - \gammabar^+(x_{c})), \min(u, t - \gammabar^{-}(x_{c}))] \\
\gammabar(x_{c}^{\ast}) &= [\max(\gammabar^{-}(x_{c}), t - u), \min(\gammabar^+(x_{c}), t - l)]
\end{align*}
#+latex: \end{lemma}

#+latex: \begin{proof}
Buffering is only possible if the conditions of Lemmas [[lemma:main-tightening]] and
[[lemma:buffering-imagining]] are triggered. By Lemma [[lemma:main-tightening]], we are guaranteed to be
able to narrow where in the range $[l, u]$ $x_{c}$ was scheduled. By Lemma
[[lemma:buffering-imagining]], we know that rewritten bounds will lead to an assignment of $x_{c}$ that
is no later than $l + \gammabar^{+}(x_{c})$. Our tool for narrowing the bounds is Equation
[[eqn:fixed-recording]], which allows us to use the observation to reason over the assignment and
observation delay. Our strategy is to look at the extreme cases leading to an observation.

We start by reasoning over the earliest and latest assignments respectively. In order for $x_{c}$ to
be assigned as early as possible, $l^{\ast}$, we assume the delay has taken on its maximum value,
$\gammabar^+(x_{c})$.

\begin{align}
\assign(x_{c}) &= \obs(x_{c}) - \gamma(x_{c}) \\
l^\ast &= t - \gammabar^+(x_c) \label{eqn:l-ast}
\end{align}

Likewise, to find the last possible assignment leading to an observation, we subtract the smallest
observation delay, $\gammabar^{-}(x_{c})$.

\begin{align}
u^\ast = t - \gammabar^-(x_c) \label{eqn:u-ast}
\end{align}

Given that Nature will adhere to the constraints originally put forth in $S$, the bounds of
$x_{c}^{\ast}$ must remain within the bounds of $x_{c}$. Hence, we guarantee the lower bound is at
least $l$ while the upper bound is at most $u$.

\begin{align*}
l^\ast &= \max(l, t - \gammabar^+(x_c)) \\
u^\ast &= \min(u, t - \gammabar^-(x_c))
\end{align*}

We use the same logic for narrowing the observation delay. If $x_{c}$ was assigned as late as
possible, $u$, then the observation delay would be minimized, $\gammabar^-(x_{c}^{\ast})$. Likewise,
if $x_{c}$ was assigned as early as possible, $l$, the observation delay would be maximized,
$\gammabar^+(x_{c}^{\ast})$. The narrowed lower and upper bounds of $\gammabar(x_{c})^{\ast}$ are as
follows.

\begin{align*}
\gamma &= \obs(x_{c}) - \assign(x_{c}) \\
\gammabar^-(x_{c}^{\ast}) &= t - u \\
\gammabar^+(x_{c}^{\ast}) &= t - l \\
\end{align*}

As before, the bounds of $\gammabar(x_{c}^{\ast})$ must stay within the original bounds of
$\gammabar(x_{c})$, leaving us with the following narrowed observation delay.

\begin{align}
\gammabar^-(x_{c}^{\ast}) &= \max(\gammabar^{-}(x_{c}), t - u) \\
\gammabar^+(x_{c}^{\ast}) &= \min(\gammabar^+(x_{c}), t - l)
\end{align}
#+latex: \end{proof}

We revisit the example from the beginning of this section to see Lemma [[lemma:narrow-bounds]] in
action. As we saw before, any $\obs(B)$ before $t = 4$ will result in buffered assignments.

$$
\vdelayedge{A}{B}{[1, 7]}{[1, 3]}
\edge{}{C}{[5, 9]}
$$

Let $t = 3$. We will step through the reasoning for narrowing the bounds of $x_{c}$ accordingly.

\begin{align*}
x_{c}^{\ast} &= [\max(l, t - \gammabar^+(x_{c})), \min(u, t - \gammabar^{-}(x_{c}))] \\
x_{c}^{\ast} &= [\max(1, 3 - 3), \min(7, 3 - 1)] \\
x_{c}^{\ast} &= [1, 2] \\
\\
\gammabar(x_{c}^{\ast}) &= [\max(\gammabar^{-}(x_{c}), t - u), \min(\gammabar^+(x_{c}), t - l)] \\
\gammabar(x_{c}^{\ast}) &= [\max(1, 3 - 7), \min(3, 3 - 1)] \\
\gammabar(x_{c}^{\ast}) &= [1, 2]
\end{align*}

We find that $\assign(x_{c})$ must have fallen somewhere in the range of $[1, 2]$, while
$\gammabar(x_{c})$ was resolved somewhere in $[1, 2]$. Looking at the extremes, it is clear that
there are multiple combinations of the assignment and observation delay that could lead to an
observation at $t = 3$. While the narrowed range allows for observations other than $t = 3$, for
instance, if $\assign(x_{c}) = 2$ and $\obs(x_{c}) = 2$ yielding an observation at $t = 4$, there
are no other ranges of assignments or observation delay outside of $\assign(x_{c}) \in [1, 2]$ and
$\gammabar(x_{c}) \in [1, 2]$ that would allow an observation at $t = 3$.

#+label: alg:rewrite-stnu
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Rewrite STNU}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{VDC STNU $S_{\mathit{original}}$; Variable-delay function $\gammabar$\; Observed contingent event $x$; Observation time $t$;}
\Output{VDC STNU}

\Initialize{$S_{\mathit{new}} \gets \mathtt{copy}(S_{\mathit{original}})$}

\Indp
\Algorithm{}
\Indp

\For{$\mathit{constraint}$ in $S_{\mathit{new}}$} {
    \If{$\mathit{constraint}$ ends in $x$} {
        $\mathit{constraint}[lower] \gets \max(\mathit{constraint}[lower], t - \gammabar^{+}(x))$\;
        $\mathit{constraint}[upper] \gets \min(\mathit{constraint}[upper], t - \gammabar^{-}(x))$\;
        $\gammabar^{-}(x) \gets \max(\gammabar^{-}(x), t - \mathit{constraint}[upper])$\;
        $\gammabar^{+}(x) \gets \max(\gammabar^{+}(x), t - \mathit{constraint}[lower])$\;
    }
}

\Return $S_{\mathit{new}}$\;

\caption{An Algorithm for rewriting an STNU given the resolution of uncertainty of a contingent link.}
\label{alg:rewrite-stnu}
\end{algorithm}
#+end_export

The complexity of Algorithm [[alg:optimistic-rescheduling]] is dominated by the loop over
=updateSchedule=. Each call to =updateSchedule= is $O(N^{3})$ in the number of events. In the worst
case scenario, every event up to the last contingent event has been scheduled, giving us a
complexity of $O(N^{4})$. We discuss potential means for improving Optimistic Rescheduling in
Section [[sec:discussion-optimistic-rescheduling]].

** Experimental Analysis
<<sec:scheduling-experimental>>

Optimistic vs normal VDC scheduling

#+label: fig:dish-stnu
#+attr_latex: :width 1\textwidth
#+caption: An STNU representing the installation and test of repeater antennas. Each row represents a single astronaut. The episode durations are representative of the bounds used in simulation.
[[file:../images/dish-install-stnu.png]]

we introduce an example which models a construction task on the lunar surface. This scenario depicted with the STNU in Figure \ref{fig:dish-stnu} represents an EVA wherein $i$ astronauts are each installing $j$ surface signal repeater antennas. During the activity, every astronaut is responsible for installing one repeater. %Each event, $X$, is represented for the $i$-th astronaut and $j$-th repeater as $X_{i,j}$.

The astronauts work in parallel, with a $[0, \infty)$ requirement link from the start of the STNU to each $A_{i,1}$ (not shown). The first episode, $\conedge{A_{i,j}}{B_{i,j}}{}$, represents traversing to the site of the installation. We model traverses as uncontrollable due to the fact that crews are embarking across unknown terrain. Once at the site, an antenna is installed as represented by $\edge{B_{i,j}}{C_{i,j}}{}$. Each repeater needs to have its configuration tested and confirmed working by $D_{i,j}$, represented by the edge $\conedge{C_{i,j}}{D_{i,j}}{}$. Confirmation takes the form of a request-response cycle to the ground. We model $D_{i,j}$ as uncontrolled and with variable delay because each antenna takes an unknown time to self-configure and the crew does not know when they will receive a response from MCC that the repeater installation has been verified due to uncertainty in communication. Bandwidth is limited, so we limit the number of repeaters simultaneously sending requests to their configuration. We use the $\edge{D_{i,j}}{C_{i+1,j}}{}$ links to enforce that the start of the confirmation of the next repeater does not begin until after the previous repeater's confirmation. Confirmations are required until we reach the last crew member or the last activity. Once testing is complete, the astronauts clean up their workstations, $\edge{D_{i,j}}{A_{i,j+1}}{}$ and then repeat the cycle until all antennas have been installed.
