#+title: Technical Scheduling

* COMMENT
:PROPERTIES:
:startup: content
:END:
** TODO consistency with "noop"
is it =noop= or =no-op= or $\mathit{noop}$ or /noop/ or /no-op/?
** TODO consistency with capitalization and italics of Scheduler, Delay Scheduler, Dispatcher, Driver
** TODO we need an =updateSchedule= algo defined in the execution strategy section
include the fact that it returns if an event is buffered
** TODO clean up fast-ex algos
- [ ] double check accuracy!
- [ ] weird italics
- [ ] check for loop usage
** TODO fix:observations is weird. fix notation, caption
** TODO RTED defn is missing info in the scheduler section. also check it is accurate wrt code
** extra content 1
Bhargava et al. [cite:@Bhargava2018] addressed this ambiguity in contingent event assignment by
first transforming the VDC STNU into a controllability-equivalent fixed-delay STNU. With fixed
observation delay, we /do/ have the guarantee that we learn the exact assignment of contingent
events (so long as the observation delay is not infinite). Thus, scheduling a fixed-delay STNU only
differs from scheduling a vanilla STNU in that we must subtract a fixed observation delay when we
make contingent event assignments. Otherwise, the dispatchable form is the same as in the case of a
vanilla STNU, and we can choose any STNU scheduling algorithm to generate execution decisions.

# TODO explain "execution space" earlier?
# TODO wc "tractable"
The flow from variable-delay STNU to fixed-delay STNU to dispatchable form may appear sufficient to
enable scheduling of variable-delay STNUs, but we must contend with a novel issue: the execution
spaces of the original variable-delay STNU and its transformed fixed-delay equivalent are
mismatched. Nature is obliged to respect the uncertainties of the original variable-delay STNU. As
will be shown later, the fixed-delay equivalent reduces the execution space to make the
controllability check tractable. As such, we may receive observations outside the range of the
contingent links in the fixed-delay STNU, which we must reconcile with the dispatchable form. See
Figure [[fig:flow-chart]] for an overview of the information flow in scheduling a variable-delay STNU.
** old explanation of buffering and imagining
Next, in comparing the bounds of $x_{c}$ and $x'_{c}$ when $u - l \geq \gammabar^+(x_c) -
\gammabar^-(x_c)$, $x'_{c} \in [l^+(x_{c}), u^-(x_{c})]$ (Lemma [[lemma:main-tightening]]) there are
three regimes of observations of $\obs(x_{c})$ we must consider:

# TODO might be wordy
Nature decides in which regime we receive $\obs(x_{c})$. We are faced with the unique challenge of
deciding how to act when Nature selects an $\obs(x_{c})$ that fails to follow the constraints of
$S'$, eg. $\obs(x_{c}) < l^+(x_{c}) \lor \obs(x_{c}) > u^-(x_{c})$, which would lead to an
assignment, $\assign(x'_{c})$, in the first or third regimes above. In plainer words, the contingent
links of $S$ and $S'$ do not have the same constraints. We make assignments in $S'$, but we receive
observations from $S$. We need to decide how to act when we observe a contingent event earlier or
later than we expect according to $S'$, because if we blindly assigned $\assign(x'_{c})$ outside its
constraints from $S'$, we lose the guarantee of controllability. Our only choice is to find a
strategy to assign $x'_{c}$ that respects the constraints of $S'$, despite observing $x_{c}$ earlier
or later than expected. We do so by reasoning over the possible /range/ of assignments,
$\assign(x_{c})$, that could have led to a particular observation, $\obs(x_{c})$. What we find is
that, due to the uncertainty in observation delay, we are allowed to /modify/ our assignment of
$\assign(x'_{c})$ to ensure it respects $S'$. We present two modification strategies for addressing
the first and third cases, which we call /buffering/ and /imagining/ respectively.

We first address the case where $\obs(x_{c}) < l^+(x_{c})$. As shown in Lemma
[[lemma:buffering-imagining]], buffering is a valid execution strategy for early observations.

#+label: lemma:buffering
#+latex: \begin{lemma}
#+latex: \label{lemma:buffering}
If a contingent event, $x_{c} \in X_{c}$, is observed earlier than the bounds of $x'_{c}$ in $S'$
for a fixed-delay controllable $S'$, $\obs(x_{c}) < l^+(x_{c})$, we perform a /buffering/ operation
by letting $\assign(x'_{c}) = l^+(x_{c})$ in $S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
# Our strategy is to artificially assign \assign(x'_{c}) \in [l^+(x_{c}), l^+(x_{c})]$, or, in other
# words, /buffer/ it.

# TODO ditch g(x_c) in graph
# TODO subscripts and superscripts look like garbage in g docs
To demonstrate why buffering is sound, we compare the bounds of $x_{c}$ in $S$ and $x'_{c}$ in $S'$
to show that our execution strategy for $\assign(x'_{c})$ is applicable to any $\assign(x_{c}) \in
[l, l^+(x_{c})]$.

We know that $S'$ is fixed-delay controllable when $\assign(x'_{c}) \in [l^+(x_{c}), u^-(x_{c})]$.
Consider an observation at the lower bound of $\assign(x'_{c}), $\obs(x_{c}) = l^+(x_{c})$. We can
discern the range of possible assignments of $x_{c}$ in $S$ (Using Lemma
[[lemma:information-fixes-bounds]] to rewrite $o(x_{c}) = l^+(x_{c})$ as $o(x_{c}) = [l^+(x_{c}),
l^+(x_{c})]$).

#+begin_export tex
\begin{align*}
\obs(x_{c}) &= \assign(x_{c}) + \gammabar(x_{c}) \\
\assign(x_{c}) &= \obs(x_{c}) - \gammabar(x_{c}) \\
\assign(x_{c}) &= [l^+(x_{c}), l^+(x_{c})] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_{c}) &= [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c}))]
\end{align*}
#+end_export

Let $\alpha = [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c}))]$ for this Lemma.

Given $S'$ is fixed-delay controllable, there must exist an execution strategy when $\assign(x'_{c})
= l^+(x_{c})$, which entails the same execution strategy applies for any assignment of
$\assign(x_{c}) \in \alpha$. Thus, during execution, if we can show that $\assign(x_{c}) \subseteq
\alpha$, we can safely act as if $\assign(x'_{c}) = l^+(x_{c})$.

Now, let $\obs(x_{c}) = l^+(x_{c}) - \epsilon$ for some small, positive $\epsilon$. Accordingly, it
is the case that $\assign(x_{c})$ must fall in the range,

#+begin_export tex
\begin{align*}
\assign(x_{c}) &= [(l^+(x_{c}) - \epsilon) - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_c) &= [l^+(x_{c}) - \epsilon, l^+(x_{c}) - \epsilon] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\assign(x_c) &= [l - \epsilon, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]
\end{align*}
#+end_export

Of course, $\assign(x_{c})$ must respect the original bounds of $x_{c}$, $x_{c} \in [l, u]$.

#+begin_export tex
\begin{align*}
\assign(x_c) &= [l - \epsilon, l + \gammabar^+(x_{c}) - \gammabar^-(x_{c}) - \epsilon] \cap [l, u]
\assign(x_c) &= [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]
\end{align*}
#+end_export

Let $\beta = [l, l + (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) - \epsilon]$ for this Lemma. See
Figure [[fig:observations]] for a visual representation of how an observation $\obs(x_{c})$ is
interpreted as an assignment \assign(x'_{c})$ during scheduling.

We see that $\beta \subset \alpha$. Thus, if we receive an observation $\obs(x_{c})$ earlier than
$l^+(x_{c})$, we may safely buffer by applying the execution strategy from an assignment of
$\obs(x_{c}) = \assign(x'_{c}) = l^+(x_{c})$.
#+begin_export tex
\end{proof}
#+end_export

Next,we address the case where $\obs(x_{c}) > u^-(x_{c})$.

#+label: lemma:imagining
#+begin_export tex
\begin{lemma}
\label{lemma:imagining}
If a contingent event, $x_{c} \in X_{c}$, will be observed after the bounds of $x'_{c}$, $\obs(x_{c}) > u^-(x_{c})$, we \textit{imagine} we have received it by assigning $\assign(x'_{c}) = u^-(x_{c})$ in $S'$.
\end{lemma}
#+end_export

#+begin_export tex
\begin{proof}
#+end_export
We apply the same argument to /imagining/ late events. We now consider an observation at the upper
bounds of $x'_{c}$, $\obs(x_{c}) = \assign(x'_{c}) = u^-(x_{c})$. We then have a new $\alpha$
representing the range of the earliest and latest assignments to $\assign(x_{c})$,

#+begin_export tex
\begin{align*}
\alpha &= u^-(x_{c}) - g(x_{c}) \\
       &= [u^-(x_{c}), u^-(x_{c})] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \\
\alpha &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})), u]
\end{align*}
#+end_export

Once again, if $S'$ is fixed-delay controllable, there must exist an execution strategy for
$\assign(x'_{c}) = u^-(x_{c})$. It follows that we can apply this execution strategy when
$\assign(x_{c}) \in \alpha$.

If we receive a late observation, $\obs(x_{c}) = u^-(x_{c}) + \epsilon$, we find that
$\assign(x_{c})$ must fall in the range of a new $\beta$, where

#+begin_export tex
\begin{align*}
\beta &= \left[ (u^-(x_{c}) + \epsilon) - g(x_{c}) \right] \cap [l, u] \\
      &= \left[ [u^-(x_{c}) + \epsilon, u^-(x_{c}) + \epsilon] - [\gammabar^-(x_{c}), \gammabar^+(x_{c})] \right] \cap [l, u] \\
      &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) + \epsilon, u + \epsilon] \cap [l, u] \\
\beta &= [u - (\gammabar^+(x_{c}) - \gammabar^-(x_{c})) + \epsilon, u]
\end{align*}
#+end_export

We find that $\beta \subset \alpha$ again and can safely imagine that we received $\obs(x_{c}) =
u^-(x_{c})$. Of course, we need not wait to receive a late observation of $x_{c}$ only to assign it
to a time in the past. During execution, if we have not received $\obs(x_{c})$ by $u^-(x_{c})$, we
imagine an observation arrived at $\obs(x_{c}) = u^-(x_{c})$ and thus assign $\assign(x'_{c}) =
u^-(x_{c})$. We then ignore the real observation of $x_{c}$ that we receive later.
#+begin_export tex
\end{proof}
#+end_export

** extra content 2 - analogy
To solidify the process of scheduling a variable-delay STNU, consider the following analogy.

#+begin_quote
Alex wants to go hiking in the woods. The area is unfamiliar to them, so they ask their friend, Sam,
who hiked these trails a long time ago, to give them directions to traverse from the trailhead to a
particularly spectacular overlook. Sam has a working idea of the trail map, but their memory is
imperfect. Regardless, they guarantee Alex that their directions will lead Alex to the overlook even
if the woods have changed over the years. Sam writes down directions like "turn left after 500
meters at the giant oak tree" and "turn right after 100 meters when you see the brook." Alex knows
that Nature will not necessarily obey Sam's directions. They may observe a giant oak tree earlier
than expected, so they must then wait to take the next trail going left. Or the brook may have dried
up, so they imagine they saw one near where Sam thought it would be and take the next right. While
hiking, Alex is charged with reconciling Sam's directions with their own observations. Even though
they may identify the landmarks in Sam's directions earlier or later than expected, their actions
will need to follow Sam's instructions to maintain the guarantee of reaching the overlook.
#+end_quote

In our analogy, $S$ models the current state of the hiking trails and the full range of projections,
while $S'$ is Sam's working memory of them. Sam's directions are the execution strategy described by
the AllMax graph we get by checking the fixed-delay controllability of $S'$. Observations of Nature
obey $S$. Alex is charged with reconciling their observations from $S$ with Sam's hiking directions
from $S'$. The analogy ends here, though, as the math and logic of temporal reasoning do not neatly
translate into hiking. Luckily, we have more information than Alex. Unlike human memory, which is
untrustworthy and irrational, the fixed-delay STNU, $S'$, is created by a set of Lemmas with
deterministic outcomes. As such, we have the means to interpret how observations in $S$ /would
appear/ in $S'$, which will be critical in adapting our fixed-delay execution strategy in response
to variable observation delay.

Our key challenge for scheduling an STNU with variable observation delay is reconciling observations
from $S$ with the dispatchable form from $S'$.

During execution, we observe the outcome of contingent events $\obs(x_{c})$ in $S$, but we make
assignments in the dispatchable form of $\assign(x'_{c})$ in $S'$. Despite being equivalent with
respect to controllability, the bounds of contingent links $x_{c}$ in $S$ and $x'_{c}$ in $S'$ are
not equivalent.
** extra content about the dispatcher
# TODO is the salient point here RTEDs? or is there something else that's more important about the
# relationship between the dispatcher and the scheduler?
This thesis contributes a dynamic dispatching algorithm for which the process of generating RTEDs is
a subroutine. As such, a dedicated dispatcher layer is required to
translate RTEDs to real actions at the right time. The dispatcher will request RTEDs and then wait
until the time window of the execution to trigger their execution.

# This thesis contributes a novel dispatching algorithm that works with any dynamic scheduler.

# TODO these paragraphs need to be cleaned up and streamlined

# scheduler doesn't do any "extraneous" jobs (extraneous is a good word. use it?)
A /dynamic dispatcher/ (or just "dispatcher") is an interface layer situated between the scheduler
and a /driver/ that communicates with hardware. The dispatcher has a two-fold responsibility: it
triggers the execution of RTEDs in the outside world by communicating with the driver (Section
[[sec:dynamic-dispatching]]), and it relays observations from the outside world about the execution of
events to the scheduler (Section [[sec:event-observations]]). An explicit dispatching layer allows us to
centralize the logic for interacting with the outside world therein, keeping the scheduler simple.
In the implementation of Kirk used in this thesis, the scheduler wholly consists of the algorithms
described above, nothing more. We go so far as to enforce that the scheduler itself has no notion of
a clock. Instead, the dispatcher has a clock. When the dispatcher wants the scheduler to update
itself, it is required to send both an event and a elapsed time to the scheduler.

Consequently, the dispatching algorithm is separate from the scheduler. As such, there is no hard
requirement on the FAST-EX-based scheduler described above. Any scheduling algorithm that produces
RTEDs adhering to Definition [[def:rted-op]] would be compatible with the dispatcher described below.

** I think VDC->FDC algo? not sure why this was here
Let $x$ be a temporal event, $x \forall x \in X_{c} \cup X_{e}$.

#+begin_export tex
\begin{algorithm}[H]
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{VDC-FAST-EX-Update}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{AllMax Graph $G$; fixed-delay function $\gamma(x'_{c})$; Observation $\obs(x_{c})$}
\Output{Updated AllMax Graph $G$}
\Initialize{}
\Indp
\Indm
\Algorithm{}
\Indp
\For{$l \in S'.contingentLinks()$} {
    $x_c \leftarrow l.endpoint()$\;
    $a, b \leftarrow l.bounds()$\;
    \If{$\gammabar^+(x_c) == \infty$ or $\gammabar^+(x_c) == \gammabar^-(x_c)$} {
        $\gamma'(x_c) \leftarrow \gammabar^+(x_c)$\;
    } \ElseIf {$b - a < \gammabar^+(x_c) - \gammabar^-(x_c)$} {
        $\gamma'(x_c) \leftarrow \infty$\;
    }
    \Else {
        $l.setBounds(a + \gammabar^+(x_c), b + \gammabar^-(x_c))$\;
        $\gamma'(x_c) \leftarrow 0$\;
        \For{$l' \in x_c.outgoingReqLinks()$} {
            $u, v \leftarrow l'.bounds()$\;
            $l'.setBounds(u - \gammabar^-(x_c), v - \gammabar^+(x_c))$\;
        }
        \For{$l' \in x_c.incomingReqLinks()$} {
            $u, v \leftarrow l'.bounds()$\;
            $l'.setBounds(u + \gammabar^+(x_c), v + \gammabar^-(x_c))$\;
        }
    }
}
\Return $S', \gamma'$
\caption{Algorithm for updating the AllMax graph when an observation arrives}
\label{alg:conversion}
\end{algorithm}
#+end_export
** something about practicalities of string event-ids
While we made a careful distinction between $x_{c}$ and $x'_{c}$ in our discussion of scheduling, in
our implementation it was important to be able to easily replace one with another when looking up
values in hash-tables and lists. For instance, to implement Equation [[eqn:fixed-recording]], we receive
$x_{c}$ but key the fixed-delay function on $x'_{c}$. Rather than adding an additional translation
layer, we give each temporal event in $S$ a unique name, all of which get copied to their equivalent
events in $S'$. Hash-tables are keyed on event names, vastly simplifying lookups in the AllMax
graph, delay function, and elsewhere.
** TODO fix dish install diagram
- [ ] doesn't need lambda
- [ ] the dashed circles need to be swapped! wrong events are highlighted as contingent!!!

* Scheduling Events Despite Uncertain Observations
<<ch:delay-scheduling>>

Now that we have shown there exists a valid execution strategy for variable-delay controllable
STNUs, we contribute a novel scheduling and dispatching architecture for online, dynamic execution.
In this Chapter, our aim is to describe the single-agent form of a new instantiation of Kirk, /Delay
Kirk/, that can reason over uncertain observation delay to decide when to execute requirement events
on real hardware. There are two main components to Delay Kirk: (1) a /delay scheduler/, and (2) a
/delay dispatcher/. As will be shown in Section [[sec:delay-scheduling]], scheduling variable-delay
controllable STNUs is an extension to existing dynamic scheduling algorithms with modifications for
the execution strategy shown to be sound and complete in Chapter [[ch:modeling-tn]].

Additionally, to the best of our knowledge, scheduling fixed-delay STNUs has not been presented in
the literature. Fixed-delay scheduling is required for addressing (1). As such, we contribute a
fixed-delay scheduler in Section [[sec:delay-scheduling]]. The execution strategy from Chapter
[[ch:modeling-tn]] will be shown to be a small extension to the fixed-delay scheduler. As to (2), to the
best of our knowledge, there are no other formalized dispatching algorithms in the literature. In
the development of Delay Kirk, we found it to be extremely useful to formalize dispatching as part
of creating a clear interface boundary between scheduling and dispatching. The dispatching
algorithms we put forth in Section [[sec:dynamic-dispatching]] represent novel contributions to temporal
reasoning.

This Chapter makes additional contributions to scheduling and dispatching. Safely executing events
on real hardware requires modifications to generating decisions in dynamic scheduling. We include
said modifications, with confluent interfaces in dynamic dispatching, to suit our intended use cases
for Delay Kirk.

# TODO maybe?
In Section [[sec:optimistic-rescheduling]], we extend our approach to scheduling variable-delay STNUs by
introducing an optional procedure that addresses a shortcoming in the semantics of scheduling a
variable-delay STNU. The shortcoming takes the form of potentially unnecessary wait times that are
added after receiving contingent event assignments, extending the makespan of procedures. We present
a generate-and-test algorithm to partially mitigate said shortcomings.

Finally, Section [[sec:scheduling-experimental]] provides a series of benchmarks of the scheduling and
dispatching algorithms described in this Chapter.

** Dynamic Scheduling through Real-Time Execution Decisions
<<sec:dynamic-scheduling>>

We first provide a necessary overview of dynamic scheduling of vanilla STNUs, which we will extend
for STNUs with observation delay in Section [[sec:delay-scheduling]].

An STNU, $S$, that exhibits dynamic controllability can be /scheduled/ dynamically (or /online/). At
a high-level, dynamic scheduling is the process of mapping the history of event assignments to the
execution time of future free events. We will build off of the scheduling work by Hunsberger
[cite:@Hunsberger2013;@Hunsberger2016], which describes an $O(N^{3})$ online procedure, FAST-EX, for
dynamic scheduling of STNUs. We chose FAST-EX because, to the best of our knowledge, this is the
fastest dynamic scheduling algorithm in the literature today. At its core is the notion of
/Real-Time Execution Decisions/ (RTEDs), which map a time to a set of requirement events to be
executed and are generated based on /partial schedules/ of STNUs being executed. =WAIT= decisions
may also be produced, reflecting the need to wait for the assignment of a contingent event before
continuing. RTED-based scheduling applies a dynamic programming paradigm in three steps:

# TODO why did I use Hunsberger2009 here? not 2016?
1. creating a dispatchable form of temporal constraints offline in the form of a distance graph,
2. updating the dispatchable form as the partial schedule is updated online through event
   assignments, and
3. querying the dispatchable form online to quickly find the next RTED [cite:@Hunsberger2009].

The dispatchable form employed by FAST-EX is the /AllMax/ distance graph, which is first described
in the Morris $O(N^{4})$ DC-checking procedure [cite:@Morris2006].

#+latex: \begin{defn}
*AllMax Distance Graph* [cite:@Morris2005]

The /AllMax/ distance graph is a distance graph exclusively consisting of unlabeled and upper-case
edges.
#+latex: \end{defn}

The key idea of FAST-EX is maintaining accurate distances from an artificial zero point, $Z$, of the
distance graph to all events. At the outset of execution, all events from $S$ are present as nodes
in /AllMax/. As events are assigned, /AllMax/ performs update steps using Dijkstra Single
Source/Sink Shortest Path (SSSP) to maintain distances to unexecuted events, while also collapsing
executed events to $Z$. We include pseudo-code of the real-time update step in Figure
[[alg:fast-ex-update]].

# TODO define replacement edge. maybe 1-3 sentences at most

#+label: alg:fast-ex-update
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{FAST-EX Update}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{Time $t$; Set of newly executed events $\texttt{Exec} \subseteq X_{e} \cup X_{r}$; AllMax Graph $G$; Distance matrix $D$, where $D(A, B)$ is the distance from $A$ to $B$}
\Output{Updated $D$}
\Indp
\Algorithm{}
\Indp
\For{each contingent event $C \in \texttt{Exec}$} {
    Remove each upper-case edge, $\edge{Y}{A}{C:-w}$, labled by $C$\;
    Replace each edge from $Y$ to $Z$ with the strongest replacement edge\;
}
\For{each event $E \in \texttt{Exec}$} {
    Add lower-bound edge $\edge{E}{Z}{-t}$\;
}
For each event $X$, update $D(X, Z)$ using Dijkstra Single-Sink Shortest Paths\;
\For{each event $E \in \texttt{Exec}$} {
    Add upper-bound edge $\edge{Z}{E}{t}$\;
}
For each event $X$, update $D(Z, X)$ using Dijkstra Single-Source Shortest Paths\;
\caption{Algorithm for updating distances for all events in relation to $Z$ upon the execution of an event. Adapated from \citeprocitem{3}{[3]}, Fig. 19.}
\label{alg:fast-ex-update}
\end{algorithm}
#+end_export

With an up-to-date distance graph in hand, we can perform an online query for the current RTED.

#+latex: \begin{defn}
*Real-Time Execution Decisions* [cite:@Hunsberger2009]

A /Real-Time Execution Decision/ is a two-tuple $\langle t, \chi \rangle$, where:
- $t$ is a time with domain $\mathbb{R}$,
- $\chi$ is a set of $x_{r} \in X_{r}$ to be executed at time $t$
#+latex: \end{defn}

Let $U_{x}$ be the set of unexecuted free timepoints. If $U_{x}$ is empty, then the RTED is to
=WAIT=. Otherwise, we find the lower bound of the earliest executable time point and the set of
executable events associated with it.

#+label: eqn:rted1
\begin{align}
t &= \min\{-D(X, Z)~|~X \in U_{x}\} \\
\label{eqn:rted-chi}
\chi &= \{X \in U_{x}~|~-D(X, Z) = t\}
\end{align}

We cannot execute events in the past. Let =now= be the current time, i.e. the last timepoint
captured in the event assignments. It is possible that $t \leq \texttt{now}$, in which case we must
reassign $t$ to guarantee that $t > \texttt{now}$. To do so, we update $t$ as follows, where $t^+$
is earliest upper bound of the executable timepoints,

#+label: eqn:rted2
\begin{align}
t^+ &= \min\{D(Z, X)~|~X \in U_{x}\} \\
\label{eqn:rted-t}
t &= \cfrac{\texttt{now} + t^+}{2}
\end{align}

So long as $t^+ > \texttt{now}$, we know that the reassignment of $t$ ensures $t > \texttt{now}$.

** Delay Scheduling as an Extension to Dynamic Scheduling
<<sec:delay-scheduling>>

#+ATTR_ORG: :width 400
#+ATTR_LATEX: :width 0.8\textwidth
#+caption: A high-level flow chart showing how we use variable-delay STNUs to generate scheduling decisions. The boxes represent the data structures involved in scheduling, while the arrows are the processes that are followed to eventually produce RTEDs.
#+label: fig:flow-chart
[[file:../images/flow-chart.png]]

Figure [[fig:flow-chart]] presents a high-level overview of the information flow in the scheduling
process.

In order to schedule a variable-delay STNU, the core problem we must address is that, to date, there
is no means to directly create a corresponding dispatchable form that accounts for uncertain
assignments resulting from variable observation delay. We encountered this same problem when
describing the process of checking VDC in Section [[sec:vdc]]. We overcame this limitation by first
transforming the variable-delay STNU to a fixed-delay STNU before checking FDC. A similar strategy
will be followed for scheduling in that we will transform the variable-delay to a fixed-delay STNU,
then dispatch events using the dispatchable form of the fixed-delay STNU instead. However, doing so
creates a second problem. While we will be performing FAST-EX against the fixed-delay STNU, the
contingent event observations we receive will adhere to the constraints and variable-delay function
of the variable-delay STNU. Hence, we must modify our real-time update and RTED generation
algorithms to account for early and late contingent event observations.

# TODO rewrite
We start by providing an explanation of fixed-delay scheduling, before expanding it to address the
execution strategies of variable-delay scheduling.

*** Fixed-Delay Scheduling

# TODO wc algebra
We first establish the algebra of receiving observations.

# TODO remind people what the primes mean

#+label: lemma:information-fixes-bounds
#+latex: \begin{lemma}
#+latex: \label{lemma:information-fixes-bounds}
For any contingent event, $x_{c} \in S$ or $x'_{c} \in S'$, observing $x_{c}$ at time $t \in
[l^-(x_{c}), u^+(x_{c})]$ fixes the observation to $\obs(x_{c}) = [t, t]$.
#+latex: \end{lemma}
#+latex: \begin{proof}

# TODO use def:schedule-as-interval?

Prior to execution, an observation of $x_{c}$ may fall anywhere within the set-bounded interval from
the earliest possible observation at $l^-(x_{c})$ to the last possible observation at $u^+(x_{c})$.
Receiving an observation $\obs(x_{c}) = t$ during execution eliminates all possible observations
outside the interval $[t, t]$.
#+latex: \end{proof}

#+label: lemma:equal-is-fixed-bounds
#+latex: \begin{lemma}
#+latex: \label{equal-is-fixed-bounds}
For any temporal constraint, $x$, with bounds $x \in [l, u]$ for some $l$ and $u$, and timepoint $t
\in [l, u]$, if information reduces the bounds of $x$ to $x \in [t, t]$, we may assert $x = t$.
#+latex: \end{lemma}

#+latex: \begin{proof}
# TODO is this sound?
When the bounds of an interval, $x \in [l, u]$ are fixed such that $t = l = u$, we can assert that
$x$ must have resolved to $t$.
#+latex: \end{proof}

#+label: lemma:subtract-gamma
#+latex: \begin{lemma}
#+latex: \label{lemma:subtract-gamma}
For any contingent event $x'_{c} \in X_{c}$ in fixed-delay controllable $S'$, if $\gamma(x'_{c}) \in
\mathbb{R}$, we assign $\assign(x'_{c}) = \obs(x_{c}) - \gamma(x'_{c})$ in the dispatchable form of
$S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
The central challenge of checking fixed-delay controllability is determining that an execution
strategy exists that allows an agent to wait an additional $\gamma(x'_{c})$ time units after a
contingent event has been assigned to learn its outcome. Importantly, the $\gamma$ function is not
used to modify the edges of the labeled distance graph, which are derived from the constraints $r
\in R_{e} \cup R_{c}$ in $S'$.

As $\gamma(x'_{c})$ resolves to a known and finite value, we can derive the true value of
$\assign(x'_{c})$ to be assigned in the labeled distance graph. Contingent event assignments are
recorded in the labeled distance graph as follows, where $\obs(x_{c})$ is the resolved observation,

#+label: eqn:fixed-recording
#+begin_export tex
\begin{align}\assign(x'_c) = \obs(x_c) - \gamma(x'_c) \label{eqn:fixed-recording}
\end{align}
#+end_export
#+latex: \end{proof}

The FAST-EX real-time update algorithm, Algorithm [[alg:fast-ex-update]], then becomes Algorithm
[[alg:fast-ex-fixed-obs]].

#+label: alg:fast-ex-fixed-obs
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{FAST-EX Update with Fixed Observation Delay}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{Time $t$; Set of newly observed events $\texttt{Exec} \subseteq X_{e} \cup X_{r}$; AllMax Graph $G$; Distance matrix $D$, where $D(A, B)$ is the distance from $A$ to $B$; Fixed-delay function $\gamma$;}
\Output{Updated $D$}
\Indp
\Algorithm{}
\Indp
\For{each contingent event $C \in \texttt{Exec}$} {
    $\assign(C) \leftarrow \obs(C) - \gamma(C)$\;
    Remove each upper-case edge, $\edge{Y}{A}{C:-w}$, labled by $C$\;
    Replace each edge from $Y$ to $Z$ with the strongest replacement edge\;
}
\For{each event $E \in \texttt{Exec}$} {
    Add lower-bound edge $\edge{E}{Z}{-t}$\;
}
For each event $X$, update $D(X, Z)$ using Dijkstra Single-Sink Shortest Paths\;
\For{each event $E \in \texttt{Exec}$} {
    Add upper-bound edge $\edge{Z}{E}{t}$\;
}
For each event $X$, update $D(Z, X)$ using Dijkstra Single-Source Shortest Paths\;
\caption{Algorithm for updating distances for all events in relation to $Z$ upon the execution or observation of an event.}
\label{alg:fast-ex-fixed-obs}
\end{algorithm}
#+end_export

No other modifications to FAST-EX are required to schedule a fixed-delay STNU.

*** Variable-Delay Scheduling

# TODO probably needs to say we're building off FDC

Our execution strategy must address each of the following special categories of contingent event
observations:

# TODO remind $S'$, which lemmas. highlight that general strategy for VDC will do FDC transformation first and it creates these two problems... ref back to prev chapters

# TODO num 1 is also a problem for fixed delay! move up

1. contingent events with infinite observation delay,
2. contingent events that are observed outside $[l^+(x_{c}), u^-(x_{c})]$ in $S'$.

The first category is a requirement for dispatching the fixed-delay equivalent of a variable-delay
STNU. If the constraints of a problem domain are modeled directly in a fixed-delay STNU and the
modeler gives a contingent event, $x_{c}$, infinite delay, e.g. $\gamma(x_{c}) = \infty$, the event
will never be observed and thus a fixed-delay scheduler has no need for an execution strategy in the
event that $x_{c}$ is observed. However, by Lemmas [[lemma:partially-unobservable]] and
[[lemma:not-enough-information]] there are some contingent events with potentially finite observation
delay in $S$ that are transformed to infinite observation delay in $S'$, making it possible that the
scheduler receives observations of them.

#+label: lemma:ignore-inf-delay
#+latex: \begin{lemma}
#+latex: \label{lemma:ignore-inf-delay}
For any contingent event $x'_{c} \in X_{c}$ in fixed-delay controllable $S'$, if $\gamma(x'_{c}) =
\infty$, we mark the event executed but do not assign $\assign(x'_{c})$ in the dispatchable form of
$S'$.
#+latex: \end{lemma}

#+latex: \begin{proof}
If we are scheduling a fixed-delay STNU, $S'$, that is already known to be fixed-delay controllable,
an execution strategy must exist that is independent of the assignment of $\assign(x'_{c})$ when
$\gamma(x'_{c}) = 0$. We are not required to record $\assign(x'_{c})$ when $\gamma(x'_{c}) = \infty$
to guarantee controllability and may safely ignore it.

We mark the event executed to prevent it from appearing in future RTEDs.
#+latex: \end{proof}

#+label: fig:observations
#+attr_latex: :width 3in
#+caption: Here, we show how the combination of $\assign(x_{c})$ and $\gammabar(x_{c})$ lead to an assignment of $\assign(x'_{c})$ in $S'$. We see the range $\alpha \in [l, l + \gammabar^+(x_{c}) - \gammabar^-(x_{c})$ representing the earliest and latest assignments of $\assign(x_{c})$ that could result in $\obs(x_{c}) \in \assign(x'_{c}) \in [l^+(x_{c})$, l^+(x_c)]$. The grey region represents the range of possible observation delays, $\gammabar(x_{c})$, supporting $\assign(x'_{c}) \in [l^+(x_{c}), l^+(x_{c})]$.
[[file:../images/viz-l-plus.png]]

The second category refers to the need for buffering and imagining events as a result of Lemma
[[lemma:main-tightening]] using the execution strategy proven to be valid in Lemma
[[lemma:buffering-imagining]]. There are three regimes of contingent event observations to address.

1. $\obs(x_{c})  \in [l^-(x_{c}), l^+(x_{c}))$, ie. strictly earlier than the range
   of $\assign(x'_{c})$,
2. $\obs(x_{c}) \in [l^+(x_{c}), u^-(x_{c})]$, ie. the range equivalent to $x'_{c}$, and
3. $\obs(x_{c}) \in(u^-(x_{c}), u^+(x_{c})]$, ie. strictly later than the range of
   $\assign(x'_{c})$.

Note that we omit the $-\gamma(x'_{c})$ term from Equation [[eqn:fixed-recording]] in this analysis due
to the fact that $\gamma(x'_{c}) = 0$ after applying Lemma [[lemma:main-tightening]].

Our execution strategy is to then make the following assignments during the FAST-EX real-time
update.

# TODO why is this not rendering!?
#+begin_export tex
\begin{equation}
\assign(x'_c) = \begin{cases}
$l^+(x_{c})$  & \text{if } $\obs(x_{c}) \in [l^-(x_{c}), l^+(x_{c}))$ \textit{(buffering)} \\
$\obs(x_{c})$ & \text{if } $\obs(x_{c}) \in [l^+(x_{c}), u^-(x_{c})]$ \\
$u^-(x_{c})$  & \text{if } $\obs(x_{c}) \in (u^-(x_{c}), u^+(x_{c})]$ \textit{(imagining)}
\end{cases}
\end{equation}
#+end_export

# TODO or the assignment might fail altogether!
# TODO make it clear that observing does not mean you can instantly assign. THIS IS PART OF THE DIFF BETWEEN REGULAR AND DELAY SCHEDULER
In the first case, we cannot immediately schedule buffered events. It may be the case that there are
other unexecuted timepoints between $\obs(x_{c})$ and $l^+(x_{c})$. If we make an assignment at
$l^+(x_{c})$, we would be preempting later timepoints, which would cause us to later make
assignments in the past, which invalidates our assumptions of partial history. Thus, we buffer
$x'_{c}$ in the sense that we wait until $l^+(x_{c})$ to assign $\assign(x'_{c}) = l^+(x_{c})$.

In the last case, late observations are assigned to an earlier time. During execution, time is
always increasing. There is no need to wait to make an observation after $u^-(x_{c})$. Instead, we
modify RTED generation, namely Equation [[eqn:rted1]], such that we dispatch $x'_{c}$ at $u^-(x_{c})$ if
it is not been observed before $u^-(x_{c})$. Let $U_{c}$ be the set of unobserved contingent
timepoints.

# TODO this omits t_U logic! needs to be fixed

#+label: rted-with-ctg
\begin{align}
t_{x} &= \min\{-D(X, Z)~|~X \in U_{x}\} \\
t_{c} &= \min\{D(Z, X)~|~X \in U_{c}\} \\
t &= \min\{t_{x}, t_{c}\} \\
\chi_{x} &= \{X \in U_{x}~|~-D(X, Z) = t\} \\
\chi_{c} &= \{X \in U_{c}~|~D(Z, X) = t\} \\
\chi &= \chi_{x} \cup \chi_{c}
\end{align}

We see that RTEDs may now include unobserved (or unexecuted) contingent timepoints at their upper
bounds. Note that there is no need to distinguish between contingent events that are the result of
tightening during the fixed-delay transformation by applying Lemma [[lemma:main-tightening]] and others.
We assume that the contingent constraints of the variable-delay STNU accurately reflect Nature. The
latest any other contingent event should be observed is their upper bound in $S'$ and thus should
never be in the set of events, $\chi$, of an executed RTED.

We have defined variable-delay execution strategies for when contingent events have infinite delay
and tightened constraints. The remaining category of contingent events is when a contingent event
has a finite, non-zero $\gamma(x'_{c})$ in $S'$. If that is the case, $x'_{c}$ must have had fixed
observation delay in $S$, Lemma [[lemma:emulating-fixed]], and can be scheduled normally after backing
out the observation delay with Equation [[eqn:fixed-recording]].

We have addressed the key issue of reconciling observations from $S$ with the dispatchable form from
$S'$. We now present a dispatcher and wrapper algorithms on top of FAST-EX that combine to add
robustness for variable observation delay.

** Dynamic Dispatching of STNUs with Observation Delay
<<sec:delay-scheduler>>

# TODO architecture img

# TODO "dispatching an action on hardware"

The terms "scheduling" and "dispatching" are often used interchangeably in temporal reasoning
literature. However, we distinguish the goals of a scheduler, as described above, and a dispatcher,
described here.

- *Scheduling*: Generating RTEDs based on a partial schedule.
- *Dispatching*: Reasoning over a clock and RTEDs to guarantee that requirement events are safely
  executed (w.r.t. controllability).

We assume that events in an STNU map 1:1 to actions in the real world. To put the design of the
dispatcher in context, it is worth considering what events may look like. In the case of a robotic
agent, requirement events may represent the instantaneous timepoints when motion plans begin, while
contingent events could be anything from the completion of said motion plans to the receipt of
=PROCEED= messages from a third party. For a human, requirement events could be presented in a
mission timeline as the start of planned actions such as the collection of scientific samples. The
end of a sampling activity would then be a contingent event. Or contingent events could be the
actions performed by other agents, like say another astronaut on an EVA, with whom temporal
constraints are shared. In both the case of the robot and the human, a robust dispatcher should take
into consideration that passing a message to the agent telling it to execute a requirement event
does not cause the event to occur instantaneously. Put in other words, dispatching is not the same
as assignment. A robot may require offline processing before it executes the motion plan. Or a human
may need to acknowledge that they have started the activity their mission timeline has told them to
perform. Neither is a problem, though, for our chosen formalism for temporal reasoning so long as
each requirement event is assigned at some point within their constraints in the STNU. In our view,
the dispatcher is responsible for ensuring requirement constraints are met by both monitoring the
real-world and interfacing with hardware to cause actions to be performed.

We finally introduce a third component, the /driver/, that can interpret dispatched events and cause
some action to be performed in an exogenous system. For instance, if Delay Kirk is controlling a
robotic arm, the driver might be responsible for forming and publishing ROS messages when the
dispatcher dispatches an event. If Delay Kirk is managing an astronaut's EVA schedule, the driver
might be responsible for causing a heads up display to alert the astronaut to start their sample
collection procedure.

In this Section, we contribute a set of algorithms for building the dispatcher for a robust
executive that can reason over observation delay and safely enact the actions symbolized in
requirement events in the real world. Dynamic dispatching is designed around the two interfaces of
scheduling - the input of partial schedules and output of RTEDs. As such, we focus on the
interpretation, management, and flow of RTEDs in Section [[sec:dynamic-dispatching]] and observing
events in Section [[sec:event-observations]]. But first, we present a novel view on RTEDs that is
required for dispatching events to real hardware in Section [[sec:real-vs-noop-events]].

*** Guaranteeing Agents Receive Actionable Events
<<sec:real-vs-noop-events>>

# In our view, RTEDs are not commands to the agent. Rather, they inform the executive of the
# time where actions ensure consistency.

We take the view that events in an STNU may be interpreted as commands by the driver. It is improper
to knowingly send an invalid command. Accordingly, the driver must never receive a dispatched event
that cannot be mapped to a corresponding action in its exogenous system. As such, it is the
dispatcher's responsibility to filter events in order to only dispatch valid commands to the driver.

In a variable-delay STNU, there are events that need to be executed by the driver and there are
events that do not. We call these /real/ and /noop/ ("no operation") events. Both contingent /and/
requirement events may fall into either category. Below, we present our rationale for the
distinction between real and no-op events, and how we modify real-time execution decisions
accordingly.

To start, imagined contingent events are no-ops. They are assignments we artificially perform with
no corresponding real-world action, and solely exist to maintain the controllability of the
fixed-delay dispatchable form. Imagined events should never be dispatched to a driver.

There are requirement events that are also no-ops. Consider the process of normalization of an STNU
[cite:@Morris2006]. While building the labeled distance graph during a DC check, we rewrite
contingent links such that their lower bounds are always $0$. For instance, for a contingent event
$C$ and free event $E$, $C - E \in [l, u]$, during normalization we create a new requirement event,
$C'$, fixed at the lower bound of the contingent link, and then shift the bounds of the contingent
link to start at 0 while maintaining the original range, $u - l$. This results in two constraints:
$E - C' \in [l, l]$ and $C - C' \in [0, u - l]$ that still reflect the original contingent link's
semantics.

Importantly, the requirement events representing the normalized lower bounds of contingent events
are in the dispatchable form for dynamic scheduling because we draw the AllMax graph directly from
the DC check. To a scheduler, there is no distinction between the semantics of a real event, as
modeled by a human planner writing an STNU for an agent to execute, and $C'$, an artifact of
checking controllability. Both are modeled in the AllMax distance graph forming the basis of RTED
generation. However, an agent does not need to execute any task in the outside world to satisfy $E -
C'$. Thus, we make the following addendum to the definition of RTEDs.

#+begin_export latex
\newcommand*{\eventnoop}{\mathit{event}\textsf{-}\mathit{noop}}
\newcommand*{\eventnoops}{\mathit{event}\textsf{-}\mathit{noops}}
#+end_export

# TODO these variables aren't great
#+label: def:rted
#+latex: \begin{defn}
*Event-No-op Pair*

An /Event-No-op Pair/, $\eventnoop$, is a two-tuple, $\langle x, \mathit{noop} \rangle$,
where:
- $x$ is an event in $X_{e} \cup X_{c}$,
- /noop/ is a boolean, where if true, the event cannot be interpreted by the driver, else the event
  is a valid command.
#+latex: \end{defn}

#+label: def:rted-op
#+latex: \begin{defn}
#+latex: \label{def:rted-op}
*RTED with Operational Distinction*

A /Real-Time Execution Decision with Operational Distinction/ is a two-tuple $\langle t,
\eventnoops \rangle$, where:
- $t$ is a time with domain $\mathbb{R}$,
- $\eventnoops$ is a set of $\eventnoop$ pairs to be executed at time $t$.
#+latex: \end{defn}

For convenience and simplicity, and given the similarities between RTED and RTED with Operational
Distinction, future references to RTEDs will always refer to RTEDs with Operational Distinctions.

*** Dynamic Event Dispatching
<<sec:dynamic-dispatching>>

The dynamic dispatcher runs the main loop of the executive's temporal reasoning routine. It consists
of a dispatching routine and some type of outer loop monitoring it. The dispatching routine,
Algorithm [[alg:dispatcher-inner]], is responsible for retrieving the latest RTEDs and firing driver
commands when the clock indicates that the agent has reached time $t$ corresponding to the latest
RTED. The outer loop allows the dispatching routine to run until the scheduler reports there are no
requirement events remaining.

The dispatcher requests RTEDs with blocking synchronous calls, while the dispatcher and driver
communicate asynchronously. The dispatcher spawns a thread to make non-blocking calls to the
driver's interface to execute events. The dispatcher and driver also share a FIFO queue that the
driver can append messages to indicating the successful execution of events.
# TODO is the part about non-blocking calls to the driver true? does it matter?

We now provide a walkthrough of the dynamic dispatching algorithm. For simplicity's sake, the term
/schedule/ here is shorthand for whatever data structures the scheduler uses to generate RTEDs.
/Updating the schedule/ refers to running the fixed-delay FAST-EX update, Algorithm
[[alg:fast-ex-fixed-obs]], using the variable-delay execution strategy from Section
[[sec:delay-scheduling]].

The interaction between the dispatching routine and monitoring loop is limited. Algorithm
[[alg:dispatcher-inner]] returns a Boolean indicating whether there are executable events remaining.
Here, the monitoring loop is a simple =while= that repeats until it receives =false= from the inner
loop. Otherwise, the only communication between the dispatching routine and outer loop is a variable
containing the last RTED that was generated but not executed. The outer loop creates the variable
and passes it by reference to the dispatching routine, which is free to use or modify the variable
as it sees fit.

We break the dispatching routine into three distinct phases.

1. Receive execution confirmation from the driver.
2. Collect an RTED and confirm the clock time matches RTED time $t$.
3. If there is an RTED:
   a. send executable events to the driver, else
   b. immediately assign all /no-op/ events to the current time.

Our goal in the dispatching routine is to dispatch events to the driver only after updating the
schedule, collecting an up-to-date RTED, and confirming we are within the time window of the RTED.
The routine will exit before reaching the dispatch step if any conditions are not met.

For the first step, we ask the scheduler if there are any remaining executable events. If there are
none, we return =false= to signal the loop's termination, otherwise we continue.

Next, we check the FIFO queue for any event execution messages returned from the driver. The
presence of a message would indicate that the driver has successfully executed a free event. We
iteratively pop messages off the queue and update the schedule with the events and execution time
contained in each message. Note that the scheduler update is a blocking operation because we need an
up-to-date schedule to guarantee future RTEDs are consistent. We then invalidate the last RTED
generated.

# TODO do we need to be more specific about checking the RTED? what if some events overlap but not all?
The second step starts once we have popped all messages from the driver off the queue. If we do not
have a valid RTED from the last iteration of the routine, we ask the scheduler for one and save it
to the referenced variable from the outer loop. Given that we interact with the driver
asynchronously, it is possible that the current RTED is one that has already been sent to the driver
but we have yet to receive an acknowledgment message confirming its execution. If so, there is
nothing to do so we return =true=.

# TODO does it make sense to call it a "suggested" time?
# TODO isn't this the second \epsilon in the chapter? what about the epsilon proof? maybe the proof gets a new variable because this one is baked into Kirk?
Lastly, we compare the suggested time in the RTED against the clock's elapsed time. Given the
relationship between the scheduler, routine, and driver, we do not assume that dispatched events are
executed instantaneously by the driver. We know that execution contends against delays such as the
computational time in simply calling a function, to network latency, to robotic hardware that takes
a moment to interpolate a motion plan from waypoints. In some contexts, it may make sense to preempt
execution by dispatching events some small amount of time /before/ the clock time reaches the RTED
execution window. We call this preemption time $\epsilon$, where $\epsilon \in \mathbb{R}^{\geq 0}$.
Thus, we dispatch events, signaled by =dispatch-p=, when $\texttt{dispatch-p} = (t_{\mathit{RTED}} -
t_{\mathit{clock}} \leq \epsilon)$. If $\epsilon = 0$, the dispatcher is not allowed to preemptively
dispatch events before the RTED time. We allow the human operator to choose an $\epsilon$ that is
consistent with the operational context for the driver.

If =dispatch-p= is =false=, we are too early to execute the RTED and so the loop returns =true=.
Otherwise we continue.

Once we reach the third stage, we are guaranteed to be able to safely dispatch events because (1) we
have confirmed that the RTED we have in hand has unexecuted events that have never been dispatched,
and (2) that we are in a time window that the scheduler has told us is consistent with the STNU's
constraints. Going forward, we take advantage of the operational distinction we added to
Hunsberger's RTEDs in Definition [[def:rted-op]]. Using the /no-op/ property of each $\eventnoop$ pair
in the RTED, we filter the $\eventnoop$ pairs into a set of /no-op/ events and a set of real events.
In the event that a contingent event and its normalized lower bound are to be scheduled at the same
time, we schedule the /no-op/ events first. The real events are then asynchronously sent to the
driver.

Finally, because events were dispatched, the dispatching routine returns =true=.

#+label: alg:dispatcher-outer
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Outer Loop}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\SetKw{Continue}{continue}

\Indm

\Initialize{$\mathit{RTED_{\mathit{last}}} \gets \varnothing$}

\Indp
\Algorithm{}
\Indp

\While{Calling inner loop with $\mathit{RTED_{\mathit{last}}}$ returns $\textbf{true}$} {
    \Continue
}
\caption{The outer loop of the dynamic dispatching algorithm.}
\label{alg:dispatcher-outer}
\end{algorithm}
#+end_export

# TODO check logic with last RTED
# TODO add buffered events

#+label: alg:dispatcher-inner
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Routine}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{$\mathit{Scheduler}$; $\mathit{Driver}$; FIFO queue, $\mathit{Queue}$; $\mathit{RTED_{\mathit{last}}}$; $\epsilon$;}
\Output{Boolean whether the outer loop should continue}

\Initialize{$\mathit{events}_{\mathit{real}} \gets$ \{\}; $\mathit{events}_{\mathbf{noop}} \gets$ \{\};}

\Indp
\Algorithm{}
\Indp

\If{$\mathit{Scheduler}$ has no more unexecuted events} {
    \Return $\mathtt{false}$\;
}

\For{$\mathit{message}$ in $\mathit{Queue}$} {
    Pop $\mathit{message}$\;
    \For{$\mathit{event}, t_{\mathit{execution}}$ in $\mathit{message}$} {
        Set $\assign(\mathit{event}) = t_{\mathit{execution}}$ in $\mathit{Scheduler}$\;
    }
    $\mathit{RTED_{\mathit{last}}} \gets \varnothing$\;
}

$\mathit{RTED} \gets$ a new RTED from $\mathit{Scheduler}$; \Comment{Equations \ref{eqn:rted-chi} and \ref{eqn:rted-t}}

\If{$\mathit{RTED} = \mathit{RTED}_{\mathit{last}}$} {
    \Return $\mathtt{true}$\;
}

$\mathit{RTED}_{\mathit{last}} \gets \mathit{RTED} $\;

\If{$t_{\mathit{RTED}} - t_{\mathit{current}} > \epsilon$} {
    \Return $\mathtt{true}$\;
}

\For{$\eventnoop$ pair in $\mathit{RTED}_{\eventnoops}$} {
    \eIf{$\eventnoop[noop]$ is \textbf{true}} {
        Add $\eventnoop[x]$ to $\mathit{events}_{\mathbf{noop}}$\;
    } {
        Add $\eventnoop[x]$ to $\mathit{events}_{\mathit{real}}$\;
    }
}

\For{$\mathit{event}$ in $\mathit{events}_{\mathbf{noop}}$} {
    Set $\assign(\mathit{event}) = t_{\mathit{RTED}}$ in $\mathit{Scheduler}$\;
}

Asynchronously send all $\mathit{events}_{\mathit{real}}$ to the $\mathit{Driver}$\;

\Return $\mathtt{true}$\;

\caption{The dynamic dispatching routine.}
\label{alg:dispatcher-inner}
\end{algorithm}
#+end_export

The biggest factor for the performance of the dispatching routine, Algorithm
[[alg:dispatcher-inner]], is updating the schedule. Assuming the /Scheduler/ is the Delay Scheduler
described in Section [[sec:delay-scheduler]], then performing an assignment of an event will trigger the
FAST-EX update that runs in $O(N^{3})$ [cite:@Hunsberger2016 p144] with the number of events in the
STNU. In the worst case, the dispatcher confirms that all events in the STNU have arrived at the
same time, whether as messages from the driver in the FIFO queue, or RTED =noop= events. Each event
would trigger a schedule update. Thus, the dynamic dispatching routine runs in $O(N^{4})$ in the
worst case.

*** Observing Contingent Events
<<sec:event-observations>>

The dispatcher relays contingent event observations to the scheduler. In the base case, when a
contingent event is observed, the dispatcher updates the schedule with the event and current clock
time.

If the observed event is contingent and arrived earlier than its lower bound, then the dispatcher
will save the event in a =buffered-events= hash-table for the lower bound.

** Experimental Analysis
<<sec:scheduling-experimental>>

We first introduce an example which models a construction task on the lunar surface that will be
used to randomly generate STNUs with realistic constraints for benchmarking purposes. We then
describe benchmarks against the performance of the real-time FAST-EX update with the variable-delay
execution strategy, the dispatching routine, and observations. All benchmark code can be found at
[[https://gitlab.com/enterprise/enterprise]] in the =kirk-v2/benchmarks= directory.

#+label: fig:dish-stnu
#+attr_latex: :width 1\textwidth
#+caption: An STNU representing the installation and test of repeater antennas. Each row represents a single rover. The episode durations are representative of the bounds used in simulation.
[[file:../images/dish-install-stnu.png]]

It is possible that, before NASA is ready to grow the population of a lunar base, there is a need to
prepare a communications infrastructure near a habitat with a large grid of repeater antennas. This
scenario depicted with the STNU in Figure [[fig:dish-stnu]] represents an installation task wherein $i$
rovers (mobile robot) are each installing $j$ surface signal repeater antennas. During the activity,
every rover is responsible for installing one repeater. Each event, $X$, is represented for the
$i$-th rover and $j$-th repeater as $X_{i,j}$. All numbers in the figure are representative of the
minimum and maximum of the randomly generated constraints in the benchmarks.

The rovers work in parallel, with a $[0, \infty)$ requirement link from the start of the STNU to
each $A_{i,1}$ (not shown). The first episode, $\conedge{A_{i,j}}{B_{i,j}}{}$, represents traversing
to the site of the installation. We model traverses as uncontrollable due to the fact that crews are
embarking across unknown terrain. Once at the site, an antenna is installed as represented by
$\edge{B_{i,j}}{C_{i,j}}{}$. Each repeater needs to have its configuration tested and confirmed
working by $D_{i,j}$, represented by the edge $\conedge{C_{i,j}}{D_{i,j}}{}$. Confirmation takes the
form of a request-response cycle to the ground. We model $D_{i,j}$ as uncontrolled and with variable
delay because each antenna takes an unknown time to self-configure and the crew does not know when
they will receive a response from Earth that the repeater installation has been verified due to
uncertainty in communication. Bandwidth is limited, so we limit the number of repeaters
simultaneously sending requests to their configuration. We use the $\edge{D_{i,j}}{C_{i+1,j}}{}$
links to enforce that the start of the confirmation of the next repeater does not begin until after
the previous repeater's confirmation. Confirmations are required until we reach the last crew member
or the last activity. Once testing is complete, the rovers clean up their workstations,
$\edge{D_{i,j}}{A_{i,j+1}}{}$ and then repeat the cycle until all antennas have been installed.

To perform the benchmarks, we generated variable-delay STNUs of increasing sizes with randomly
determined constraints as previously described. We immediately checked VDC of each STNU, and would
generate new STNUs of a given size until we found one that was confirmed to be VDC. We then
simulated scheduling and dispatching of the STNU with a faster-than-realtime clock. No driver was
present, so all real events were scheduled immediately.

These data were collected on an Intel i7-10710U 6c/12t mobile processor with 16GB of RAM in a
ThinkPad X1 Carbon Gen 7 laptop. All tests were run while the laptop was attached to wall power. The
code was written in Common Lisp and all benchmarks were run with Steel Bank Common Lisp version
2.0.1. To reduce the time spent running benchmarks, we scheduled multiple STNUs in parallel, with
each STNU being scheduled in its own thread.

The regressions below were performed using the Python packages ~scipy~ [cite:@2020SciPy-NMeth] and
~sklearn~ [cite:@scikit-learn], then graphed with ~matplotlib~ [cite:@Hunter:2007].

The implementation of the delay scheduler from which these data were collected has a bug that we
have been unable to identify. We have only seen the bug surface with STNUs with more than about 50
events. The bug takes effect when observing a contingent event, $x_{c}$, which has incoming
contingent constraint $[l, u]$. If we observe $x_{c}$ at some time $t$, where $l \leq t < u$, the
Dijkstra SSSP subroutine may unexpectedly find a negative edge and raise an error. We have been
able to replicate the problem for specific STNUs with specific observations, and, as of the time of
this writing, we are still investigating the cause. We do not believe it meaningfully impacts the
validity of the benchmarks below.

*** Scheduling

We start with the runtime performance of schedule updates. There can be runtime variance for each
individual call to the scheduling update routine, so we focus on the total time spent scheduling all
events in the STNU. According to the FAST-EX algorithm, the total runtime is dominated by the $O(N
\log N)$ runtime of Dijkstra SSSP, where $N$ is the total number of events. Thus, the total runtime
to schedule every event in an STNU is $O(N^{2} \log N)$ [cite:@Hunsberger2016 p.144]. Given the
changes we made to FAST-EX are also dominated by Dijkstra SSSP, we expect to see the same runtime
performance here.

Figure [[fig:runtime-scheduling-sub-300]] clearly shows that the total time spent scheduling STNUs with
$N \leq 300$ follows $O(N^{2} \log N)$ as expected, with a coefficient of determination for the
regression of $R^{2} = 0.995$.

#+label: fig:runtime-scheduling-sub-300
#+attr_latex: :width 0.8\textwidth
#+caption: Total runtime data for scheduling all events in VDC STNUs where $N \leq 300$.
file:../images/scheduling-total-runtime-sub-300.png

If we expand the size of STNUs to $N \leq 600$, then we see the total runtime correspond less
closely with $O(N^{2} \log N)$, as can be seen in Figure [[fig:runtime-scheduling-aggregate]]. We
believe the deviation is due to programming language features in lisp outside of our control, such
as automated memory management.
# It is also possible that the aforementioned scheduler bug is responsible for the deviation.

#+label: fig:runtime-scheduling-aggregate
#+attr_latex: :width 0.8\textwidth
#+caption: Total runtime data for scheduling all events in VDC STNUs where $N \leq 600$.
file:../images/scheduling-total-runtime-all.png

*** Event Observations

Next, we examine the runtime characteristics of event observations. While generating VDC STNUs, we
also collected possible ranges of time to observe the confirmation event. As scheduling progressed,
we automatically triggered observations of the confirmation event at a time randomly selected within
the range given.

Contingent event observations are made much less frequently than scheduling. While we must schedule
every event in an STNU, our benchmarking procedure will only observe a small fraction of the events.
As a result, sample sizes are small. Given event observations are dominated by the call to FAST-EX
for a scheduling update, we expect to see runtimes on the order of $O(N \log N)$. However, the data
in Figure [[fig:runtime-observations-aggregate]] show significant deviation from it. Given that the
method call to observe events is a thin wrapper around a FAST-EX update, we believe the error of
this graph is due to small sample sizes.

#+label: fig:runtime-observations-aggregate
#+attr_latex: :width 0.8\textwidth
#+caption: Average runtime data for observing events in VDC STNUs. Error bars represent standard deviation.
file:../images/observations-avg-runtime.png

*** Dispatching

Finally, we benchmark action dispatching. In our simulated environments for dispatching, we run the
dispatcher function as described in Algorithm [[alg:dispatcher-inner]] twice per simulated second. (We
run it twice in the event that scheduling an event enables us to dispatch other actions immediately.
If we ran Algorithm [[alg:dispatcher-inner]] once per second, the newly enabled events would then be
dispatched a second late.)

Given every event will be scheduled once using the FAST-EX update, FAST-EX updates will dominate the
total runtime of dispatching. As seen in Figure [[fig:runtime-tick-aggregate]], the total runtime of all
calls to Algorithm [[alg:dispatcher-inner]] indeed follows $O(N^{2} \log N)$.

#+label: fig:runtime-tick-aggregate
#+attr_latex: :width 0.8\textwidth
#+caption: Average runtime data for running Algorithm [[alg:dispatcher-inner]].
file:../images/tick-total-runtime.png
