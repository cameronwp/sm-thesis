#+title: Technical - Executive

* COMMENT extra
** notes on kirk from jake

Kirk operates on qualitative state plans, which consist of episodes that organize the occurrance of
events as activities. Also includes causal links (:effects and :requires ala STRIPS/PDDL planning).
All passed to OpSAT, which is like an SMT solver. Makes choices through causal links to decompose
state constraints into a SAT problem and then solve. Temporal constraints go to
temporal-controllability. State plan gets turned into a SAT solver, with ordering from temporal
constraints.

* An Executive for Scheduling with Observation Delay
<<ch:technical-executive>>

A delay scheduler is only useful if there is a system capable of dispatching the actions associated
with RTEDs. A delay scheduler could be integrated as a subsystem for a digital assistant, if such a
digital assistant has a means for surfacing RTEDs to a user in a useful manner. Instead, for this
thesis, we choose to integrate with a high-level task and motion planner, /Kirk/
[cite:@Williams2003]. Kirk is a complete, end-to-end executive in that it can take human-friendly
problem specifications as input and send commands to hardware as output.

At a high-level, Kirk operates by first taking a description of the problem domain as written by
domain experts, which should include the constraints, agent dynamics, environment, and starting and
goal states of the problem at hand. Kirk then generates state plans, which consist of episodes that
organize the occurrence of events as activities. State plans may include temporal constraints and
non-temporal constraints, such as classical planning preconditions and effects. Kirk checks plans
for consistency using an optimal satisfiability (OpSAT) solver [cite:@Williams2007]. Next, it
elaborates temporal plan networks (TPNs) [cite:@Kim2001] to sub-executives when it encounters
constraints and goals it cannot plan against directly. Finally, it dispatches actions to hardware.
For the purpose of this thesis, we focus on Kirk's capability to dispatch actions from state plans.

Below, we present an instantiation of Kirk, /Delay Kirk/, designed to dispatch actions from state
plans with uncertain observations. A delay scheduler lives at the core of Delay Kirk, with a new
component, a /delay dispatcher/ taking responsibility for translating RTEDs into actions in the real
world. In this chapter, we start by defining a delay dispatcher, which plays a key role in enabling
delay scheduling. Next, we present a high-level overview of Kirk's architecture. Finally, we define
necessary components of an input language, the Reactive Model-Based Programming Language (RMPL),
used to represent constraints and action models for Delay Kirk. We present experimental results on
the performance of the delay dispatcher, however, experimentation with a full Delay Kirk executive
are presented in Section [[sec:ma-experimental]].

** Dynamic Dispatching of STNUs with Observation Delay
<<sec:delay-scheduler>>

We assume that events in an STNU map one-to-one with actions in the real world. To put the design of
the dispatcher in context, it is worth considering what events may look like. In the case of a
robotic agent, requirement events may represent the instantaneous timepoints when motion plans
begin, while contingent events could be anything from the completion of said motion plans to the
receipt of =PROCEED= messages from a third party. For a human, requirement events could be presented
in a mission timeline as the start of planned actions such as the collection of scientific samples.
The end of a sampling activity would then be an uncontrollable event. Or uncontrollable events could
be the actions performed by other agents, like say another astronaut on an EVA, with whom temporal
constraints are shared. In both the case of the robot and the human, a robust dispatcher should take
into consideration that passing a message to the agent telling it to execute a requirement event
does not cause the event to occur instantaneously. Put in other words, we are not guaranteed that
dispatching an action causes an event to be scheduled instantaneously. A robot may require offline
processing before it executes the motion plan. Or a human may need to acknowledge that they have
started the action their digital assistant has instructed them to perform. Neither situation is a
problem for our chosen formalism for temporal reasoning so long as each requirement event is
assigned at some point within their constraints in the STNU. In our view, the dispatcher is
responsible for ensuring requirement constraints are met by both monitoring the real-world and
interfacing with hardware to cause actions to be performed.

#+label: fig:executive-dispatching-architecture
#+attr_latex: :width 0.6\textwidth
#+caption: A more detailed view of the delay dispatcher architecture.
file:../images/architecture.png

As depicted in Figure [[fig:executive-dispatching-architecture]], there are two key pathways within a
delay dispatcher. First, a delay dispatcher takes an RTED as input and causes actions to happen in
the environment as output. Second, it takes event observations as input and may cause the scheduler
to record events as output.

Additionally, we introduce a sub-component, a /driver/, that can interpret dispatched events and
cause some action to be performed in the environment. We separate the driver and delay dispatcher in
Figure [[fig:executive-dispatching-architecture]] for completeness, however, for all intents and
purposes, the driver is a sub-component of a delay dispatcher. A driver is defined as performing the
following transformation: given some event, $x$, as input the driver should cause an action to be
performed. For instance, if Delay Kirk is controlling a robotic manipulator over ROS, the driver
would receive an event string as input and publish ROS messages as output.

In this Section, we contribute a set of algorithms for building the dispatcher for a robust
executive that can reason over observation delay and safely enact the actions symbolized in
requirement events in the real world. We focus on the interpretation, management, and flow of RTEDs
in Section [[sec:dynamic-dispatching]]. In Section [[sec:event-observations]] we describe the process of
observing events. But first, we present a novel view on RTEDs that is required for dispatching
events to real hardware in Section [[sec:real-vs-noop-events]].

*** Guaranteeing Agents Receive Actionable Events
<<sec:real-vs-noop-events>>

# In our view, RTEDs are not commands to the agent. Rather, they inform the executive of the
# time where actions ensure consistency.

We take the view that events in an STNU may be interpreted as commands by the driver. It is improper
to knowingly send an invalid command. Accordingly, the driver must never receive an event (in an
RTED) that cannot be mapped to a corresponding action in its environment. As such, it is the
dispatcher's responsibility to filter events in order to only dispatch valid actions.

In a variable-delay STNU, there are events that are associated with actions and there are events
that are not. We call these /real/ and /no-op/ ("no operation") events. Only controllable events may
be real, but both uncontrollable /and/ controllable events may be no-op. Below, we present our
rationale for the distinction between real and no-op events, and how we modify real-time execution
decisions accordingly.

To start, imagined uncontrollable events are no-ops. They are assignments we artificially perform
with no corresponding real-world action, and solely exist to maintain the controllability of the
fixed-delay dispatchable form. Imagined events should never be dispatched to a driver.

There are requirement events that are also no-ops. Consider the process of normalization of an STNU
[cite:@Morris2006]. While building the labeled distance graph during a DC check, we rewrite
contingent links such that their lower bounds are always $0$. For instance, for an uncontrollable
event $C$ and requirement event $E$, $C - E \in [l, u]$, during normalization we create a new
requirement event, $C'$, fixed at the lower bound of the contingent link, and then shift the bounds
of the contingent link to start at 0 while maintaining the original range, $u - l$. This results in
two constraints: $E - C' \in [l, l]$ and $C - C' \in [0, u - l]$. The original contingent link's
semantics are thus maintained.

Importantly, the requirement events representing the normalized lower bounds of uncontrollable
events are in the dispatchable form for dynamic scheduling because we draw the AllMax graph directly
from the DC check. To a scheduler, there is no distinction between the semantics of a real event, as
modeled by a human planner writing an STNU for an agent to execute, and $C'$, an artifact of
checking controllability. Both are modeled in the AllMax distance graph forming the basis of RTED
generation. However, an agent cannot dispatch any action to satisfy $E - C'$, rather $C'$ should
simply be scheduled at the appropriate time. Thus, we make the following addendum to the definition
of RTEDs.

#+begin_export latex
\newcommand*{\eventnoop}{\mathit{event}\textsf{-}\mathit{noop}}
\newcommand*{\eventnoops}{\mathit{event}\textsf{-}\mathit{noops}}
#+end_export

# TODO these variables aren't great
#+label: def:rted
#+latex: \begin{defn}
*Event-No-op Pair*

An /Event-No-op Pair/, $\eventnoop$, is a two-tuple, $\langle x, \mathit{noop} \rangle$,
where:
- $x$ is an event in $X_{e} \cup X_{c}$,
- /noop/ is a boolean, where if true, the event cannot be interpreted by the driver, else the event
  is a valid command.
#+latex: \end{defn}

#+label: def:rted-op
#+latex: \begin{defn}
#+latex: \label{def:rted-op}
*RTED with Operational Distinction*

A /Real-Time Execution Decision with Operational Distinction/ is a tuple $\langle t, \eventnoops
\rangle$, where:
- $t$ is a time with domain $\mathbb{R}$,
- $\eventnoops$ is a set of $\eventnoop$ pairs to be executed at time $t$.
#+latex: \end{defn}

For convenience and simplicity, and given the similarities between RTED and RTED with Operational
Distinction, future references to RTEDs will always refer to RTEDs with Operational Distinctions.

*** Dispatching Actions Dynamically
<<sec:dynamic-dispatching>>

The dynamic dispatcher runs the main loop of the executive's temporal reasoning routine. It consists
of a dispatching routine and some type of outer loop monitoring it. The dispatching routine,
Algorithm [[alg:dispatcher-inner]], is responsible for retrieving the latest RTEDs and dispatching
actions when the clock indicates that the agent has reached time $t$ corresponding to the latest
RTED. The outer loop allows the dispatching routine to run until the scheduler reports there are no
requirement events remaining.

The dispatcher requests RTEDs with blocking synchronous calls, while the dispatcher and driver
communicate asynchronously. The dispatcher spawns a thread to make non-blocking calls to the
driver's interface to execute events. The dispatcher and driver also share a FIFO queue that the
driver can append messages to indicating the successful execution of events.
# TODO is the part about non-blocking calls to the driver true? does it matter?

We now provide a walkthrough of the dynamic dispatching algorithm. For simplicity's sake, the term
/schedule/ here is shorthand for whatever data structures the scheduler uses to generate RTEDs.
/Updating the schedule/ refers to running the fixed-delay FAST-EX update, Algorithm
[[alg:fast-ex-fixed-obs]], using the variable-delay execution strategy from Section
[[sec:delay-scheduling]].

The interaction between the dispatching routine and monitoring loop is limited. Algorithm
[[alg:dispatcher-inner]] returns a Boolean indicating whether there are executable events remaining.
Here, the monitoring loop is a simple =while= that repeats until it receives =false= from the inner
loop. Otherwise, the only communication between the dispatching routine and outer loop is a variable
containing the last RTED that was generated but not executed. The outer loop creates the variable
and passes it by reference to the dispatching routine, which is free to use or modify the variable
as it sees fit.

We break the dispatching routine into three distinct phases.

1. Observe events that were executed.
2. Collect an RTED and confirm the clock time matches RTED time $t$.
3. If there is an RTED:
   a. send executable events to the driver, else
   b. immediately assign all /no-op/ events to the current time.

Our goal in the dispatching routine is to dispatch events to the driver only after updating the
schedule, collecting an up-to-date RTED, and confirming we are within the time window of the RTED.
The routine will exit before reaching the dispatch step if any conditions are not met.

For the first step, we ask the scheduler if there are any remaining executable events. If there are
none, we return =false= to signal the loop's termination, otherwise we continue.

Next, we observe events associated with actions that have been dispatched by the driver. We choose
to use a FIFO queue to store messages corresponding to event observations from the driver. The
presence of a message would indicate that the driver has successfully executed a free event. We
iteratively pop messages off the queue and update the schedule with the events and execution time
contained in each message. Note that the scheduler update is a blocking operation because we need an
up-to-date schedule to guarantee future RTEDs are consistent. We then invalidate the last RTED
generated.

# TODO do we need to be more specific about checking the RTED? what if some events overlap but not all?
The second step starts once we have popped all messages from the driver off the queue. If we do not
have a valid RTED from the last iteration of the routine, we ask the scheduler for one and save it
to the referenced variable from the outer loop. Given that we interact with the driver
asynchronously, it is possible that the current RTED is one that has already been sent to the driver
but we have yet to receive an acknowledgment message confirming its execution. If so, there is
nothing to do so we return =true=.

# TODO does it make sense to call it a "suggested" time?
# TODO isn't this the second \epsilon in the chapter? what about the epsilon proof? maybe the proof gets a new variable because this one is baked into Kirk?
Lastly, we compare the suggested time in the RTED against the clock's elapsed time. Given the
relationship between the scheduler, routine, and driver, we do not assume that dispatched actions
are executed instantaneously by the driver. We know that execution contends against delays such as
the computational time in simply calling a function, to network latency, to robotic hardware that
takes a moment to interpolate a motion plan from waypoints. In some contexts, it may make sense to
preempt execution by dispatching events some small amount of time /before/ the clock time reaches
the RTED execution window. We call this preemption time $\epsilon$, where $\epsilon \in
\mathbb{R}^{\geq 0}$. Thus, we dispatch actions, signaled by =dispatch-p=, when $\texttt{dispatch-p}
= (t_{\mathit{RTED}} - t_{\mathit{clock}} \leq \epsilon)$. If $\epsilon = 0$, the dispatcher is not
allowed to preemptively dispatch actions before the RTED time. We allow the human operator to choose
an $\epsilon$ that is consistent with the operational context for the driver.

If =dispatch-p= is =false=, we are too early to execute the RTED and so the loop returns =true=.
Otherwise we continue.

Once we reach the third stage, we are guaranteed to be able to dispatch valid actions because (1) we
have confirmed that the RTED we have in hand has unexecuted events that have never been dispatched,
and (2) that we are in a time window that the scheduler has told us is consistent with the STNU's
constraints. Going forward, we take advantage of the operational distinction we added to
Hunsberger's RTEDs in Definition [[def:rted-op]]. Using the no-op property of each $\eventnoop$ pair in
the RTED, we filter the $\eventnoop$ pairs into a set of no-op events and a set of real events. In
the event that an uncontrollable event and its normalized lower bound are to be scheduled at the
same time, we schedule the no-op events first. Real events are then asynchronously sent to the
driver.

Finally, because events were dispatched, the dispatching routine returns =true=.

We benefit greatly from using instance-based properties. All inputs in Algorithms
[[alg:dispatcher-outer]], [[alg:choose-event-noops]], and [[alg:dispatcher-inner]] can be properties on an
instance of a delay dispatcher class.

#+label: alg:dispatcher-outer
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Outer Loop}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\SetKw{Continue}{continue}

\Indm
\Input{}

\Initialize{\texttt{buffered-events} $\gets \varnothing$; \texttt{history} $\gets \varnothing$}

\Indp
\Algorithm{}
\Indp

\texttt{all-inputs} \gets \langle \texttt{buffered-events}, \texttt{history}, \textit{Scheduler}, \textit{Driver}, \textit{Queue}, \epsilon \rangle\;

\While{Calling inner loop with \texttt{all-inputs} returns true} {
    \Continue
}
\caption{The outer loop of the dynamic dispatching algorithm.}
\label{alg:dispatcher-outer}
\end{algorithm}
#+end_export

# TODO check logic with last RTED
# TODO add buffered events

#+label: alg:choose-event-noops
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Choose Event-Noops}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{\texttt{RTED}; \texttt{buffered-events}; a set of dispatched event-noops \texttt{history}, current time $t$}
\Output{Set of event-noops, time to dispatch}

\Initialize{$t_{\mathit{dispatch}}$ \gets \infty; \texttt{event-noops} \gets \varnothing\;}

\Indp
\Algorithm{}
\Indp

\If{t is a key in \texttt{buffered-events}} {
    $t_{\mathit{dispatch}} \gets t$\;
    \texttt{event-noops} $\gets$ event-noops from \texttt{buffered-events}[$t$]\;
}

\uIf{\texttt{RTED}[time] < $t_{\mathit{dispatch}}$} {
    $t_{\mathit{dispatch}}$ \gets \texttt{RTED}[time]\;
    \texttt{event-noops} $\gets$ \texttt{RTED}[event-noops]\;
}
\uElseIf {\texttt{RTED}[time] = $t_{\mathit{dispatch}}$} {
    Add \texttt{RTED}[event-noops] to \texttt{event-noops}\;
}

Remove any event-noops in \texttt{event-noops} that are in \texttt{history}\;

\Return \texttt{event-noops}, $t_{\mathit{dispatch}}\;

\caption{An algorithm for paring the events from an RTED and buffered events into \eventnoops.}
\label{alg:choose-event-noops}
\end{algorithm}
#+end_export


#+label: alg:dispatcher-inner
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwComment{Comment}{//}{}
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Dynamic Dispatching Routine}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}

\Indm
\Input{Current time $t$, $\texttt{buffered-events}; \mathit{Scheduler}; \mathit{Driver}; \mathit{Queue}; \texttt{history}; \epsilon$;}
\Output{Boolean whether the outer loop should continue}

\Initialize{\texttt{real-events} $\gets$ \{\}; \texttt{noop-events} $\gets$ \{\};}

\Indp
\Algorithm{}
\Indp

\If{\mathit{Scheduler} has no more unexecuted events} {
    \Return false\;
}

\For{message in \mathit{Queue}} {
    Pop message\;
    \For{event, $t_{\mathit{execution}}$ in message} {
        Update \textit{Scheduler} with observation of event at $t_{execution}$\;
    }
}

\texttt{RTED} $\gets$ a new RTED from \textit{Scheduler}; \Comment{Equations \ref{eqn:rted-chi} and \ref{eqn:rted-t}}

$t_{\mathit{dispatch}}$, \texttt{event-noops} \gets \\
\quad \texttt{choose-event-noops(RTED, buffered-events, history, \mathit{t})}\;

\If{$t - t_{\mathit{dispatch}} > \epsilon$} {
    \Return $\mathtt{true}$\;
}

\For{\texttt{event-noop} pair in \texttt{event-noops}} {
    \eIf{\texttt{event-noop}[noop] is \textbf{true}} {
        Add \texttt{event-noop}[event] to \texttt{noop-events}\;
    } {
        Add \texttt{event-noop}[event] to \texttt{real-events}\;
    }
}

\For{event in \texttt{noop-events}} {
    Update \textit{Scheduler} with observation of event at $t_{dispatch}$\;
}

Asynchronously send all \texttt{real-events} to the \textit{Driver}\;

Add \texttt{event-noops} to \texttt{history}\;

\Return true\;

\caption{The dynamic dispatching routine.}
\label{alg:dispatcher-inner}
\end{algorithm}
#+end_export

The biggest factor for the performance of the dispatching routine, Algorithm
[[alg:dispatcher-inner]], is updating the schedule. Assuming the /Scheduler/ is the Delay Scheduler
described in Section [[sec:delay-scheduler]], then performing an assignment of an event will trigger the
FAST-EX update that runs in $O(N^{3})$ [cite:@Hunsberger2016 p144] with the number of events in the
STNU. In the worst case, the dispatcher confirms that all events in the STNU have arrived at the
same time, whether as messages from the driver in the FIFO queue, or RTED =noop= events. Each event
would trigger a schedule update. Thus, the dynamic dispatching routine runs in $O(N^{4})$ in the
worst case.

*** Observing Contingent Events
<<sec:event-observations>>

The dispatcher relays contingent event observations to the scheduler. In the base case, when a
contingent event is observed, the dispatcher updates the schedule with the event and current clock
time.

If the observed event is contingent and arrived earlier than its lower bound, then the dispatcher
will save the event in a =buffered-events= hash-table for the lower bound.

*** Experimental

# TODO mention it will be tested next section in a MA context

Finally, we benchmark action dispatching. In our simulated environments for dispatching, we run the
dispatcher function as described in Algorithm [[alg:dispatcher-inner]] twice per simulated second. (We
run it twice in the event that scheduling an event enables us to dispatch other actions immediately.
If we ran Algorithm [[alg:dispatcher-inner]] once per second, the newly enabled events would then be
dispatched a second late.)

Given every event will be scheduled once using the FAST-EX update, FAST-EX updates will dominate the
total runtime of dispatching. As seen in Figure [[fig:runtime-tick-aggregate]], the total runtime of all
calls to Algorithm [[alg:dispatcher-inner]] indeed follows $O(N^{2} \log N)$.

#+label: fig:runtime-tick-aggregate
#+attr_latex: :width 0.8\textwidth
#+caption: Average runtime data for running Algorithm [[alg:dispatcher-inner]].
file:../images/tick-total-runtime.png
** Architecture

We present a view of the Delay Kirk architecture that focuses attention to its scheduling and
dispatching capabilities. Kirk takes RMPL [cite:@RMPL2002] as input and produces actions as output
(from here on, "Kirk" refers to Delay Kirk because the architectural design of Delay Kirk and other
Kirks is fundamentally the same). As shown in Figure [[fig:executive-kirk-architecture]], there are
three key components of Kirk.

#+label: fig:executive-kirk-architecture
#+attr_latex: :width 0.6\textwidth
#+caption: A simplified, high-level overview of the Delay Kirk task executive architecture with respect to dispatching actions.
file:../images/executive-architecture.png

Figure [[fig:executive-kirk-architecture]] explicitly identifies the environment. We do so to highlight
that Kirk is designed to be able to interact with the outside world. For instance, if Kirk is
running on a robot, the environment might consist of the pose of the manipulator and any objects in
the scene. If Kirk is responsible for sending notifications to a digital assistant in a spacesuit,
then the environment might be the "as executed" version of an EVA timeline. In either case, actions
caused by Kirk will impact the environment. Likewise, Kirk learns from the environment. Here we show
event observations from the environment being sent to the scheduler. However, when Kirk is working
with sub-executives designed for specific problem domains, e.g. risk-bounded motion planning, it may
be monitoring other aspects of the environment as well.

Every Kirk has a planning component that takes RMPL as input, generates state plans, then checks
consistency using OpSAT. OpSAT is similar to a satisfiability (SAT) solver with the property that it
produces optimal assignment to real valued variables. Any temporal constraints in the state plan are
translated to a delay STNU then checked with the variable-delay controllability checker from Chapter
[[ch:modeling-tn]].

If the overall state plan is satisfiable, it is then sent to the delay scheduler. Note that earlier
we have said that the delay scheduler takes a temporal network as input. However, Figure
[[fig:executive-kirk-architecture]] shows a state plan as input to the delay scheduler. Functionally,
there is no difference. There is a one-to-one relationship between state plans and delay STNUs. In
fact, as implemented for this thesis, the delay scheduler can take either a state plan or delay STNU
as input. If a state plan is received, then the first action taken is to convert the state plan to a
delay STNU.

RTEDs that the delay scheduler outputs are sent to a delay dispatcher. As a dispatcher, it has the
primary purpose of translating events to actions that can affect the environment. It is also
responsible for running the loop described in Algorithm [[alg:approach-delay-scheduler]]. With the
additional requirement of dispatching actions in the presence of observation delay, the delay
dispatcher manages buffered events (see Lemma [[lemma:buffering-imagining]]) to ensure they are sent to
the delay scheduler at the appropriate time.

** RMPL
<<sec:rmpl>>

# TODO better explanation
RMPL is a key component of Kirk. This section steps through example RMPL control programs to
describe their features and our modeling choices. The purpose of this section is three-fold:

1. A short walkthrough of the language is required in order to explain this thesis' contributions
   because an updated RMPL description in any form (e.g. manual, publication, or tutorial) has not
   been publicly released since 2003 [cite:@Williams2003]
2. We must describe the modeling choices of RMPL in sufficient detail to make concrete our approach
   to modeling temporal constraints in human-readble form
3. The above is used to demonstrate that modeling uncertain communication delay can be naturally
   modeled in RMPL

This section is not meant to be a complete documentation of RMPL, rather our goal is to motivate the
strength of RMPL as a modeling language for human planners describing autonomous systems with
observation uncertainty.

RMPL has undergone a number of rewrites since its inception, and is currently being developed as a
superset of the Common Lisp language using the Metaobject Protocol [cite:@Kiczales1991]. The goal is
that a human should have a comfortable means for accurately modeling sufficient detail about the
problem domain such that an executive can perform model-based reasoning to decide how to act.

# TODO does this sentence go with the paragraph above?
# RMPL should /never/ include explicit programming instructions for the executive.

RMPL and Kirk can be used to achieve a number of different goals. These include but are not limited
to temporal scheduling, classical planning, hybrid planning. For this thesis, we focus on temporal
scheduling and the ability for a human to write /control programs/, or composable constraints and
goals.

For this thesis, we take the assumption that each Kirk executive is responsible for a single agent.
We also ignore vehicle dynamics given this thesis' focus on contributions to temporal scheduling.
However, RMPL is more flexible and allows multi-agent planning and motion planning using vehicle
dynamics, which will be briefly described in Section [[sec:rmpl-agents]].

An example of an RMPL control program for a single-agent without agent dynamics follows in Listing
[[code:example-control-program]].

#+name: code:example-control-program
#+caption: A sample control program composed of three constraints. =eat-breakfast= and =bike-to-lecture= designate controllable constraints, while the =main= control program enforces that the constraints are satisfied in series.
#+begin_src lisp
;; NOTE: we omitted Lisp package definitions here for simplicity's sake

(define-control-program eat-breakfast ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program bike-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program main ()
  (with-temporal-constraint (simple-temporal :upper-bound 40)
    (sequence (:slack nil)
              (eat-breakfast)
              (bike-to-lecture))))
#+end_src

Looking past the parentheses, we can see different options for defining temporal constraints. For
example, the =(duration (simple ...))= form is used to define a set-bounded temporal constraint
between a =:lower-bound= and an =:upper-bound=. The =main= control program uses a different form,
=(with-temporal-constraint ...)= to place an =:upper-bound= on the overall deadline for scheduling
all events in the control program.

The example control programs in Listing [[code:example-control-program]] are defined without agents in
that there is an assumption that the Kirk instance that executes this control program must know what
the semantics of =eat-breakfast= and =bike-to-lecture= mean and how to execute them.

It could also be the case that Kirk is simply being used to produce a schedule of events offline
that will be handed to an agent that knows how to execute them. As an example, perhaps a student
wants some help planning their morning, so they write an RMPL control program with constraints
representing everything they need to do between waking up and going to lecture, as seen in the more
complex control program in Listing [[code:morning-lecture]]. The student could ask Kirk to produce a
schedule of events that satisfies all the temporal constraints in this RMPL control program, which
they would then use to plan their morning routine. See the resulting schedule produced by Kirk in
Table [[tab:morning-lecture-schedule]]. (Note that while normally times in RMPL are represented in
seconds, we use minutes in Listing [[code:morning-lecture]] and Table [[tab:morning-lecture-schedule]] for
simplicity's sake.)

#+name: code:morning-lecture
#+caption: A student's morning routine preparing for lecture as modeled in RMPL. This is a complete RMPL program that includes the required Lisp package definitions to run in Kirk.
#+begin_src lisp -n -r
;; This file lives in the thesis code repo at:
;;      kirk-v2/examples/morning-lecture/script.rmpl
;;
;; To execute this RMPL control program as-is and generate a schedule, go to the root
;; of the thesis code repo and run the following command:
;;
;; kirk run kirk-v2/examples/morning-lecture/script.rmpl \
;;      -P morning-lecture \
;;      --simulate

(rmpl/lang:defpackage #:morning-lecture)

(in-package #:morning-lecture)

(define-control-program shower ()
  (declare (primitive)
           (duration (simple :lower-bound 5 :upper-bound 10))))

(define-control-program eat-breakfast ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program review-scheduling-notes ()
  (declare (primitive)
           (duration (simple :lower-bound 10 :upper-bound 15))))

(define-control-program review-planning-notes ()
  (declare (primitive)
           (duration (simple :lower-bound 10 :upper-bound 15))))

(define-control-program pack-bag ()
  (declare (primitive)
           (duration (simple :lower-bound 5 :upper-bound 6))))

(define-control-program bike-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program review-notes ()
  (sequence (:slack t)
    (review-scheduling-notes)
    (review-planning-notes)))

(define-control-program main ()
  (with-temporal-constraint (simple-temporal :upper-bound 60)
    (sequence (:slack t)
      (shower)
      (parallel (:slack t) (ref:parallel)
        (eat-breakfast)
        (review-notes))
      (pack-bag)
      (bike-to-lecture))))
#+end_src

#+name: tab:morning-lecture-schedule
#+caption: The schedule produced by Kirk's scheduler for the student's routine before lecture as modeled in Listing [[code:morning-lecture]]. Note: Kirk's output has been cleaned for readability purposes.
#+ATTR_LATEX: :align left
| *Event*                         | *Time (min)* |
|---------------------------------+--------------|
| =START=                         |            0 |
| Start =shower=                  |            1 |
| End =shower=                    |            6 |
| Start =review-scheduling-notes= |            6 |
| Start =eat-breakfast=           |            6 |
| End =review-scheduling-notes=   |           16 |
| Start =review-planning-notes=   |           16 |
| End =eat-breakfast=             |           21 |
| End =review-planning-notes=     |           26 |
| Start =pack-bag=                |           26 |
| End =pack-bag=                  |           31 |
| Start =bike-to-lecture=         |           32 |
| End =bike-to-lecture=           |           46 |
| =END=                           |           46 |

Listing [[code:morning-lecture]] introduces the notion of control programs that are allowed to be
executed simultaneously, as modeled with the =(parallel ...)= form found in the =main= control
program on line [[(parallel)]].

Kirk is able to simulate the RMPL script in Listing [[code:morning-lecture]] and produce a schedule
because there were no uncontrollable constraints, that is, all control programs are under the
agent's control. Say we replaced =bike-to-lecture= with =drive-to-lecture=. Due to traffic
conditions, driving presents in an uncontrollable constraint. RMPL allows us to model uncontrollable
constraints as in Listing [[code:drive-to-lecture]].

#+name: code:drive-to-lecture
#+caption: An uncontrollable, or contingent, temporal constraint in a control program.
#+begin_src lisp
(define-control-program drive-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20)
                     :contingent t)))
#+end_src

The addition of =:contingent t= to the =(duration ...)= form tells Kirk that it does not have
control over when the end of =drive-to-lecture= is scheduled, rather, Nature (i.e. traffic
conditions) chooses a time. Despite the lack of control over =drive-to-lecture=, we do know the
drive should take between 15 and 20 minutes, hence our model includes =:lower-bound 15= and
=:upper-bound 20=.

With uncontrollable constraints in a control program, we are no longer guaranteed to be able to
produce a schedule offline as we show in Table [[tab:morning-lecture-schedule]]. Instead, as time
passes, we may only choose to schedule controllable events based on the /partial history/ of
contingent event assignments so far, or, in other words, perform /dynamic scheduling/. Thus, we can
no longer simulate a schedule with Kirk. We must connect Kirk to a source for receiving contingent
event assignments in order to make valid controllable event assignments. Our approach to dynamic
scheduling is the focus of Chapter [[ch:delay-scheduling]].

As a contribution of this thesis, our existing approach to specifying durations in RMPL was expanded
to model observation delay. An example follows in Listing [[code:rmpl-obs-delay]] modeling a sample
collection control program with observation delay.

#+name: code:rmpl-obs-delay
#+caption: An RMPL control program describing a science data collection task with observation delay.
#+begin_src lisp
(define-control-program collect-science-sample ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 30
                             :min-observation-delay 5
                             :max-observation-delay 15)
                     :contingent t)))
#+end_src

We can see in Listing [[code:rmpl-obs-delay]] that representing set-bounded observation delay is a
simple as adding =:min-= and =:max-observation-delay= to the =(duration (simple ...) :contingent t)=
form. In full, this control program represents an uncontrollable constraint with a contingent event
that Nature will schedule $[15, 30]$ time units after sample collection begins. The executive will
then wait an additional $[5, 15]$ time units before learning that =collect-science-sample= has been
scheduled. As will be described in much greater detail in Section [[sec:vdc]], the executive will only
learn /that/ the contingent event occurred - is not guaranteed to learn where in $[15, 30]$ the
contingent event was assigned, nor will it know how much observation delay was incurred.

*** Multi-Agent Control Programs
<<sec:ma-control-programs>>

# It's hard to write MA RMPL by hand

# TODO is what I'm describing here more of an RMPL restriction? why did (:slack t) not work?
# TODO what this is describing is more of a problem with (:slack nil)?

# TODO paragraph probably needs to be broken up. part of the claim needs to be moved into the chapter intro
This thesis introduces challenges in writing control programs for multiple agents who need to
coordinate. We do not claim to solve all aspects of coordination, rather we present a framework for
simple scenarios with the key feature being that agents need to agree on the /order/ of a subset of
events. We start by presenting an example of inter-agent temporal constraints, followed by defining
a modeling technique for guaranteeing that agents agree about the order of events in their
respective partial histories. To the best of our knowledge, we are unaware of any other MA framework
for coordinating the order of event histories.

# TODO do we need to define "semantically similar"?
Consider two agents, =agent1= and =agent2=, that are scheduling STNUs $S_{1}$ and $S_{2}$
respectively. $S_{1}$ and $S_{2}$ share a subset of semantically similar episodes, $e_{1}$ and
$e_{2}$. =agent1= "owns" $e_{1}$, meaning it is responsible for scheduling the free event
$e_{1}$​-start and observing the contingent event $e_{1}$​-end, while =agent2= owns $e_{2}$. It is the
case that $e_{1}$ must precede $e_{2}$ in $S_{1}$ and $S_{2}$. A simplified MA view of the
constraints is as follows.

$$
\conedge{e_{1}\text{-start}}{e_{1}\text{-end}}{[15, 30]}
\edge{}{e_{2}\text{-start}}{[0, \infty]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

From =agent1='s perspective, $S_{1}$ models the following constraints. We add a =noop= start event,
$Z$, to simplify coordination. For now, we allow chained contingencies, though in a moment they will
need to be addressed.

$$
\edge{Z}{e_{1}\text{-start}}{[0, 0]}
\conedge{}{e_{1}\text{-end}}{[15, 30]}
\conedge{}{e_{2}\text{-start}}{[0, \infty]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

We assume that =agent1= models $e_{2}$ in $S_{1}$ because other events under their control depend on
$e_{2}$. $S_{2}$ is then modeled as follows. Note the change to the controllability of
$\conedge{Z}{e_{1}\text{-start}}{[0, 0]}$.

$$
\conedge{Z}{e_{1}\text{-start}}{[0, 0]}
\conedge{}{e_{1}\text{-end}}{[15, 30]}
\edge{}{e_{2}\text{-start}}{[0, \infty]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

For the sake of controllability of $S_{1}$ and $S_{2}$, we would simply add $[0, 0]$ free
constraints between consecutive contingent constraints. Also note that from a scheduling standpoint,
there is no difference between $\edge{a}{b}{[0, 0]}$ and $\conedge{a}{b}{[0, 0]}$ - both indicate
$a$ and $b$ should be scheduled simultaneously.

We will walk through scheduling this scenario from the perspective of both agents. First, we
describe their actions in the case that there is no communication delay, then we introduce
communication, and finally we add delay to communications. This scenario will motivate our analysis
of the challenges that arise in MA control programs.

# TODO maybe we don't even need to include the "instantaneous knowledge" version of events here
If both agents have perfect knowledge of the world (instantaneous knowledge of events), scheduling
is trivial. =agent1= and =agent2= execute $Z$ simultaneously. =agent1= schedules $e_{1}$​-start and
=agent2= instantaneously receives an observation of $e_{1}$​-start. $e_{1}$​-end arrives in $[15, 30]$
later, which again, both agents observe simultaneously. Now =agent2= is free to act. It schedules
$e_{2}$​-start, which =agent1= observes instantaneously. $e_{2}$​-end arrives $[22, 26]$ later and is
observed simultaneously by both agents.

# TODO check assumption of instantaneous execution
Now, we enforce that =agent1= "owns" $e_{1}$ and is the only agent that can observe it directly.
Likewise, =agent2= owns $e_{2}$. In order for an agent to learn about an episode they do not own,
they must receive a communication from the agent who does. After =agent1= schedules $e_{1}$​-start,
it must send a message to =agent2=. =agent2= receives said message, which it interprets as an
observation of $e_{1}$​-start. If communications are instantaneous, the partial histories of both
agents agree on the assignment of $e_{1}$​-start. Later $e_{1}$​-end is observed by =agent1=, who is
then responsible for relaying a communication to =agent2= indicating that it is safe to assign
$e_{1}$​-end. =agent2= is now free to schedule $e_{2}$​-start, which it does instantaneously. The same
pattern of sending messages that events have been scheduled repeats and =agent1= learns that
$e_{2}$​-start was schedule simultaneously with $e_{1}$​-end. After all events have been scheduled,
the histories of =agent1= and =agent2= still agree on the times assigned to each event.

We now show that adding delay to the communications between agents forces us to add
/synchronization/ episodes to $S_{1}$ and $S_{2}$ to maintain event ownership. First, we must
address the chained contingencies. Note that we have freedom in how we model the constraints of this
scenario. The following example will motivate the need for a synchronization episode while remaining
as close to the semantics of the original STNU as possible.

From the perspective of =agent1=, $S_{1}$, we cannot escape the fact that there are two
uncontrollable events in sequence - the end of $e_{1}$ and the start of $e_{2}$, if we try to
separate the events with a synthetic requirement episode, $\sigma$, with a $[0, \infty]$ constraint,
the semantics no longer respect the original scenario.

$$
\edge{Z}{e_{1}\text{-start}}{[0, 0]}
\conedge{}{e_{1}\text{-end}}{[15, 30]}
\edge{}{\sigma\text{-start}}{[0, 0]}
\edge{}{\sigma\text{-end}}{[0, \infty]}
\conedge{}{e_{2}\text{-start}}{[0, 0]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

The delay scheduler will choose to schedule $\sigma$​-end simultaneously with $\sigma$​-start, also
leading to $e_{2}$​-start being immediately scheduled. However, $e_{2}$ is not under =agent1='s
control, and thus it has no authority to schedule $e_{2}$​-start. Instead, our synthetic constraint
also needs to be contingent.

$$
\edge{Z}{e_{1}\text{-start}}{[0, 0]}
\conedge{}{e_{1}\text{-end}}{[15, 30]}
\edge{}{\sigma\text{-start}}{[0, 0]}
\conedge{}{\sigma\text{-end}}{[0, \infty]}
\edge{}{e_{2}\text{-start}}{[0, 0]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

Now, the issue is that $S_{1}$ is uncontrollable due to
$\conedge{\sigma\texttt{-start}}{\sigma\texttt{-end}}{[0, \infty]}$. We know the =agent2= will
receive $e_{1}$​-end somewhere in $\gammabar'(e_{1}\texttt{-end})$, where the $\gammabar'$ function
represents observation delay in $S_{2}$. =agent2= will then immediately schedule $e_{2}$​-start.
Finally, $S_{1}$ becomes

$$
\edge{Z}{e_{1}\text{-start}}{[0, 0]}
\conedge{}{e_{1}\text{-end}}{[15, 30]}
\edge{}{\sigma\text{-start}}{[0, 0]}
\conedge{}{\sigma\text{-end}}{[\gammabar'^-(e_{1}\texttt{-start}), \gammabar'^-(e_{1}\texttt{-end})]}
\edge{}{e_{2}\text{-start}}{[0, 0]}
\conedge{}{e_{2}\text{-end}}{[22, 26]}
$$

In practice, an agent may choose to schedule other events while waiting for $\sigma$​-end to arrive.

In $S_{2}$, we may choose to give =agent2= the same synchronization episode without changing the
execution semantics. We know that $e_{1}$​-end will be observed somewhere in
$\gammabar'(e_{1}\texttt{-end})$. When $e_{1}$​-end arrives, we are guaranteed to have waited
somewhere in the lower and upper bounds $\sigma$. Assuming =agent2= knows that $e_{1}$​-end and
$\sigma$​-end semantically represent the same point in time, $\sigma$​-end can be safely scheduled as
soon as $e_{1}$​-end arrives.

# where, according to the way RMPL is compiled to STNUs (see Appendix [[appendix:rmpl]]), $[l, u]$ may
# take on either $[0, 0]$ or $[0, \infty]$ bounds. Regardless, =robot-drilling:start= is a
# controllable event, meaning the astronaut is allowed to choose when to schedule it. The envisioned
# scenario does not allow the astronaut to decide when the robot is allowed to start drilling. Hence,
# we added an uncontrollable =sync= episode to ensure that the astronaut must wait to receive
# =robot-drilling:start= from the robot. The robot also has a =sync= episode, which ensures that both
# agents agree on the naming of events. Finally, the last salient feature of =sync= to highlight is
# that bounds of =sync= match the bounds of the observation delay for =human-downlink-science=
# according to the robot. This correlation ensures that the robot can schedule =sync:end= immediately
# upon observing =human-downlink-science:end= because any resolution of observation delay of
# =human-downlink-science:end= also satisfies the constraint between =sync:start= and =sync:end=.

Synchronization episodes allow inter-agent constraints with observation delay to be modeled without
impacting the ordering of events. They are used to separate control programs in the hardware
demonstration in Section [[sec:hw-demo]].


*** Action Model
<<sec:rmpl-agents>>

This section is included to expand on the features of RMPL, though note that none of these features
are required for controlling distributed agents, and were not a part of the experiments for this
research.

If we wanted to specify agents in a multi-agent control program, or if we wanted to take vehicle
dynamics into account, RMPL gives us a means for using the Common Lisp Object System (CLOS) for
defining agents, agent dynamics, and the control programs agents may execute.

An example RMPL control program with an agent is provided in Listing [[code:glider-simple]] for
completeness sake from the domain of underwater robotics.

#+name: code:glider-simple
#+caption: A snippet of an RMPL script that defines an agent and classical planning predicates and effects of a control program.
#+begin_src lisp
;; This code is a snippet from a file in the thesis code repo found at:
;;      kirk-v2/examples/glider/script.rmpl

(defclass glider ()
  ((id
    :initarg :id
    :finalp t
    :type integer
    :reader id
    :documentation
    "The ID of this glider.")
   (deployed-p
    :initform nil
    :type boolean
    :accessor deployed-p
    :documentaiton
    "A boolean stating if the glider is deployed at any point in time.")
   (destination
    :initform nil
    :type (member nil "start" "end" "science-1" "science-2")
    :accessor destination
    :documentation
    "The location to which the glider is currently heading, or NIL if it is not
    in transit.")
   (location
    :initarg :location
    :initform "start"
    :type (member nil "start" "end" "science-1" "science-2")
    :accessor location
    :documentation
    "The location where the glider is currently located, or NIL if it is not at
    a location (in transit).")))

(define-control-program move (glider to)
  (declare (primitive)
           (requires (and
                      (over :all (= (destination glider) to))))
           (effect (and
                    (at :start (= (destination glider) to))
                    (at :start (= (location glider) nil))
                    (at :end (= (destination glider) nil))
                    (at :end (= (location glider) to))))
           (duration (simple :lower-bound 10 :upper-bound 20))))
#+end_src

In Listing [[code:glider-simple]], =glider= refers to a low-powered autonomous underwater vehicle that
prefers to traverse by following ocean currents using a buoyancy engine.[fn:: The Slocum Glider is
an example: [[https://www.whoi.edu/what-we-do/explore/underwater-vehicles/auvs/slocum-glider/][https://www.whoi.edu/what-we-do/explore/underwater-vehicles/auvs/slocum-glider/.]]] We see
that we model a =glider= agent and its properties using standard CLOS. The =move= control program
then takes a =glider= and a =location= as arguments. The =(requires ...)= form is equivalent to the
preconditions of a durative action in a PDDL 2.1 [cite:@Fox2003] domain. Likewise, the =(effect
...)= form is equivalent to PDDL effects. Finally, as we saw before, the durative action also
includes a temporal constraint in its =(duration ...)= form.

Kirk is able to take RMPL as input to perform classical planning, though further discussion of it
falls outside the scope of this thesis.


