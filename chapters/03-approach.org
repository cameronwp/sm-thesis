#+title: Approach

* COMMENT
- for inter-agent communication as well as the observations agents make of the environment.
- where do we differentiate between existing work and the novel work of the thesis?
- With a model-based approach to autonomy, a human should not write an explicit program for solving
  the problem domain. Instead, the executive should take full responsibility for taking a model from
  a human and producing safe actions according to the constraints provided.
- Furthermore, extending either approach [MASTNUs and HR] likely would have been non-trivial and
  would have expanded the scope of this thesis significantly.

** TODO do we need to describe how each component is tested?
** TODO check ref for where VDC experiments live
I say they're at the end of the vdc chapter, but they currently aren't there.
** TODO we may not need to delineate between agent and executive. "multi-agent" is kind of a problem if we do
** IDEA does the discussion of what we could have done belong in the discussion section instead?
** Robustness

Autonomy research tends to focus on ideal, generic executives that behave perfectly. For instance,
temporal reasoning research assumes that controllable events are executed instantaneously at the
exact correct time without fail. Reality cannot conform to ideal conditions. At minimum, CPU cycles
will tick by before a scheduled event is dispatched, causing the hands of precise clocks to move
when our algorithms expect them to remain static. To run on hardware, executives and agents must
communicate, which adds additional time that is unaccounted for in scheduling algorithms. And
finally, we need to explicitly decide how to translate temporal events to messages that hardware can
execute. Given our need to deploy Kirk on real hardware, we contribute a seemingly disparate set of
algorithms removing expectations of idealized performance, that, when taken together, enable
deployment of temporal reasoning algorithms in real agents.

We include five contributions to dynamic scheduling and dispatching for enabling robust executives.

1. A well defined architecture for event execution with distinct scheduler, dispatcher, and driver
   responsibilities
2. Tolerance in event scheduling
3. Controllable event preemption
4. The separation of real and =noop= controllable events in execution decisions
5. A clock-synchronized approach for managing repeated tasks during online execution

# There lacks research into the design of interfaces between executives and agents.

TODO given the hardware experiments of this thesis...

This thesis identifies addresses three core issues...

We improve the delay scheduler by differentiating real and =noop= controllable events...

We remove the assumption that controllable events are instantaneously executed...

We identify drawbacks in na√Øve approaches to building executives using parallel and concurrent
processes. We propose a clock-synchronized architecture that addresses challenges in simulating
executives and better matches our expectations of order of operations behavior as programmers.


* Approach
<<ch:approach>>

# TODO clean up first sentence
# TODO mention VDC or delay scheduling here?
For addressing our problem statement, we envision that a high-level executive should take
responsibility for managing task planning and execution with respect to temporal constraints. For
this thesis, we chose to extend an existing high-level task and motion planner, /Kirk/
[cite:@Williams2003]. Kirk is a complete, end-to-end executive in that it can take human-friendly
problem specifications as input and send commands to hardware as output.

To clarify terminology in this thesis, the term /executive/ refers to Kirk and its subsystems, while
/agent/ refers to the combination of an executive and the system it controls that interacts with the
outside world, e.g. robotic hardware.

At a high-level, Kirk works by first taking a description of the problem domain as written by domain
experts, which should include the constraints, agent dynamics, environment, and starting and goal
states of the problem at hand. Kirk then generates and checks plans using an optimal satisfiability
(OpSAT) solver [cite:@Williams2007], elaborates temporal plan networks (TPNs) [cite:@Kim2001] to
sub-executives when it encounters constraints and goals it cannot plan against directly, and
eventually dispatches event schedules and motion plans to hardware. For the purpose of this thesis,
we focus on Kirk's capability to dispatch events online after a plan has been generated.

# TODO add this to above
Kirk operates on qualitative state plans, which consist of episodes that organize the occurrance of
events as activities. Also includes causal links (:effects and :requires ala STRIPS/PDDL planning).
All passed to OpSAT, which is like an SMT solver. Makes choices through causal links to decompose
state constraints into a SAT problem and then solve. Temporal constraints go to
temporal-controllability. State plan gets turned into a SAT solver, with ordering from temporal
constraints.

# TODO this would be a good place for a diagram of Kirk's overall pipeline

Some aspects of Kirk were already well-suited for coordinating multiple agents under observation
delay, others were not. Specifically, our approach required research contributions in three key
areas, which were then implemented in Kirk:

1. /Modeling and Controllability/: prior to execution, we must be able to model communication delay
   separate from temporal constraints, as well as guarantee that all temporal constraints can be
   satisfied
2. /Scheduling/: during execution, executives must be able to dynamically schedule and dispatch
   events respecting temporal constraints in spite of observation delay
3. /Coordination/: during execution, peer executives must be able to share event assignments and
   observations

Our approach to each research focus will be described below.

# TODO do we need to say something about evaluation here? how do we want to evaluate our approach?

** Modeling and Controllability

We take a model-based approach to deploying autonomous systems, that is, prior to a mission, we
envision that engineers and domain experts work together to model the system at hand, then during
the mission (though not necessarily online), the autonomous system then takes the models as input
and decides how to act as output. There are three core challenges with modeling - the first being
that we need formalisms that can be ingested by our algorithms and be used to guarantee safe
execution. In other words, we need a data type to represent the phenomenon over which we want the
algorithms comprising our system to reason. Next, the chosen formalism must allow us to guarantee
the satisfiability of the system, i.e. the autonomous system must be able to act in a safe manner
respecting all constraints to go from the starting state to the goal state. The third challenge is
that we need a human-friendly form of said formalisms such that human domain experts, who are
unlikely to also be experts in autonomy, can still model their domains accurately enough such that
the desired safe behavior is exhibited by the autonomous system. We address each challenge in our
approach to modeling.

States and constraints can take on arbitrary forms, and how they are modeled depends entirely on the
problem domain. Classical planning problems use boolean predicates and actions to model the world
(e.g. STRIPS planning problems [cite:@Fikes1971]). Scheduling problems involving time constraints
will have continuous temporal bounds between discrete timepoints (e.g. in the form of temporal
constraint graphs [cite:@Dechter1991]). Other scenarios where motion planning is the focus will
likely be modeled with vectors of continuous values in $\mathbb{R}$ (e.g. often representing convex
regions as in the case of the /Magellan/ planner [cite:@FernandezGonzalez2018]). Hybrid domains
combine states and constraints with mixed continuous and discrete values (e.g. using mixed-integer
linear programs as demonstrated by Chen et al. [cite:@Chen2021a]).

Given this thesis' emphasis on temporal scheduling, we choose to focus entirely on formalisms where
states and constraints are temporal in nature. The starting state of the system is, by definition,
one where time is set to $0$ seconds, $t = 0$, and no events have been executed (i.e. no event
assignments have been made). We then define controlled and uncontrolled set-bounded constraints
between events. The goal state is one where times have been assigned to each controllable event such
that all constraints are satisfied. To do so, we build our formalisms representing temporal
constraints with set-bounded observation delay on top of simple temporal networks with uncertainty
(STNUs) [cite:@Vidal1999]. A brief explanation of our modeling strategy for temporal constraints
with observation delay follows in Section [[sec:obs-delay-in-stnus]], though we will elaborate on
temporal reasoning and our chosen formalisms for it in much more detail in Chapter [[ch:modeling-tn]].

With a modeling formalism in hand, the second key challenge is to use the formalism to guarantee a
property known as /controllability/, or that all controllable temporal constraints can be satisfied
given the existing uncertainty in the STNU. There already exist a number of strategies for checking
the controllability of STNUs. Examples of different strategies include the canonical work by Morris,
Muscettola, and Vidal in checking for semi-reducible negative cycles (SRNCs)
[cite:@MMV2001;@Morris2005;@Morris2006;@Morris2014], as well as reframing controllability as a
Satisfiable Modulo Theory (SMT) problem [cite:@Cimatti2012;]. In our approach to controllability
under observation uncertainty, we build on top of checks for SRNCs as will be shown in [[sec:vdc]].

# TODO is there a better sentence to start this paragraph?
For the third challenge, we choose to extend the Reactive Model-Based Programming Language (RMPL)
[cite:@RMPL2002], which provides to domain experts a means for describing the constraints and goal
states of their domain without requiring additional expertise in autonomy. With RMPL, a human
planner is capable of building control programs describing the constraints, agents, and states of
the problem domain in a way that is human-readable yet highly programmable, and is independent of
the underlying algorithms used by the autonomous system. As will be explained in Section [[sec:rmpl]]
below, our approach was to add the ability for planners to model observation delay alongside
temporal constraints in RMPL.

*** Modeling Uncertain Observation Delay in STNUs
<<sec:obs-delay-in-stnus>>

In the case of observation delay, our model dictates that we reason over two time intervals. The
first time interval represents the true length of time between two events, while the second interval
represents the length of time between when an event occurs and when an executive observes the event.
For ensuring that an executive takes safe actions in an uncertain environment, we assume worst-case
scenario with respect to information gain. Our approach to modeling uncertain observation delay in
STNUs is as follows.

1. The duration of time between two events is represented as a set-bounded interval
2. The duration of time between an event and its observation (observation delay) is represented as a
   set-bounded interval
3. Timestamps in event observations are ignored
4. The true duration of observation delay is not guaranteed to be learned

The first point comes directly from the STNU formalism (see Section [[sec:tn]]). The second point allows
for uncertainty in the amount of observation delay, e.g. in an uncertain environment, we could model
observation delay for a given event as, say, $[1, \infty]$, meaning an observation of an event could
arrive one second after it occurs, or never arrive, or arrive at some arbitrary time, $t$, $1 < t \leq
\infty$ later. The third point comes from assuming worst-case scenario and prevents us from
"cheating" in our scheduling algorithm. For instance, imagine two agents coordinating. If agents
passed timestamp information along with events to one another, they must also be able to synchronize
their clocks, potentially to an arbitrary degree of precision. The challenge of synchronizing clocks
between agents is outside the scope of this thesis and may not always be possible. As such,
executives only trust their own clocks. Rather than backfill potentially erroneous times for event
assignments as reported by exogenous sources, the executive we envision in this thesis records times
that are internally consistent with its own clock. Doing so guarantees that the actions the
executive takes as a result of temporal reasoning are consistent with its model.

The fourth point, that we are not guaranteed to learn event assignments, is a result of the first
three. It stands to reason that an event observation is a function of the true assignment of an
event and its observation delay. If there is uncertainty in both the event assignment and delay,
then we have one equation with two unknowns. Thus, the term "uncertain" in uncertain observation
delay means that we are forced to reason with deciding when to act even when we are not guaranteed
to learn the true times assigned to events.

# TODO where do the VDC experiments live? is this the end of ch:modeling-tn the right reference?

We call STNUs with variable observation delay /variable-delay STNUs/, which Bhargava first proposed
as the underlying data structure for checking Variable-Delay Controllability (VDC)
[cite:@Bhargava2018;@Bhargava2020;]. We (Pittman) co-authored a journal article with Bhargava that
was submitted to the Journal of AI Research presenting VDC and its chance constrained variant. We
include VDC as a contribution of this thesis, given that we (Pittman) wrote or rewrote a significant
portion of the VDC article, notably including a rewrite of key proofs with novel explanations. The
new proofs will will be presented in Section [[sec:vdc]]. Additionally, we rewrote the comparison of VDC
to Partially Observable STNUs (POSTNUs) [cite:@Moffitt2007], including identifying and correcting a
mistake in the same comparison as originally put forth by Bhargava in [cite:@Bhargava2020]. See
Appendix [[appendix:postnus]] for an in-depth comparison to POSTNUs. We designed and ran the
quantitative evaluation of VDC in the article. The same experiments will be included at the end of
Chapter <<ch:modeling-tn>>.

We formalize event observations and observation delay in Section [[sec:vdc]].

*** Modeling Observation Delay in RMPL
<<sec:rmpl>>

# TODO better explanation
RMPL is a key component of Kirk. This section steps through example RMPL control programs to
describe their features and our modeling choices. The purpose of this section is three-fold:

1. A short walkthrough of the language is required in order to explain this thesis' contributions
   because an updated RMPL description in any form (e.g. manual, publication, or tutorial) has not
   been publicly released since 2003 [cite:@Williams2003]
2. We must describe the modeling choices of RMPL in sufficient detail to make concrete our approach
   to modeling temporal constraints in human-readble form
3. The above is used to demonstrate that modeling uncertain communication delay can be naturally
   modeled in RMPL

This section is not meant to be a complete documentation of RMPL, rather our goal is to motivate the
strength of RMPL as a modeling language for human planners describing autonomous systems with
observation uncertainty.

RMPL has undergone a number of rewrites since its inception, and is currently being developed as a
superset of the Common Lisp language using the Metaobject Protocol [cite:@Kiczales1991]. The goal is
that a human should have a comfortable means for accurately modeling sufficient detail about the
problem domain such that an executive can perform model-based reasoning to decide how to act.

# TODO does this sentence go with the paragraph above?
# RMPL should /never/ include explicit programming instructions for the executive.

RMPL and Kirk can be used to achieve a number of different goals. These include but are not limited
to temporal scheduling, classical planning, hybrid planning. For this thesis, we focus on temporal
scheduling and the ability for a human to write /control programs/, or composable constraints and
goals.

For this thesis, we take the assumption that each Kirk executive is responsible for a single agent.
We also ignore vehicle dynamics given this thesis' focus on contributions to temporal scheduling.
However, RMPL is more flexible and allows multi-agent planning and motion planning using vehicle
dynamics, which will be briefly described in Section [[sec:rmpl-agents]].

An example of an RMPL control program for a single-agent without agent dynamics follows in Listing
[[code:example-control-program]].

#+name: code:example-control-program
#+caption: A sample control program composed of three constraints. =eat-breakfast= and =bike-to-lecture= designate controllable constraints, while the =main= control program enforces that the constraints are satisfied in series.
#+begin_src lisp
;; NOTE: we omitted Lisp package definitions here for simplicity's sake

(define-control-program eat-breakfast ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program bike-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program main ()
  (with-temporal-constraint (simple-temporal :upper-bound 40)
    (sequence (:slack nil)
              (eat-breakfast)
              (bike-to-lecture))))
#+end_src

Looking past the parentheses, we can see different options for defining temporal constraints. For
example, the =(duration (simple ...))= form is used to define a set-bounded temporal constraint
between a =:lower-bound= and an =:upper-bound=. The =main= control program uses a different form,
=(with-temporal-constraint ...)= to place an =:upper-bound= on the overall deadline for scheduling
all events in the control program.

The example control programs in Listing [[code:example-control-program]] are defined without agents in
that there is an assumption that the Kirk instance that executes this control program must know what
the semantics of =eat-breakfast= and =bike-to-lecture= mean and how to execute them.

It could also be the case that Kirk is simply being used to produce a schedule of events offline
that will be handed to an agent that knows how to execute them. As an example, perhaps a student
wants some help planning their morning, so they write an RMPL control program with constraints
representing everything they need to do between waking up and going to lecture, as seen in the more
complex control program in Listing [[code:morning-lecture]]. The student could ask Kirk to produce a
schedule of events that satisfies all the temporal constraints in this RMPL control program, which
they would then use to plan their morning routine. See the resulting schedule produced by Kirk in
Table [[tab:morning-lecture-schedule]]. (Note that while normally times in RMPL are represented in
seconds, we use minutes in Listing [[code:morning-lecture]] and Table [[tab:morning-lecture-schedule]] for
simplicity's sake.)

#+name: code:morning-lecture
#+caption: A student's morning routine preparing for lecture as modeled in RMPL. This is a complete RMPL program that includes the required Lisp package definitions to run in Kirk.
#+begin_src lisp -n -r
;; This file lives in the thesis code repo at:
;;      kirk-v2/examples/morning-lecture/script.rmpl
;;
;; To execute this RMPL control program as-is and generate a schedule, go to the root
;; of the thesis code repo and run the following command:
;;
;; kirk run kirk-v2/examples/morning-lecture/script.rmpl \
;;      -P morning-lecture \
;;      --simulate

(rmpl/lang:defpackage #:morning-lecture)

(in-package #:morning-lecture)

(define-control-program shower ()
  (declare (primitive)
           (duration (simple :lower-bound 5 :upper-bound 10))))

(define-control-program eat-breakfast ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program review-scheduling-notes ()
  (declare (primitive)
           (duration (simple :lower-bound 10 :upper-bound 15))))

(define-control-program review-planning-notes ()
  (declare (primitive)
           (duration (simple :lower-bound 10 :upper-bound 15))))

(define-control-program pack-bag ()
  (declare (primitive)
           (duration (simple :lower-bound 5 :upper-bound 6))))

(define-control-program bike-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20))))

(define-control-program review-notes ()
  (sequence (:slack t)
    (review-scheduling-notes)
    (review-planning-notes)))

(define-control-program main ()
  (with-temporal-constraint (simple-temporal :upper-bound 60)
    (sequence (:slack t)
      (shower)
      (parallel (:slack t) (ref:parallel)
        (eat-breakfast)
        (review-notes))
      (pack-bag)
      (bike-to-lecture))))
#+end_src

#+name: tab:morning-lecture-schedule
#+caption: The schedule produced by Kirk's scheduler for the student's routine before lecture as modeled in Listing [[code:morning-lecture]]. Note: Kirk's output has been cleaned for readability purposes.
#+ATTR_LATEX: :align left
| *Event*                         | *Time (min)* |
|---------------------------------+--------------|
| =START=                         |            0 |
| Start =shower=                  |            1 |
| End =shower=                    |            6 |
| Start =review-scheduling-notes= |            6 |
| Start =eat-breakfast=           |            6 |
| End =review-scheduling-notes=   |           16 |
| Start =review-planning-notes=   |           16 |
| End =eat-breakfast=             |           21 |
| End =review-planning-notes=     |           26 |
| Start =pack-bag=                |           26 |
| End =pack-bag=                  |           31 |
| Start =bike-to-lecture=         |           32 |
| End =bike-to-lecture=           |           46 |
| =END=                           |           46 |

Listing [[code:morning-lecture]] introduces the notion of control programs that are allowed to be
executed simultaneously, as modeled with the =(parallel ...)= form found in the =main= control
program on line [[(parallel)]].

Kirk is able to simulate the RMPL script in Listing [[code:morning-lecture]] and produce a schedule
because there were no uncontrollable constraints, that is, all control programs are under the
agent's control. Say we replaced =bike-to-lecture= with =drive-to-lecture=. Due to traffic
conditions, driving presents in an uncontrollable constraint. RMPL allows us to model uncontrollable
constraints as in Listing [[code:drive-to-lecture]].

#+name: code:drive-to-lecture
#+caption: An uncontrollable, or contingent, temporal constraint in a control program.
#+begin_src lisp
(define-control-program drive-to-lecture ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 20)
                     :contingent t)))
#+end_src

The addition of =:contingent t= to the =(duration ...)= form tells Kirk that it does not have
control over when the end of =drive-to-lecture= is scheduled, rather, Nature (i.e. traffic
conditions) chooses a time. Despite the lack of control over =drive-to-lecture=, we do know the
drive should take between 15 and 20 minutes, hence our model includes =:lower-bound 15= and
=:upper-bound 20=.

With uncontrollable constraints in a control program, we are no longer guaranteed to be able to
produce a schedule offline as we show in Table [[tab:morning-lecture-schedule]]. Instead, as time
passes, we may only choose to schedule controllable events based on the /partial history/ of
contingent event assignments so far, or, in other words, perform /dynamic scheduling/. Thus, we can
no longer simulate a schedule with Kirk. We must connect Kirk to a source for receiving contingent
event assignments in order to make valid controllable event assignments. Our approach to dynamic
scheduling is the focus of Section [[sec:approach-scheduling]].

As a contribution of this thesis, our existing approach to specifying durations in RMPL was expanded
to model observation delay. An example follows in Listing [[code:rmpl-obs-delay]] modeling a sample
collection control program with observation delay.

#+name: code:rmpl-obs-delay
#+caption: An RMPL control program describing a science data collection task with observation delay.
#+begin_src lisp
(define-control-program collect-science-sample ()
  (declare (primitive)
           (duration (simple :lower-bound 15 :upper-bound 30
                             :min-observation-delay 5
                             :max-observation-delay 15)
                     :contingent t)))
#+end_src

We can see in Listing [[code:rmpl-obs-delay]] that representing set-bounded observation delay is a
simple as adding =:min-= and =:max-observation-delay= to the =(duration (simple ...) :contingent t)=
form. In full, this control program represents an uncontrollable constraint with a contingent event
that Nature will schedule $[15, 30]$ time units after sample collection begins. The executive will
then wait an additional $[5, 15]$ time units before learning that =collect-science-sample= has been
scheduled. As will be described in much greater detail in Section [[sec:vdc]], the executive will only
learn /that/ the contingent event occurred - is not guaranteed to learn where in $[15, 30]$ the
contingent event was assigned, nor will it know how much observation delay was incurred.

*** Explicitly Modeling Agents in RMPL
<<sec:rmpl-agents>>

This section is included to expand on the features of RMPL, though note that none of these features
are required for controlling distributed agents, and were not a part of the experiments for this
research.

If we wanted to specify agents in a multi-agent control program, or if we wanted to take vehicle
dynamics into account, RMPL gives us a means for using the Common Lisp Object System (CLOS) for
defining agents, agent dynamics, and the control programs agents may execute.

An example RMPL control program with an agent is provided in Listing [[code:glider-simple]] for
completeness sake from the domain of underwater robotics.

#+name: code:glider-simple
#+caption: A snippet of an RMPL script that defines an agent and classical planning predicates and effects of a control program.
#+begin_src lisp
;; This code is a snippet from a file in the thesis code repo found at:
;;      kirk-v2/examples/glider/script.rmpl

(defclass glider ()
  ((id
    :initarg :id
    :finalp t
    :type integer
    :reader id
    :documentation
    "The ID of this glider.")
   (deployed-p
    :initform nil
    :type boolean
    :accessor deployed-p
    :documentaiton
    "A boolean stating if the glider is deployed at any point in time.")
   (destination
    :initform nil
    :type (member nil "start" "end" "science-1" "science-2")
    :accessor destination
    :documentation
    "The location to which the glider is currently heading, or NIL if it is not
    in transit.")
   (location
    :initarg :location
    :initform "start"
    :type (member nil "start" "end" "science-1" "science-2")
    :accessor location
    :documentation
    "The location where the glider is currently located, or NIL if it is not at
    a location (in transit).")))

(define-control-program move (glider to)
  (declare (primitive)
           (requires (and
                      (over :all (= (destination glider) to))))
           (effect (and
                    (at :start (= (destination glider) to))
                    (at :start (= (location glider) nil))
                    (at :end (= (destination glider) nil))
                    (at :end (= (location glider) to))))
           (duration (simple :lower-bound 10 :upper-bound 20))))
#+end_src

In Listing [[code:glider-simple]], =glider= refers to a low-powered autonomous underwater vehicle that
prefers to traverse by following ocean currents using a buoyancy engine.[fn:: The Slocum Glider is
an example: [[https://www.whoi.edu/what-we-do/explore/underwater-vehicles/auvs/slocum-glider/][https://www.whoi.edu/what-we-do/explore/underwater-vehicles/auvs/slocum-glider/.]]] We see
that we model a =glider= agent and its properties using standard CLOS. The =move= control program
then takes a =glider= and a =location= as arguments. The =(requires ...)= form is equivalent to the
preconditions of a durative action in a PDDL 2.1 [cite:@Fox2003] domain. Likewise, the =(effect
...)= form is equivalent to PDDL effects. Finally, as we saw before, the durative action also
includes a temporal constraint in its =(duration ...)= form.

Kirk is able to take RMPL as input to perform classical planning, though further discussion of it
falls outside the scope of this thesis.

** Scheduling Temporal Events
<<sec:approach-scheduling>>

The bulk of the technical chapters of this thesis, namely Chapters [[ch:modeling-tn]] and
[[ch:delay-scheduling]], describe the algorithmic insights behind the /delay scheduler/. The delay
scheduler dispatches controllable events online for dynamically controllable STNUs while reasoning
over observation delay in the uncontrollable events it receives. There were two key contributions
that enabled the delay scheduler.

Reasoning over the controllability of STNUs with variable-observation delay had been demonstrated to
be possible in prior work [cite:@Bhargava2018a], though an explicit, online execution strategy, let
alone a valid execution strategy, was never defined for variable-delay STNUs. For our first
contribution, we define an execution strategy for variable-delay controllable STNUs and prove its
validity.

Likewise, dynamic schedulers have been established for dispatching events from STNUs, e.g. FAST-EX
[cite:@Hunsberger2016]. For our second contribution, we defined a novel delay scheduler built on
FAST-EX capable of applying the execution strategy defined in our first contribution.

We elaborate further on our approach to each contribution below.

*** Defining a Valid Execution Strategy for STNUs with Variable Observation Delay

We cannot execute an STNU without first demonstrating that it is controllable. Our approach to
checking the controllability of STNUs with observation delay is to apply Bhargava's Variable-Delay
Controllability checker (VDC) [cite:@Bhargava2018]. VDC is a procedure that takes place in two
stages and is $O(N^{3})$ in the number of events. In the first stage, we transform the STNU with
variable observation delay to one with fixed observation delay in $O(N^{2})$. In the second stage,
we check the controllability of the fixed-delay STNU using Bhargava's fixed-delay controllability
checker (FDC) [cite:@Bhargava2018a;@Bhargava2020;], which is modified from Morris' $O(N^{3})$
dynamic controllability check [cite:@Morris2014] such that it accounts for fixed observation delay
in contingent links.

In short, the first stage process is built around the idea of modeling a worst-case scenario with
respect to receiving observations. The resulting fixed-delay STNU reflects a situation where the
executive learns as little as possible about the contingent events. If the fixed-delay STNU with
minimal information is controllable, then so too must any situation be controllable when we learn
more information.

We contribute the definition for an execution strategy for variable-delay STNUs, wherein we dispatch
events according to the /dispatchable form/ of the /fixed-delay/ STNU, while respecting the
constraints modeled in the /variable-delay/ STNU. Existing controllability checks, like FDC, and
execution strategies, like FAST-EX, depend on a dispatchable form, i.e. a /distance graph/
representation of the STNU. The key challenge in defining an execution strategy for a variable-delay
STNU is that unlike vanilla STNUs and fixed-delay STNUs, a dispatchable form for variable-delay
STNUs has not been investigated. Hence why the VDC check first transforms the variable-delay STNU to
a fixed-delay form. In Chapter [[ch:delay-scheduling]], we formally define the execution strategy for
variable-delay STNUs and prove its validity.

*** Online Dispatching for STNUs with Variable Observation Delay

We chose to build the delay scheduler as a modified variant of Hunsberger's FAST-EX
[cite:@Hunsberger2016] because, to the best of our knowledge, FAST-EX is the fastest dynamic
scheduler published to date.

FAST-EX maps partial histories, or schedules of events up to the current time, to Real-Time
Execution Decisions (RTEDs). RTEDs contain a list of events to be executed and a time (that could be
from now to point in the future) to execute them. When contingent events are observed or
controllable events are scheduled, it updates the distance graph to capture the information gained.
To improve the online performance of dynamic scheduling, Hunsberger's insight was to reduce the
space of the dispatchable form by removing edges as events are executed. It can do so by first
iteratively updating the distances to and from the remaining events by performing Dijkstra's Single
Sink and Single Source Shortest Paths algorithms to and from the zero point (start event) of the
distance graph.

The delay scheduler differs from FAST-EX because we no longer assume events are instantaneously observed....

in the way it (1) records partial histories and (2) how it generates RTEDs. For both changes, we
must address special cases related to a change in the /execution space/ - the time ranges of
possible event assignments - that result from the variable-delay to fixed-delay STNU transformation.
We make two changes for (1). First, we do not assume that contingent events are instantaneously
observed. Essentially, we use the known fixed observation delay to decide where in the past an
observed contingent event was assigned. Second, to account for one special case due to the
transformation, we use observations to optimistically rewrite the variable-delay STNU in an attempt
to shorten the overall makespan (see Section [[sec:optimistic-rescheduling]]). Key to (2) is that we are
allowed to /imagine/ that contingent events were assigned despite never observing them. Imagining
contingent events is a result of the other special case from the variable-delay to fixed-delay
transformation (see Section [[sec:delay-scheduling]]).

** Coordination
<<sec:approach-coordination>>

# TODO wc. framework?
To the best of our knowledge, this thesis contributes the first framework for, and demonstration of,
online coordination between dynamic schedulers with inter-agent temporal constraints.

# TODO wc. "vehicle control". actually moving the vehicle
# To be clear, coordination is limited to scheduling and dispatching - it does not include task
# planning, motion planning, or vehicle control.

Our challenge is to allow multiple Kirk instances to dynamically schedule simultaneously while
sharing events. At a high level, our approach is that inter-agent communications take the form of
event observations. Each agent's ego controllable events are sent to peers, who receive them as
exogenous, uncontrollable event observations. We allow (and expect) that communications have
uncertain delay, thus we apply the modeling formalisms of variable-delay STNUs to inter-agent
temporal constraints.

Our approach to online coordination is as follows:

1. Each instance of Kirk receives a unique, manually written control program
2. All control programs begin execution at the same time
3. Kirk executives broadcast scheduled events to a known set of peers
4. In their own schedules, Kirk executives record event observations from their peers as they are
   received

# TODO is the first sentence true?
# TODO clean up end of paragraph?
The challenge of manually writing control programs that enable MA execution is non-trivial. A
modeler must consider both intra-agent and inter-agent constraints that, compounded by uncertain
communication, frequently contain difficult to spot conflicts. (It is no surprise that temporal
decoupling is incomplete!) Furthermore, we found that translating events between executives is
challenging. When writing MA control programs, it is possible that the same event has different
identifiers in different STNUs. Care must be taken to ensure different executives understand the
event observations they receive from their peers. In our experiments, our strategy was to carefully
write MA control programs to guarantee events shared names between executives. MA control programs
under uncertain communication will be discussed in detail in Section [[sec:ma-control-programs]].

# TODO is there more to say about second point?
The second point ensures that control programs share a temporal frame of reference. However,
uncertain communication was able to partially mitigate executives with clocks that did not agree. In
effect, communication delay can be used to mitigate the differences in executive clock times.

The third and fourth points encapsulate our contribution to the challenge of MA communication with
respect to inter-agent temporal constraints. We imagined inter-agent communications as a simple
directional graph between executives. In this structure, all event nodes are publishers. Outgoing
edges represent subscribers that receive all scheduled events, including both controllable events
and uncontrollable event observations that the publishing agent itself receives. Event observations
are then naturally propagated through the graph. We assume that communication delay in the modeled
system incorporates the time events spend propagating through the graph. Event propagation will be
formally defined in Section [[sec:event-propagation]].

