#+title: Approach

* COMMENT
- for inter-agent communication as well as the observations agents make of the environment.
- where do we differentiate between existing work and the novel work of the thesis?
- With a model-based approach to autonomy, a human should not write an explicit program for solving
  the problem domain. Instead, the executive should take full responsibility for taking a model from
  a human and producing safe actions according to the constraints provided.
- Furthermore, extending either approach [MASTNUs and HR] likely would have been non-trivial and
  would have expanded the scope of this thesis significantly.

** TODO do we need to describe how each component is tested?
** TODO check ref for where VDC experiments live
I say they're at the end of the vdc chapter, but they currently aren't there.
** TODO we may not need to delineate between agent and executive. "multi-agent" is kind of a problem if we do
** IDEA does the discussion of what we could have done belong in the discussion section instead?
** Robustness

Autonomy research tends to focus on ideal, generic executives that behave perfectly. For instance,
temporal reasoning research assumes that controllable events are executed instantaneously at the
exact correct time without fail. Reality cannot conform to ideal conditions. At minimum, CPU cycles
will tick by before a scheduled event is dispatched, causing the hands of precise clocks to move
when our algorithms expect them to remain static. To run on hardware, executives and agents must
communicate, which adds additional time that is unaccounted for in scheduling algorithms. And
finally, we need to explicitly decide how to translate temporal events to messages that hardware can
execute. Given our need to deploy Kirk on real hardware, we contribute a seemingly disparate set of
algorithms removing expectations of idealized performance, that, when taken together, enable
deployment of temporal reasoning algorithms in real agents.

We include five contributions to dynamic scheduling and dispatching for enabling robust executives.

1. A well defined architecture for event execution with distinct scheduler, dispatcher, and driver
   responsibilities
2. Tolerance in event scheduling
3. Controllable event preemption
4. The separation of real and =noop= controllable events in execution decisions
5. A clock-synchronized approach for managing repeated tasks during online execution

# There lacks research into the design of interfaces between executives and agents.

TODO given the hardware experiments of this thesis...

This thesis identifies addresses three core issues...

We improve the delay scheduler by differentiating real and =noop= controllable events...

We remove the assumption that controllable events are instantaneously executed...

We identify drawbacks in na√Øve approaches to building executives using parallel and concurrent
processes. We propose a clock-synchronized architecture that addresses challenges in simulating
executives and better matches our expectations of order of operations behavior as programmers.


** bcw
define input and output for subproblems. then give breakdowns of what it means for each subproblem to be correct

define pseudocode for algo that calls   both subproblems, with proof showing that algo will solve problem statement given subsolvers work correctly

- in approach chapter, explain what each agent scheduler does as a black box. coordinator
  establishes comm pathways. and describe architecture of single agent scheduler


** Modeling and Controllability

We take a model-based approach to deploying autonomous systems, that is, prior to a mission, we
envision that engineers and domain experts work together to model the system at hand, then during
the mission (though not necessarily online), the autonomous system then takes the models as input
and decides how to act as output. There are three core challenges with modeling - the first being
that we need formalisms that can be ingested by our algorithms and be used to guarantee safe
execution. In other words, we need a data type to represent the phenomenon over which we want the
algorithms comprising our system to reason. Next, the chosen formalism must allow us to guarantee
the satisfiability of the system, i.e. the autonomous system must be able to act in a safe manner
respecting all constraints to go from the starting state to the goal state. The third challenge is
that we need a human-friendly form of said formalisms such that human domain experts, who are
unlikely to also be experts in autonomy, can still model their domains accurately enough such that
the desired safe behavior is exhibited by the autonomous system. We address each challenge in our
approach to modeling.

States and constraints can take on arbitrary forms, and how they are modeled depends entirely on the
problem domain. Classical planning problems use boolean predicates and actions to model the world
(e.g. STRIPS planning problems [cite:@Fikes1971]). Scheduling problems involving time constraints
will have continuous temporal bounds between discrete timepoints (e.g. in the form of temporal
constraint graphs [cite:@Dechter1991]). Other scenarios where motion planning is the focus will
likely be modeled with vectors of continuous values in $\mathbb{R}$ (e.g. often representing convex
regions as in the case of the /Magellan/ planner [cite:@FernandezGonzalez2018]). Hybrid domains
combine states and constraints with mixed continuous and discrete values (e.g. using mixed-integer
linear programs as demonstrated by Chen et al. [cite:@Chen2021a]).

Given this thesis' emphasis on temporal scheduling, we choose to focus entirely on formalisms where
states and constraints are temporal in nature. The starting state of the system is, by definition,
one where time is set to $0$ seconds, $t = 0$, and no events have been executed (i.e. no event
assignments have been made). We then define controlled and uncontrolled set-bounded constraints
between events. The goal state is one where times have been assigned to each controllable event such
that all constraints are satisfied. To do so, we build our formalisms representing temporal
constraints with set-bounded observation delay on top of simple temporal networks with uncertainty
(STNUs) [cite:@Vidal1999]. A brief explanation of our modeling strategy for temporal constraints
with observation delay follows in Section [[sec:obs-delay-in-stnus]], though we will elaborate on
temporal reasoning and our chosen formalisms for it in much more detail in Chapter [[ch:modeling-tn]].

With a modeling formalism in hand, the second key challenge is to use the formalism to guarantee a
property known as /controllability/, or that all controllable temporal constraints can be satisfied
given the existing uncertainty in the STNU. There already exist a number of strategies for checking
the controllability of STNUs. Examples of different strategies include the canonical work by Morris,
Muscettola, and Vidal in checking for semi-reducible negative cycles (SRNCs)
[cite:@MMV2001;@Morris2005;@Morris2006;@Morris2014], as well as reframing controllability as a
Satisfiable Modulo Theory (SMT) problem [cite:@Cimatti2012;]. In our approach to controllability
under observation uncertainty, we build on top of checks for SRNCs as will be shown in [[sec:vdc]].

# TODO is there a better sentence to start this paragraph?
For the third challenge, we choose to extend the Reactive Model-Based Programming Language (RMPL)
[cite:@RMPL2002], which provides to domain experts a means for describing the constraints and goal
states of their domain without requiring additional expertise in autonomy. With RMPL, a human
planner is capable of building control programs describing the constraints, agents, and states of
the problem domain in a way that is human-readable yet highly programmable, and is independent of
the underlying algorithms used by the autonomous system. As will be explained in Section [[sec:rmpl]]
below, our approach was to add the ability for planners to model observation delay alongside
temporal constraints in RMPL.

*** Modeling Uncertain Observation Delay in STNUs
<<sec:obs-delay-in-stnus>>

In the case of observation delay, our model dictates that we reason over two time intervals. The
first time interval represents the true length of time between two events, while the second interval
represents the length of time between when an event occurs and when an executive observes the event.
For ensuring that an executive takes safe actions in an uncertain environment, we assume worst-case
scenario with respect to information gain. Our approach to modeling uncertain observation delay in
STNUs is as follows.

1. The duration of time between two events is represented as a set-bounded interval
2. The duration of time between an event and its observation (observation delay) is represented as a
   set-bounded interval
3. Timestamps in event observations are ignored
4. The true duration of observation delay is not guaranteed to be learned

The first point comes directly from the STNU formalism (see Section [[sec:tn]]). The second point allows
for uncertainty in the amount of observation delay, e.g. in an uncertain environment, we could model
observation delay for a given event as, say, $[1, \infty]$, meaning an observation of an event could
arrive one second after it occurs, or never arrive, or arrive at some arbitrary time, $t$, $1 < t \leq
\infty$ later. The third point comes from assuming worst-case scenario and prevents us from
"cheating" in our scheduling algorithm. For instance, imagine two agents coordinating. If agents
passed timestamp information along with events to one another, they must also be able to synchronize
their clocks, potentially to an arbitrary degree of precision. The challenge of synchronizing clocks
between agents is outside the scope of this thesis and may not always be possible. As such,
executives only trust their own clocks. Rather than backfill potentially erroneous times for event
assignments as reported by exogenous sources, the executive we envision in this thesis records times
that are internally consistent with its own clock. Doing so guarantees that the actions the
executive takes as a result of temporal reasoning are consistent with its model.

The fourth point, that we are not guaranteed to learn event assignments, is a result of the first
three. It stands to reason that an event observation is a function of the true assignment of an
event and its observation delay. If there is uncertainty in both the event assignment and delay,
then we have one equation with two unknowns. Thus, the term "uncertain" in uncertain observation
delay means that we are forced to reason with deciding when to act even when we are not guaranteed
to learn the true times assigned to events.

# TODO where do the VDC experiments live? is this the end of ch:modeling-tn the right reference?

We call STNUs with variable observation delay /variable-delay STNUs/, which Bhargava first proposed
as the underlying data structure for checking Variable-Delay Controllability (VDC)
[cite:@Bhargava2018;@Bhargava2020;]. We (Pittman) co-authored a journal article with Bhargava that
was submitted to the Journal of AI Research presenting VDC and its chance constrained variant. We
include VDC as a contribution of this thesis, given that we (Pittman) wrote or rewrote a significant
portion of the VDC article, notably including a rewrite of key proofs with novel explanations. The
new proofs will will be presented in Section [[sec:vdc]]. Additionally, we rewrote the comparison of VDC
to Partially Observable STNUs (POSTNUs) [cite:@Moffitt2007], including identifying and correcting a
mistake in the same comparison as originally put forth by Bhargava in [cite:@Bhargava2020]. See
Appendix [[appendix:postnus]] for an in-depth comparison to POSTNUs. We designed and ran the
quantitative evaluation of VDC in the article. The same experiments will be included at the end of
Chapter <<ch:modeling-tn>>.

We formalize event observations and observation delay in Section [[sec:vdc]].

** Scheduling Temporal Events
<<sec:approach-scheduling>>

The bulk of the technical chapters of this thesis, namely Chapters [[ch:modeling-tn]] and
[[ch:delay-scheduling]], describe the algorithmic insights behind the /delay scheduler/. The delay
scheduler dispatches controllable events online for dynamically controllable STNUs while reasoning
over observation delay in the uncontrollable events it receives. There were two key contributions
that enabled the delay scheduler.

Reasoning over the controllability of STNUs with variable-observation delay had been demonstrated to
be possible in prior work [cite:@Bhargava2018a], though an explicit, online execution strategy, let
alone a valid execution strategy, was never defined for variable-delay STNUs. For our first
contribution, we define an execution strategy for variable-delay controllable STNUs and prove its
validity.

Likewise, dynamic schedulers have been established for dispatching events from STNUs, e.g. FAST-EX
[cite:@Hunsberger2016]. For our second contribution, we defined a novel delay scheduler built on
FAST-EX capable of applying the execution strategy defined in our first contribution.

We elaborate further on our approach to each contribution below.

*** Defining a Valid Execution Strategy for STNUs with Variable Observation Delay

We cannot execute an STNU without first demonstrating that it is controllable. Our approach to
checking the controllability of STNUs with observation delay is to apply Bhargava's Variable-Delay
Controllability checker (VDC) [cite:@Bhargava2018]. VDC is a procedure that takes place in two
stages and is $O(N^{3})$ in the number of events. In the first stage, we transform the STNU with
variable observation delay to one with fixed observation delay in $O(N^{2})$. In the second stage,
we check the controllability of the fixed-delay STNU using Bhargava's fixed-delay controllability
checker (FDC) [cite:@Bhargava2018a;@Bhargava2020;], which is modified from Morris' $O(N^{3})$
dynamic controllability check [cite:@Morris2014] such that it accounts for fixed observation delay
in contingent links.

In short, the first stage process is built around the idea of modeling a worst-case scenario with
respect to receiving observations. The resulting fixed-delay STNU reflects a situation where the
executive learns as little as possible about the contingent events. If the fixed-delay STNU with
minimal information is controllable, then so too must any situation be controllable when we learn
more information.

We contribute the definition for an execution strategy for variable-delay STNUs, wherein we dispatch
events according to the /dispatchable form/ of the /fixed-delay/ STNU, while respecting the
constraints modeled in the /variable-delay/ STNU. Existing controllability checks, like FDC, and
execution strategies, like FAST-EX, depend on a dispatchable form, i.e. a /distance graph/
representation of the STNU. The key challenge in defining an execution strategy for a variable-delay
STNU is that unlike vanilla STNUs and fixed-delay STNUs, a dispatchable form for variable-delay
STNUs has not been investigated. Hence why the VDC check first transforms the variable-delay STNU to
a fixed-delay form. In Chapter [[ch:delay-scheduling]], we formally define the execution strategy for
variable-delay STNUs and prove its validity.

*** Online Dispatching for STNUs with Variable Observation Delay

We chose to build the delay scheduler as a modified variant of Hunsberger's FAST-EX
[cite:@Hunsberger2016] because, to the best of our knowledge, FAST-EX is the fastest dynamic
scheduler published to date.

FAST-EX maps partial histories, or schedules of events up to the current time, to Real-Time
Execution Decisions (RTEDs). RTEDs contain a list of events to be executed and a time (that could be
from now to point in the future) to execute them. When contingent events are observed or
controllable events are scheduled, it updates the distance graph to capture the information gained.
To improve the online performance of dynamic scheduling, Hunsberger's insight was to reduce the
space of the dispatchable form by removing edges as events are executed. It can do so by first
iteratively updating the distances to and from the remaining events by performing Dijkstra's Single
Sink and Single Source Shortest Paths algorithms to and from the zero point (start event) of the
distance graph.

The delay scheduler differs from FAST-EX because we no longer assume events are instantaneously observed....

in the way it (1) records partial histories and (2) how it generates RTEDs. For both changes, we
must address special cases related to a change in the /execution space/ - the time ranges of
possible event assignments - that result from the variable-delay to fixed-delay STNU transformation.
We make two changes for (1). First, we do not assume that contingent events are instantaneously
observed. Essentially, we use the known fixed observation delay to decide where in the past an
observed contingent event was assigned. Second, to account for one special case due to the
transformation, we use observations to optimistically rewrite the variable-delay STNU in an attempt
to shorten the overall makespan (see Appendix [[appendix:optimistic-rescheduling]]). Key to (2) is that we are
allowed to /imagine/ that contingent events were assigned despite never observing them. Imagining
contingent events is a result of the other special case from the variable-delay to fixed-delay
transformation (see Section [[sec:delay-scheduling]]).

** Coordination
<<sec:approach-coordination>>

# TODO wc. framework?
To the best of our knowledge, this thesis contributes the first framework for, and demonstration of,
online coordination between dynamic schedulers with inter-agent temporal constraints.

# TODO wc. "vehicle control". actually moving the vehicle
# To be clear, coordination is limited to scheduling and dispatching - it does not include task
# planning, motion planning, or vehicle control.

Our challenge is to allow multiple Kirk instances to dynamically schedule simultaneously while
sharing events. At a high level, our approach is that inter-agent communications take the form of
event observations. Each agent's ego controllable events are sent to peers, who receive them as
exogenous, uncontrollable event observations. We allow (and expect) that communications have
uncertain delay, thus we apply the modeling formalisms of variable-delay STNUs to inter-agent
temporal constraints.

Our approach to online coordination is as follows:

1. Each instance of Kirk receives a unique, manually written control program
2. All control programs begin execution at the same time
3. Kirk executives broadcast scheduled events to a known set of peers
4. In their own schedules, Kirk executives record event observations from their peers as they are
   received

# TODO is the first sentence true?
# TODO clean up end of paragraph?
The challenge of manually writing control programs that enable MA execution is non-trivial. A
modeler must consider both intra-agent and inter-agent constraints that, compounded by uncertain
communication, frequently contain difficult to spot conflicts. (It is no surprise that temporal
decoupling is incomplete!) Furthermore, we found that translating events between executives is
challenging. When writing MA control programs, it is possible that the same event has different
identifiers in different STNUs. Care must be taken to ensure different executives understand the
event observations they receive from their peers. In our experiments, our strategy was to carefully
write MA control programs to guarantee events shared names between executives. MA control programs
under uncertain communication will be discussed in detail in Section [[sec:ma-control-programs]].

# TODO is there more to say about second point?
The second point ensures that control programs share a temporal frame of reference. However,
uncertain communication was able to partially mitigate executives with clocks that did not agree. In
effect, communication delay can be used to mitigate the differences in executive clock times.

The third and fourth points encapsulate our contribution to the challenge of MA communication with
respect to inter-agent temporal constraints. We imagined inter-agent communications as a simple
directional graph between executives. In this structure, all event nodes are publishers. Outgoing
edges represent subscribers that receive all scheduled events, including both controllable events
and uncontrollable event observations that the publishing agent itself receives. Event observations
are then naturally propagated through the graph. We assume that communication delay in the modeled
system incorporates the time events spend propagating through the graph. Event propagation will be
formally defined in Section [[sec:event-propagation]].


* Approach
<<ch:approach>>

We define a delay scheduler in such a way that one instance is useful for single-agent scheduling,
and multiple instances can be seamlessly integrated for collaboration with inter-agent constraints.
Our approach builds towards such a multi-agent delay scheduler by first defining the subproblems
necessary for single-agent scheduling with uncertain communication before layering on a
communication pathway for multi-agent scheduling. Figure [[fig:approach-ma-schedulers]] presents a
simplified view of multi-agent scheduling.

#+label: fig:approach-ma-schedulers
#+attr_latex: :width 0.7\textwidth
#+caption: A sample architecture with two delay schedulers collaborating. Each agent receives a single temporal network as input. Observations of the outside world are recorded. Communications relay event assignments to peers. Each agent outputs its own RTED.
[[file:../images/approach-ma-schedulers.png]]

Our approach relies on the ability of a delay scheduler to accurately decide what events should be
scheduled and when it is /valid/ to do so. In this context, a decision being "valid" means that the
events and time of an RTED guarantees that all constraints in the problem can be satisfied given the
history of events scheduled before now. We naturally need one or more data structures that, if
maintained correctly during scheduling, can be queried to produce such an RTED. We refer to such a
data structure as the dispatchable form, though, as will be seen in Chapter [[ch:delay-scheduling]],
other data structures facilitate scheduling as well.

A delay scheduler must be able to output RTEDs that are consistent with the constraints of the
problem and the history of scheduled events. There are four key subproblems that must be addressed:

1. an offline process must *initialize* a dispatchable form that reflects the semantics of $S$ and
   $\gammabar$,
2. an online process must *update* the dispatchable form given an event observation at a given time,
3. an online process must *broadcast* new event assignments with peers, and
4. an online process must *query* the dispatchable form for new RTEDs.

#+label: fig:approach-interfaces
#+attr_latex: :width 0.7\textwidth
#+caption: The four interfaces of a delay scheduler. The second and third are combined to highlight that broadcasts are trigged when events are observed. The first shows the dispatchable form being intialized from a model. The second shows that event observations will cause the dispatchable form to be updated, immediatelly triggering a broadcast (the third interface). The fourth interface queries the dispatchable form to create RTEDs.
file:../images/approach-interfaces.png

Figure [[fig:approach-interfaces]] shows the architecture of a delay scheduler with respect to its four
interfaces and dispatchable form.

#+label: alg:approach-delay-scheduler
#+begin_export tex
\begin{algorithm}
\SetAlgoLined
\SetKwFunction{Return}{return}
\SetKwInput{Input}{Input}
\SetKwInput{Output}{Output}
\SetKwInput{Algorithm}{\textsc{Delay Scheduling}}
\SetKwInput{Initialize}{Initialization}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\Indm
\Input{Controllable temporal network $S$; Observation uncertainty $\gammabar$; \texttt{clock}; \texttt{peers}}
\Initialize{\texttt{dispatchable-form} $\gets$ \texttt{initialize}($S, \gammabar$); \texttt{RTED} $\gets \varnothing$;}
\Indp
\Algorithm{}
\Indp

\While{there are unexecuted executable events} {
  \If{Event $x$ is observed} { \label{line:event-observed}
    \texttt{update(dispatchable-form, $x$, clock.now))}\;
    \texttt{broadcast($x$, peers)}\;
  }

  \texttt{RTED} $\gets$ \texttt{query(dispatchable-form, clock.now)}
}
\caption{Algorithm for performing delay scheduling to produce RTEDs for all executable events in a temporal network.}
\label{alg:approach-delay-scheduler}
\end{algorithm}
#+end_export

We provide pseudo-code for a delay scheduler in Algorithm [[alg:approach-delay-scheduler]]. =initialize=
will create the dispatchable form, =update= will modify the dispatchable form to reflect an event
assignment, =broadcast= will send event assignments to peers, and =query= will read the dispatchable
form to find the next RTED.

For now, we make the following assumptions. We assume that initialization, updates, and queries are
sound and complete algorithms with respect to their intended handling of the dispatchable form. We
use the term "networked" to refer to agents that can communicate event observations to each other.
Broadcasting assumes the existence of a communication protocol that guarantees messages indicating
an event has been assigned reach all networked schedulers. If a temporal network is controllable,
then there must exist a dispatchable form [cite:@MMV2001].

Below, we prove that Algorithm [[alg:approach-delay-scheduler]] will guarantee the output of valid RTEDs
for all executable events for coordinating agents. We start by showing that the delay scheduler can
be used in a multi-agent context.

#+label: lemma:approach-all-controllable
#+latex: \begin{lemma}
#+latex: \label{lemma:approach-all-controllable}
For $a$ delay schedulers, if each $S_{a}$ and $\gammabar_{a}$ received by each delay scheduler $a
\in A$ is controllable and accurately models the world, then all networked delay schedulers may
produce valid RTEDs.
#+latex: \end{lemma}

#+latex: \begin{proof}
If $S_{a}$ is controllable for a single delay scheduler, then there must exist a set of RTEDs that
allows all constraints to be satisfied for all resolutions of uncertainty in the uncontrollable
constraints and observation delay. If it were not the case that any $S_{a}$ and $\gammabar_{a}$
accurately models the world, then the uncontrollable inter-agent constraints of $S_{a}$ and
$\gammabar_{a}$ would not strictly encompass all possible outcomes of uncertainty during scheduling.
This would mean that, during scheduling, there may be a resolution of uncertainty that does not
allow a valid RTED to be produced, which is inconsistent with a controllable $S_{a}$. Thus if each
$S$ is controllable and accurate for all delay schedulers, then all delay schedulers may produce
valid RTEDs.
#+latex: \end{proof}

We now show that the delay scheduler will produce valid RTEDs in a single-agent context.

#+label: lemma:initialization
#+latex: \begin{lemma}
#+latex: \label{lemma:initialization}
Given a controllable temporal network $S$ consisting of a set of events, $X$, constraints, $R$, and
uncertain observation delay, $\gammabar$, initializing the dispatchable form before the first event
is observed guarantees the dispatchable form can be used to schedule any executable event in $X$.
#+latex: \end{lemma}

#+latex: \begin{proof}
As an offline process, by definition initialization will run before scheduling begins. Thus, the
dispatchable form must be valid and include enough information to schedule all executable events.
#+latex: \end{proof}

Not all events may be observed. For instance, any event with infinite observation delay (as may
occur during a communication dropout) is unobservable. The delay scheduler cannot schedule events
with infinite observation delay.

#+label: lemma:observable-events
#+latex: \begin{lemma}
#+latex: \label{lemma:observable-events}
All events that have the ability to impact RTEDs may be observed by the delay scheduler.
#+latex: \end{lemma}

#+latex: \begin{proof}
If $S$ is controllable, then it must be the case that the delay scheduler can output RTEDs that will
guarantee all constraints between events can be satisfied. If it were the case that unobservable
events must be assigned in order to produce a valid RTED, then scheduling would depend on
information that cannot be learned, meaning $S$ would not be controllable.
#+latex: \end{proof}

For the next lemma, it is important to highlight that RTEDs may not depend on information about
future events.

#+label: lemma:all-events-are-observed
#+latex: \begin{lemma}
#+latex: \label{lemma:all-events-are-observed}
If an event is scheduled, it will be observed by the delay scheduler.
#+latex: \end{lemma}

#+latex: \begin{proof}
There are two parts to this proof. First, the delay scheduler loops without pause until all
executable events have been scheduled, meaning that the conditional on line
$\ref{line:event-observed}$ will be reached for all events that can have an impact on RTEDs.

Second, RTEDs are not the same as event assignments. As will be shown in Definition [[def:rted-op]], the
execution time of an RTED must be in the future. We are not allowed to assign an event to a future
time, thus the events in an RTED cannot be immediately scheduled. We observe when executable events
are scheduled in the future.
#+latex: \end{proof}

#+label: lemma:observe-then-rted
#+latex: \begin{lemma}
#+latex: \label{lemma:observe-then-rted}
If we observe all events before producing RTEDs, then RTEDs will always be valid.
#+latex: \end{lemma}

#+latex: \begin{proof}
We see that we always check for event observations before producing RTEDs. There are no processes
between checking for an observation and producing an RTED. Therefore, each RTED will be queried
against a dispatchable form that has been modified to reflect all event assignments up to the
current time. If the choice of dispatchable form is valid for any set of assignments up to the
current time, and the querying process is sound and complete, then the RTED must also be valid.
#+latex: \end{proof}

We finish by revisiting the multi-agent context.

#+label: lemma:approach-broadcasting
#+latex: \begin{lemma}
#+latex: \label{lemma:approach-broadcasting}
If there are satisfiable inter-agent constraints, then broadcasting all event assignments to all
peers guarantees that each delay scheduler may produce valid RTEDs.
#+latex: \end{lemma}

#+latex: \begin{proof}
All observable events must be assigned. If all event assignments are broadcasted to all agents, then
it must be the case that all agents observe all events. If all observable events are received for a
controllable $S$, then it must be the case that a delay scheduler can produce a valid RTED, and thus
all networked delay schedulers can produce valid RTEDs.
#+latex: \end{proof}

The next chapters will address each of the assumptions made above. Chapter [[ch:modeling-tn]] will
elaborate on modeling temporal networks with uncertain communication and checking their
controllability. Chapter [[ch:delay-scheduling]] will focus on the process of creating and maintaining a
dispatchable form throughout single-agent scheduling. Chapter [[ch:technical-executive]] describes the
integration of Algorithm [[alg:approach-delay-scheduler]] in a high-level task executive. Chapter
[[ch:technical-coordination]] will describe the design of a robust broadcasting algorithm for networked
schedulers with uncertain communication.
